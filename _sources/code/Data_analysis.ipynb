{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fb0d430",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e251389",
   "metadata": {},
   "source": [
    "In this chapter the logistic regression algorithm is applied to the macro- and microstrucutral data. The procedure is analogous to both kind of data. First, the data is prepared in terms of making it suitable to use it in the code efficiently. Second, the logistic regression model is built, defining the input and output variables, scaling the relevant variables and splitting the data set into training and testing samples and subsequently training the model. Followed by evulating the model, we will refer to different metrics that provide information on how the model performs. \n",
    "\n",
    "We first start with **cortical thickness (CT)**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "623b534c",
   "metadata": {},
   "source": [
    "## 1. Macro-structural data: Cortical Thickness (CT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150941c9",
   "metadata": {},
   "source": [
    "### 1.1 Data preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed303c0c",
   "metadata": {},
   "source": [
    "In the beginning, all relevant modules needed for the analysis are imported. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4c372d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant modules\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc556abe",
   "metadata": {},
   "source": [
    "Again, to read the data, the os.pardir() function is used to make the code reproducible independent of different operating systems. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c724d3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "\n",
    "CT_Dublin_path = os.path.join(os.pardir, 'data', 'PARC_500.aparc_thickness_Dublin.csv')\n",
    "CT_Dublin = pd.read_csv(CT_Dublin_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dab3630c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Group</th>\n",
       "      <th>lh_bankssts_part1_thickness</th>\n",
       "      <th>lh_bankssts_part2_thickness</th>\n",
       "      <th>lh_caudalanteriorcingulate_part1_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part1_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part2_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part3_thickness</th>\n",
       "      <th>...</th>\n",
       "      <th>rh_supramarginal_part5_thickness</th>\n",
       "      <th>rh_supramarginal_part6_thickness</th>\n",
       "      <th>rh_supramarginal_part7_thickness</th>\n",
       "      <th>rh_frontalpole_part1_thickness</th>\n",
       "      <th>rh_temporalpole_part1_thickness</th>\n",
       "      <th>rh_transversetemporal_part1_thickness</th>\n",
       "      <th>rh_insula_part1_thickness</th>\n",
       "      <th>rh_insula_part2_thickness</th>\n",
       "      <th>rh_insula_part3_thickness</th>\n",
       "      <th>rh_insula_part4_thickness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CON9225</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.180</td>\n",
       "      <td>2.382</td>\n",
       "      <td>2.346</td>\n",
       "      <td>2.526</td>\n",
       "      <td>2.747</td>\n",
       "      <td>2.544</td>\n",
       "      <td>...</td>\n",
       "      <td>2.817</td>\n",
       "      <td>2.325</td>\n",
       "      <td>2.430</td>\n",
       "      <td>3.004</td>\n",
       "      <td>3.979</td>\n",
       "      <td>2.329</td>\n",
       "      <td>3.620</td>\n",
       "      <td>2.776</td>\n",
       "      <td>3.282</td>\n",
       "      <td>3.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CON9229</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.394</td>\n",
       "      <td>1.973</td>\n",
       "      <td>2.534</td>\n",
       "      <td>2.439</td>\n",
       "      <td>2.485</td>\n",
       "      <td>2.435</td>\n",
       "      <td>...</td>\n",
       "      <td>2.611</td>\n",
       "      <td>2.418</td>\n",
       "      <td>2.317</td>\n",
       "      <td>2.794</td>\n",
       "      <td>3.851</td>\n",
       "      <td>2.034</td>\n",
       "      <td>3.588</td>\n",
       "      <td>2.654</td>\n",
       "      <td>3.124</td>\n",
       "      <td>3.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CON9231</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.551</td>\n",
       "      <td>2.567</td>\n",
       "      <td>1.954</td>\n",
       "      <td>2.439</td>\n",
       "      <td>2.428</td>\n",
       "      <td>2.190</td>\n",
       "      <td>...</td>\n",
       "      <td>2.777</td>\n",
       "      <td>2.309</td>\n",
       "      <td>2.390</td>\n",
       "      <td>2.365</td>\n",
       "      <td>4.039</td>\n",
       "      <td>2.337</td>\n",
       "      <td>3.657</td>\n",
       "      <td>2.495</td>\n",
       "      <td>2.669</td>\n",
       "      <td>2.886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GASP3037</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.187</td>\n",
       "      <td>1.923</td>\n",
       "      <td>2.160</td>\n",
       "      <td>2.410</td>\n",
       "      <td>2.381</td>\n",
       "      <td>2.277</td>\n",
       "      <td>...</td>\n",
       "      <td>2.265</td>\n",
       "      <td>2.306</td>\n",
       "      <td>2.129</td>\n",
       "      <td>2.281</td>\n",
       "      <td>3.505</td>\n",
       "      <td>2.275</td>\n",
       "      <td>3.121</td>\n",
       "      <td>2.333</td>\n",
       "      <td>2.604</td>\n",
       "      <td>2.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GASP3040</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.862</td>\n",
       "      <td>1.750</td>\n",
       "      <td>2.129</td>\n",
       "      <td>2.516</td>\n",
       "      <td>2.244</td>\n",
       "      <td>2.169</td>\n",
       "      <td>...</td>\n",
       "      <td>2.582</td>\n",
       "      <td>2.314</td>\n",
       "      <td>2.047</td>\n",
       "      <td>2.389</td>\n",
       "      <td>3.272</td>\n",
       "      <td>2.445</td>\n",
       "      <td>3.171</td>\n",
       "      <td>2.216</td>\n",
       "      <td>2.659</td>\n",
       "      <td>2.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>RPG9019</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.240</td>\n",
       "      <td>2.150</td>\n",
       "      <td>1.995</td>\n",
       "      <td>2.254</td>\n",
       "      <td>2.164</td>\n",
       "      <td>2.008</td>\n",
       "      <td>...</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.288</td>\n",
       "      <td>2.395</td>\n",
       "      <td>2.105</td>\n",
       "      <td>3.267</td>\n",
       "      <td>2.257</td>\n",
       "      <td>3.231</td>\n",
       "      <td>2.574</td>\n",
       "      <td>2.920</td>\n",
       "      <td>2.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>RPG9102</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.269</td>\n",
       "      <td>2.124</td>\n",
       "      <td>2.531</td>\n",
       "      <td>2.502</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.183</td>\n",
       "      <td>...</td>\n",
       "      <td>2.302</td>\n",
       "      <td>2.182</td>\n",
       "      <td>2.182</td>\n",
       "      <td>2.327</td>\n",
       "      <td>2.881</td>\n",
       "      <td>2.124</td>\n",
       "      <td>3.159</td>\n",
       "      <td>2.450</td>\n",
       "      <td>2.753</td>\n",
       "      <td>2.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>RPG9119</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.559</td>\n",
       "      <td>2.578</td>\n",
       "      <td>2.463</td>\n",
       "      <td>2.463</td>\n",
       "      <td>2.053</td>\n",
       "      <td>...</td>\n",
       "      <td>2.534</td>\n",
       "      <td>2.604</td>\n",
       "      <td>2.449</td>\n",
       "      <td>2.370</td>\n",
       "      <td>3.111</td>\n",
       "      <td>2.190</td>\n",
       "      <td>3.480</td>\n",
       "      <td>2.294</td>\n",
       "      <td>2.571</td>\n",
       "      <td>2.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>RPG9121</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.940</td>\n",
       "      <td>2.438</td>\n",
       "      <td>2.272</td>\n",
       "      <td>2.272</td>\n",
       "      <td>2.610</td>\n",
       "      <td>2.099</td>\n",
       "      <td>...</td>\n",
       "      <td>2.638</td>\n",
       "      <td>2.225</td>\n",
       "      <td>2.013</td>\n",
       "      <td>2.115</td>\n",
       "      <td>3.853</td>\n",
       "      <td>2.231</td>\n",
       "      <td>3.187</td>\n",
       "      <td>2.510</td>\n",
       "      <td>2.759</td>\n",
       "      <td>2.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>RPG9126</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.108</td>\n",
       "      <td>2.269</td>\n",
       "      <td>2.145</td>\n",
       "      <td>2.192</td>\n",
       "      <td>2.443</td>\n",
       "      <td>1.977</td>\n",
       "      <td>...</td>\n",
       "      <td>2.013</td>\n",
       "      <td>2.251</td>\n",
       "      <td>2.021</td>\n",
       "      <td>2.419</td>\n",
       "      <td>3.679</td>\n",
       "      <td>1.970</td>\n",
       "      <td>3.192</td>\n",
       "      <td>2.551</td>\n",
       "      <td>2.855</td>\n",
       "      <td>2.985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Subject ID  Age  Sex  Group  lh_bankssts_part1_thickness  \\\n",
       "0      CON9225   21    2      1                        2.180   \n",
       "1      CON9229   28    2      1                        2.394   \n",
       "2      CON9231   29    2      1                        2.551   \n",
       "3     GASP3037   61    1      2                        2.187   \n",
       "4     GASP3040   47    1      2                        1.862   \n",
       "..         ...  ...  ...    ...                          ...   \n",
       "103    RPG9019   31    1      2                        2.240   \n",
       "104    RPG9102   42    2      2                        2.269   \n",
       "105    RPG9119   41    1      2                        2.273   \n",
       "106    RPG9121   51    1      2                        1.940   \n",
       "107    RPG9126   56    1      2                        2.108   \n",
       "\n",
       "     lh_bankssts_part2_thickness  lh_caudalanteriorcingulate_part1_thickness  \\\n",
       "0                          2.382                                       2.346   \n",
       "1                          1.973                                       2.534   \n",
       "2                          2.567                                       1.954   \n",
       "3                          1.923                                       2.160   \n",
       "4                          1.750                                       2.129   \n",
       "..                           ...                                         ...   \n",
       "103                        2.150                                       1.995   \n",
       "104                        2.124                                       2.531   \n",
       "105                        2.559                                       2.578   \n",
       "106                        2.438                                       2.272   \n",
       "107                        2.269                                       2.145   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part1_thickness  \\\n",
       "0                                     2.526   \n",
       "1                                     2.439   \n",
       "2                                     2.439   \n",
       "3                                     2.410   \n",
       "4                                     2.516   \n",
       "..                                      ...   \n",
       "103                                   2.254   \n",
       "104                                   2.502   \n",
       "105                                   2.463   \n",
       "106                                   2.272   \n",
       "107                                   2.192   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part2_thickness  \\\n",
       "0                                     2.747   \n",
       "1                                     2.485   \n",
       "2                                     2.428   \n",
       "3                                     2.381   \n",
       "4                                     2.244   \n",
       "..                                      ...   \n",
       "103                                   2.164   \n",
       "104                                   2.250   \n",
       "105                                   2.463   \n",
       "106                                   2.610   \n",
       "107                                   2.443   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part3_thickness  ...  \\\n",
       "0                                     2.544  ...   \n",
       "1                                     2.435  ...   \n",
       "2                                     2.190  ...   \n",
       "3                                     2.277  ...   \n",
       "4                                     2.169  ...   \n",
       "..                                      ...  ...   \n",
       "103                                   2.008  ...   \n",
       "104                                   2.183  ...   \n",
       "105                                   2.053  ...   \n",
       "106                                   2.099  ...   \n",
       "107                                   1.977  ...   \n",
       "\n",
       "     rh_supramarginal_part5_thickness  rh_supramarginal_part6_thickness  \\\n",
       "0                               2.817                             2.325   \n",
       "1                               2.611                             2.418   \n",
       "2                               2.777                             2.309   \n",
       "3                               2.265                             2.306   \n",
       "4                               2.582                             2.314   \n",
       "..                                ...                               ...   \n",
       "103                             2.273                             2.288   \n",
       "104                             2.302                             2.182   \n",
       "105                             2.534                             2.604   \n",
       "106                             2.638                             2.225   \n",
       "107                             2.013                             2.251   \n",
       "\n",
       "     rh_supramarginal_part7_thickness  rh_frontalpole_part1_thickness  \\\n",
       "0                               2.430                           3.004   \n",
       "1                               2.317                           2.794   \n",
       "2                               2.390                           2.365   \n",
       "3                               2.129                           2.281   \n",
       "4                               2.047                           2.389   \n",
       "..                                ...                             ...   \n",
       "103                             2.395                           2.105   \n",
       "104                             2.182                           2.327   \n",
       "105                             2.449                           2.370   \n",
       "106                             2.013                           2.115   \n",
       "107                             2.021                           2.419   \n",
       "\n",
       "     rh_temporalpole_part1_thickness  rh_transversetemporal_part1_thickness  \\\n",
       "0                              3.979                                  2.329   \n",
       "1                              3.851                                  2.034   \n",
       "2                              4.039                                  2.337   \n",
       "3                              3.505                                  2.275   \n",
       "4                              3.272                                  2.445   \n",
       "..                               ...                                    ...   \n",
       "103                            3.267                                  2.257   \n",
       "104                            2.881                                  2.124   \n",
       "105                            3.111                                  2.190   \n",
       "106                            3.853                                  2.231   \n",
       "107                            3.679                                  1.970   \n",
       "\n",
       "     rh_insula_part1_thickness  rh_insula_part2_thickness  \\\n",
       "0                        3.620                      2.776   \n",
       "1                        3.588                      2.654   \n",
       "2                        3.657                      2.495   \n",
       "3                        3.121                      2.333   \n",
       "4                        3.171                      2.216   \n",
       "..                         ...                        ...   \n",
       "103                      3.231                      2.574   \n",
       "104                      3.159                      2.450   \n",
       "105                      3.480                      2.294   \n",
       "106                      3.187                      2.510   \n",
       "107                      3.192                      2.551   \n",
       "\n",
       "     rh_insula_part3_thickness  rh_insula_part4_thickness  \n",
       "0                        3.282                      3.347  \n",
       "1                        3.124                      3.214  \n",
       "2                        2.669                      2.886  \n",
       "3                        2.604                      2.731  \n",
       "4                        2.659                      2.657  \n",
       "..                         ...                        ...  \n",
       "103                      2.920                      2.899  \n",
       "104                      2.753                      2.791  \n",
       "105                      2.571                      2.875  \n",
       "106                      2.759                      2.838  \n",
       "107                      2.855                      2.985  \n",
       "\n",
       "[108 rows x 312 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CT_Dublin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc679ec0",
   "metadata": {},
   "source": [
    "The data contains variables such as SubjectID, Age and Sex which are not relevant for the classification. Hence, we adjust the dataframe accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7eaad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust dataframe\n",
    "\n",
    "CT_Dublin_adj = CT_Dublin.drop(['Subject ID','Age', 'Sex'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1277a861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>lh_bankssts_part1_thickness</th>\n",
       "      <th>lh_bankssts_part2_thickness</th>\n",
       "      <th>lh_caudalanteriorcingulate_part1_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part1_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part2_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part3_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part4_thickness</th>\n",
       "      <th>lh_cuneus_part1_thickness</th>\n",
       "      <th>lh_cuneus_part2_thickness</th>\n",
       "      <th>...</th>\n",
       "      <th>rh_supramarginal_part5_thickness</th>\n",
       "      <th>rh_supramarginal_part6_thickness</th>\n",
       "      <th>rh_supramarginal_part7_thickness</th>\n",
       "      <th>rh_frontalpole_part1_thickness</th>\n",
       "      <th>rh_temporalpole_part1_thickness</th>\n",
       "      <th>rh_transversetemporal_part1_thickness</th>\n",
       "      <th>rh_insula_part1_thickness</th>\n",
       "      <th>rh_insula_part2_thickness</th>\n",
       "      <th>rh_insula_part3_thickness</th>\n",
       "      <th>rh_insula_part4_thickness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.180</td>\n",
       "      <td>2.382</td>\n",
       "      <td>2.346</td>\n",
       "      <td>2.526</td>\n",
       "      <td>2.747</td>\n",
       "      <td>2.544</td>\n",
       "      <td>2.582</td>\n",
       "      <td>1.816</td>\n",
       "      <td>2.228</td>\n",
       "      <td>...</td>\n",
       "      <td>2.817</td>\n",
       "      <td>2.325</td>\n",
       "      <td>2.430</td>\n",
       "      <td>3.004</td>\n",
       "      <td>3.979</td>\n",
       "      <td>2.329</td>\n",
       "      <td>3.620</td>\n",
       "      <td>2.776</td>\n",
       "      <td>3.282</td>\n",
       "      <td>3.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.394</td>\n",
       "      <td>1.973</td>\n",
       "      <td>2.534</td>\n",
       "      <td>2.439</td>\n",
       "      <td>2.485</td>\n",
       "      <td>2.435</td>\n",
       "      <td>2.458</td>\n",
       "      <td>1.723</td>\n",
       "      <td>1.821</td>\n",
       "      <td>...</td>\n",
       "      <td>2.611</td>\n",
       "      <td>2.418</td>\n",
       "      <td>2.317</td>\n",
       "      <td>2.794</td>\n",
       "      <td>3.851</td>\n",
       "      <td>2.034</td>\n",
       "      <td>3.588</td>\n",
       "      <td>2.654</td>\n",
       "      <td>3.124</td>\n",
       "      <td>3.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.551</td>\n",
       "      <td>2.567</td>\n",
       "      <td>1.954</td>\n",
       "      <td>2.439</td>\n",
       "      <td>2.428</td>\n",
       "      <td>2.190</td>\n",
       "      <td>2.377</td>\n",
       "      <td>2.026</td>\n",
       "      <td>1.800</td>\n",
       "      <td>...</td>\n",
       "      <td>2.777</td>\n",
       "      <td>2.309</td>\n",
       "      <td>2.390</td>\n",
       "      <td>2.365</td>\n",
       "      <td>4.039</td>\n",
       "      <td>2.337</td>\n",
       "      <td>3.657</td>\n",
       "      <td>2.495</td>\n",
       "      <td>2.669</td>\n",
       "      <td>2.886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2.187</td>\n",
       "      <td>1.923</td>\n",
       "      <td>2.160</td>\n",
       "      <td>2.410</td>\n",
       "      <td>2.381</td>\n",
       "      <td>2.277</td>\n",
       "      <td>2.361</td>\n",
       "      <td>1.585</td>\n",
       "      <td>1.750</td>\n",
       "      <td>...</td>\n",
       "      <td>2.265</td>\n",
       "      <td>2.306</td>\n",
       "      <td>2.129</td>\n",
       "      <td>2.281</td>\n",
       "      <td>3.505</td>\n",
       "      <td>2.275</td>\n",
       "      <td>3.121</td>\n",
       "      <td>2.333</td>\n",
       "      <td>2.604</td>\n",
       "      <td>2.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1.862</td>\n",
       "      <td>1.750</td>\n",
       "      <td>2.129</td>\n",
       "      <td>2.516</td>\n",
       "      <td>2.244</td>\n",
       "      <td>2.169</td>\n",
       "      <td>2.220</td>\n",
       "      <td>1.646</td>\n",
       "      <td>1.717</td>\n",
       "      <td>...</td>\n",
       "      <td>2.582</td>\n",
       "      <td>2.314</td>\n",
       "      <td>2.047</td>\n",
       "      <td>2.389</td>\n",
       "      <td>3.272</td>\n",
       "      <td>2.445</td>\n",
       "      <td>3.171</td>\n",
       "      <td>2.216</td>\n",
       "      <td>2.659</td>\n",
       "      <td>2.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2</td>\n",
       "      <td>2.240</td>\n",
       "      <td>2.150</td>\n",
       "      <td>1.995</td>\n",
       "      <td>2.254</td>\n",
       "      <td>2.164</td>\n",
       "      <td>2.008</td>\n",
       "      <td>2.298</td>\n",
       "      <td>1.918</td>\n",
       "      <td>1.717</td>\n",
       "      <td>...</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.288</td>\n",
       "      <td>2.395</td>\n",
       "      <td>2.105</td>\n",
       "      <td>3.267</td>\n",
       "      <td>2.257</td>\n",
       "      <td>3.231</td>\n",
       "      <td>2.574</td>\n",
       "      <td>2.920</td>\n",
       "      <td>2.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2</td>\n",
       "      <td>2.269</td>\n",
       "      <td>2.124</td>\n",
       "      <td>2.531</td>\n",
       "      <td>2.502</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.183</td>\n",
       "      <td>2.408</td>\n",
       "      <td>1.539</td>\n",
       "      <td>1.611</td>\n",
       "      <td>...</td>\n",
       "      <td>2.302</td>\n",
       "      <td>2.182</td>\n",
       "      <td>2.182</td>\n",
       "      <td>2.327</td>\n",
       "      <td>2.881</td>\n",
       "      <td>2.124</td>\n",
       "      <td>3.159</td>\n",
       "      <td>2.450</td>\n",
       "      <td>2.753</td>\n",
       "      <td>2.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.559</td>\n",
       "      <td>2.578</td>\n",
       "      <td>2.463</td>\n",
       "      <td>2.463</td>\n",
       "      <td>2.053</td>\n",
       "      <td>2.526</td>\n",
       "      <td>1.733</td>\n",
       "      <td>1.859</td>\n",
       "      <td>...</td>\n",
       "      <td>2.534</td>\n",
       "      <td>2.604</td>\n",
       "      <td>2.449</td>\n",
       "      <td>2.370</td>\n",
       "      <td>3.111</td>\n",
       "      <td>2.190</td>\n",
       "      <td>3.480</td>\n",
       "      <td>2.294</td>\n",
       "      <td>2.571</td>\n",
       "      <td>2.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2</td>\n",
       "      <td>1.940</td>\n",
       "      <td>2.438</td>\n",
       "      <td>2.272</td>\n",
       "      <td>2.272</td>\n",
       "      <td>2.610</td>\n",
       "      <td>2.099</td>\n",
       "      <td>2.538</td>\n",
       "      <td>1.931</td>\n",
       "      <td>1.792</td>\n",
       "      <td>...</td>\n",
       "      <td>2.638</td>\n",
       "      <td>2.225</td>\n",
       "      <td>2.013</td>\n",
       "      <td>2.115</td>\n",
       "      <td>3.853</td>\n",
       "      <td>2.231</td>\n",
       "      <td>3.187</td>\n",
       "      <td>2.510</td>\n",
       "      <td>2.759</td>\n",
       "      <td>2.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2</td>\n",
       "      <td>2.108</td>\n",
       "      <td>2.269</td>\n",
       "      <td>2.145</td>\n",
       "      <td>2.192</td>\n",
       "      <td>2.443</td>\n",
       "      <td>1.977</td>\n",
       "      <td>2.453</td>\n",
       "      <td>1.590</td>\n",
       "      <td>1.715</td>\n",
       "      <td>...</td>\n",
       "      <td>2.013</td>\n",
       "      <td>2.251</td>\n",
       "      <td>2.021</td>\n",
       "      <td>2.419</td>\n",
       "      <td>3.679</td>\n",
       "      <td>1.970</td>\n",
       "      <td>3.192</td>\n",
       "      <td>2.551</td>\n",
       "      <td>2.855</td>\n",
       "      <td>2.985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 309 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Group  lh_bankssts_part1_thickness  lh_bankssts_part2_thickness  \\\n",
       "0        1                        2.180                        2.382   \n",
       "1        1                        2.394                        1.973   \n",
       "2        1                        2.551                        2.567   \n",
       "3        2                        2.187                        1.923   \n",
       "4        2                        1.862                        1.750   \n",
       "..     ...                          ...                          ...   \n",
       "103      2                        2.240                        2.150   \n",
       "104      2                        2.269                        2.124   \n",
       "105      2                        2.273                        2.559   \n",
       "106      2                        1.940                        2.438   \n",
       "107      2                        2.108                        2.269   \n",
       "\n",
       "     lh_caudalanteriorcingulate_part1_thickness  \\\n",
       "0                                         2.346   \n",
       "1                                         2.534   \n",
       "2                                         1.954   \n",
       "3                                         2.160   \n",
       "4                                         2.129   \n",
       "..                                          ...   \n",
       "103                                       1.995   \n",
       "104                                       2.531   \n",
       "105                                       2.578   \n",
       "106                                       2.272   \n",
       "107                                       2.145   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part1_thickness  \\\n",
       "0                                     2.526   \n",
       "1                                     2.439   \n",
       "2                                     2.439   \n",
       "3                                     2.410   \n",
       "4                                     2.516   \n",
       "..                                      ...   \n",
       "103                                   2.254   \n",
       "104                                   2.502   \n",
       "105                                   2.463   \n",
       "106                                   2.272   \n",
       "107                                   2.192   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part2_thickness  \\\n",
       "0                                     2.747   \n",
       "1                                     2.485   \n",
       "2                                     2.428   \n",
       "3                                     2.381   \n",
       "4                                     2.244   \n",
       "..                                      ...   \n",
       "103                                   2.164   \n",
       "104                                   2.250   \n",
       "105                                   2.463   \n",
       "106                                   2.610   \n",
       "107                                   2.443   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part3_thickness  \\\n",
       "0                                     2.544   \n",
       "1                                     2.435   \n",
       "2                                     2.190   \n",
       "3                                     2.277   \n",
       "4                                     2.169   \n",
       "..                                      ...   \n",
       "103                                   2.008   \n",
       "104                                   2.183   \n",
       "105                                   2.053   \n",
       "106                                   2.099   \n",
       "107                                   1.977   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part4_thickness  lh_cuneus_part1_thickness  \\\n",
       "0                                     2.582                      1.816   \n",
       "1                                     2.458                      1.723   \n",
       "2                                     2.377                      2.026   \n",
       "3                                     2.361                      1.585   \n",
       "4                                     2.220                      1.646   \n",
       "..                                      ...                        ...   \n",
       "103                                   2.298                      1.918   \n",
       "104                                   2.408                      1.539   \n",
       "105                                   2.526                      1.733   \n",
       "106                                   2.538                      1.931   \n",
       "107                                   2.453                      1.590   \n",
       "\n",
       "     lh_cuneus_part2_thickness  ...  rh_supramarginal_part5_thickness  \\\n",
       "0                        2.228  ...                             2.817   \n",
       "1                        1.821  ...                             2.611   \n",
       "2                        1.800  ...                             2.777   \n",
       "3                        1.750  ...                             2.265   \n",
       "4                        1.717  ...                             2.582   \n",
       "..                         ...  ...                               ...   \n",
       "103                      1.717  ...                             2.273   \n",
       "104                      1.611  ...                             2.302   \n",
       "105                      1.859  ...                             2.534   \n",
       "106                      1.792  ...                             2.638   \n",
       "107                      1.715  ...                             2.013   \n",
       "\n",
       "     rh_supramarginal_part6_thickness  rh_supramarginal_part7_thickness  \\\n",
       "0                               2.325                             2.430   \n",
       "1                               2.418                             2.317   \n",
       "2                               2.309                             2.390   \n",
       "3                               2.306                             2.129   \n",
       "4                               2.314                             2.047   \n",
       "..                                ...                               ...   \n",
       "103                             2.288                             2.395   \n",
       "104                             2.182                             2.182   \n",
       "105                             2.604                             2.449   \n",
       "106                             2.225                             2.013   \n",
       "107                             2.251                             2.021   \n",
       "\n",
       "     rh_frontalpole_part1_thickness  rh_temporalpole_part1_thickness  \\\n",
       "0                             3.004                            3.979   \n",
       "1                             2.794                            3.851   \n",
       "2                             2.365                            4.039   \n",
       "3                             2.281                            3.505   \n",
       "4                             2.389                            3.272   \n",
       "..                              ...                              ...   \n",
       "103                           2.105                            3.267   \n",
       "104                           2.327                            2.881   \n",
       "105                           2.370                            3.111   \n",
       "106                           2.115                            3.853   \n",
       "107                           2.419                            3.679   \n",
       "\n",
       "     rh_transversetemporal_part1_thickness  rh_insula_part1_thickness  \\\n",
       "0                                    2.329                      3.620   \n",
       "1                                    2.034                      3.588   \n",
       "2                                    2.337                      3.657   \n",
       "3                                    2.275                      3.121   \n",
       "4                                    2.445                      3.171   \n",
       "..                                     ...                        ...   \n",
       "103                                  2.257                      3.231   \n",
       "104                                  2.124                      3.159   \n",
       "105                                  2.190                      3.480   \n",
       "106                                  2.231                      3.187   \n",
       "107                                  1.970                      3.192   \n",
       "\n",
       "     rh_insula_part2_thickness  rh_insula_part3_thickness  \\\n",
       "0                        2.776                      3.282   \n",
       "1                        2.654                      3.124   \n",
       "2                        2.495                      2.669   \n",
       "3                        2.333                      2.604   \n",
       "4                        2.216                      2.659   \n",
       "..                         ...                        ...   \n",
       "103                      2.574                      2.920   \n",
       "104                      2.450                      2.753   \n",
       "105                      2.294                      2.571   \n",
       "106                      2.510                      2.759   \n",
       "107                      2.551                      2.855   \n",
       "\n",
       "     rh_insula_part4_thickness  \n",
       "0                        3.347  \n",
       "1                        3.214  \n",
       "2                        2.886  \n",
       "3                        2.731  \n",
       "4                        2.657  \n",
       "..                         ...  \n",
       "103                      2.899  \n",
       "104                      2.791  \n",
       "105                      2.875  \n",
       "106                      2.838  \n",
       "107                      2.985  \n",
       "\n",
       "[108 rows x 309 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CT_Dublin_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074688be",
   "metadata": {},
   "source": [
    "As the dataframe shows, the Group variable contains information of whether the samples belong to control or patient. In this case, 1 indicates control and 2 patient. In order to perform a **Logistic Regression**, the labels of the outputs require to be 0 and 1 since the probability of an instance belonging to a default class is computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aca4d140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label group 1 as 0 and 2 as 1\n",
    "\n",
    "CT_Dublin_adj['Group'] = CT_Dublin_adj['Group'].replace([1,2],[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "408610ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>lh_bankssts_part1_thickness</th>\n",
       "      <th>lh_bankssts_part2_thickness</th>\n",
       "      <th>lh_caudalanteriorcingulate_part1_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part1_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part2_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part3_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part4_thickness</th>\n",
       "      <th>lh_cuneus_part1_thickness</th>\n",
       "      <th>lh_cuneus_part2_thickness</th>\n",
       "      <th>...</th>\n",
       "      <th>rh_supramarginal_part5_thickness</th>\n",
       "      <th>rh_supramarginal_part6_thickness</th>\n",
       "      <th>rh_supramarginal_part7_thickness</th>\n",
       "      <th>rh_frontalpole_part1_thickness</th>\n",
       "      <th>rh_temporalpole_part1_thickness</th>\n",
       "      <th>rh_transversetemporal_part1_thickness</th>\n",
       "      <th>rh_insula_part1_thickness</th>\n",
       "      <th>rh_insula_part2_thickness</th>\n",
       "      <th>rh_insula_part3_thickness</th>\n",
       "      <th>rh_insula_part4_thickness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.180</td>\n",
       "      <td>2.382</td>\n",
       "      <td>2.346</td>\n",
       "      <td>2.526</td>\n",
       "      <td>2.747</td>\n",
       "      <td>2.544</td>\n",
       "      <td>2.582</td>\n",
       "      <td>1.816</td>\n",
       "      <td>2.228</td>\n",
       "      <td>...</td>\n",
       "      <td>2.817</td>\n",
       "      <td>2.325</td>\n",
       "      <td>2.430</td>\n",
       "      <td>3.004</td>\n",
       "      <td>3.979</td>\n",
       "      <td>2.329</td>\n",
       "      <td>3.620</td>\n",
       "      <td>2.776</td>\n",
       "      <td>3.282</td>\n",
       "      <td>3.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2.394</td>\n",
       "      <td>1.973</td>\n",
       "      <td>2.534</td>\n",
       "      <td>2.439</td>\n",
       "      <td>2.485</td>\n",
       "      <td>2.435</td>\n",
       "      <td>2.458</td>\n",
       "      <td>1.723</td>\n",
       "      <td>1.821</td>\n",
       "      <td>...</td>\n",
       "      <td>2.611</td>\n",
       "      <td>2.418</td>\n",
       "      <td>2.317</td>\n",
       "      <td>2.794</td>\n",
       "      <td>3.851</td>\n",
       "      <td>2.034</td>\n",
       "      <td>3.588</td>\n",
       "      <td>2.654</td>\n",
       "      <td>3.124</td>\n",
       "      <td>3.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.551</td>\n",
       "      <td>2.567</td>\n",
       "      <td>1.954</td>\n",
       "      <td>2.439</td>\n",
       "      <td>2.428</td>\n",
       "      <td>2.190</td>\n",
       "      <td>2.377</td>\n",
       "      <td>2.026</td>\n",
       "      <td>1.800</td>\n",
       "      <td>...</td>\n",
       "      <td>2.777</td>\n",
       "      <td>2.309</td>\n",
       "      <td>2.390</td>\n",
       "      <td>2.365</td>\n",
       "      <td>4.039</td>\n",
       "      <td>2.337</td>\n",
       "      <td>3.657</td>\n",
       "      <td>2.495</td>\n",
       "      <td>2.669</td>\n",
       "      <td>2.886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.187</td>\n",
       "      <td>1.923</td>\n",
       "      <td>2.160</td>\n",
       "      <td>2.410</td>\n",
       "      <td>2.381</td>\n",
       "      <td>2.277</td>\n",
       "      <td>2.361</td>\n",
       "      <td>1.585</td>\n",
       "      <td>1.750</td>\n",
       "      <td>...</td>\n",
       "      <td>2.265</td>\n",
       "      <td>2.306</td>\n",
       "      <td>2.129</td>\n",
       "      <td>2.281</td>\n",
       "      <td>3.505</td>\n",
       "      <td>2.275</td>\n",
       "      <td>3.121</td>\n",
       "      <td>2.333</td>\n",
       "      <td>2.604</td>\n",
       "      <td>2.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.862</td>\n",
       "      <td>1.750</td>\n",
       "      <td>2.129</td>\n",
       "      <td>2.516</td>\n",
       "      <td>2.244</td>\n",
       "      <td>2.169</td>\n",
       "      <td>2.220</td>\n",
       "      <td>1.646</td>\n",
       "      <td>1.717</td>\n",
       "      <td>...</td>\n",
       "      <td>2.582</td>\n",
       "      <td>2.314</td>\n",
       "      <td>2.047</td>\n",
       "      <td>2.389</td>\n",
       "      <td>3.272</td>\n",
       "      <td>2.445</td>\n",
       "      <td>3.171</td>\n",
       "      <td>2.216</td>\n",
       "      <td>2.659</td>\n",
       "      <td>2.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1</td>\n",
       "      <td>2.240</td>\n",
       "      <td>2.150</td>\n",
       "      <td>1.995</td>\n",
       "      <td>2.254</td>\n",
       "      <td>2.164</td>\n",
       "      <td>2.008</td>\n",
       "      <td>2.298</td>\n",
       "      <td>1.918</td>\n",
       "      <td>1.717</td>\n",
       "      <td>...</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.288</td>\n",
       "      <td>2.395</td>\n",
       "      <td>2.105</td>\n",
       "      <td>3.267</td>\n",
       "      <td>2.257</td>\n",
       "      <td>3.231</td>\n",
       "      <td>2.574</td>\n",
       "      <td>2.920</td>\n",
       "      <td>2.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1</td>\n",
       "      <td>2.269</td>\n",
       "      <td>2.124</td>\n",
       "      <td>2.531</td>\n",
       "      <td>2.502</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.183</td>\n",
       "      <td>2.408</td>\n",
       "      <td>1.539</td>\n",
       "      <td>1.611</td>\n",
       "      <td>...</td>\n",
       "      <td>2.302</td>\n",
       "      <td>2.182</td>\n",
       "      <td>2.182</td>\n",
       "      <td>2.327</td>\n",
       "      <td>2.881</td>\n",
       "      <td>2.124</td>\n",
       "      <td>3.159</td>\n",
       "      <td>2.450</td>\n",
       "      <td>2.753</td>\n",
       "      <td>2.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.559</td>\n",
       "      <td>2.578</td>\n",
       "      <td>2.463</td>\n",
       "      <td>2.463</td>\n",
       "      <td>2.053</td>\n",
       "      <td>2.526</td>\n",
       "      <td>1.733</td>\n",
       "      <td>1.859</td>\n",
       "      <td>...</td>\n",
       "      <td>2.534</td>\n",
       "      <td>2.604</td>\n",
       "      <td>2.449</td>\n",
       "      <td>2.370</td>\n",
       "      <td>3.111</td>\n",
       "      <td>2.190</td>\n",
       "      <td>3.480</td>\n",
       "      <td>2.294</td>\n",
       "      <td>2.571</td>\n",
       "      <td>2.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1</td>\n",
       "      <td>1.940</td>\n",
       "      <td>2.438</td>\n",
       "      <td>2.272</td>\n",
       "      <td>2.272</td>\n",
       "      <td>2.610</td>\n",
       "      <td>2.099</td>\n",
       "      <td>2.538</td>\n",
       "      <td>1.931</td>\n",
       "      <td>1.792</td>\n",
       "      <td>...</td>\n",
       "      <td>2.638</td>\n",
       "      <td>2.225</td>\n",
       "      <td>2.013</td>\n",
       "      <td>2.115</td>\n",
       "      <td>3.853</td>\n",
       "      <td>2.231</td>\n",
       "      <td>3.187</td>\n",
       "      <td>2.510</td>\n",
       "      <td>2.759</td>\n",
       "      <td>2.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1</td>\n",
       "      <td>2.108</td>\n",
       "      <td>2.269</td>\n",
       "      <td>2.145</td>\n",
       "      <td>2.192</td>\n",
       "      <td>2.443</td>\n",
       "      <td>1.977</td>\n",
       "      <td>2.453</td>\n",
       "      <td>1.590</td>\n",
       "      <td>1.715</td>\n",
       "      <td>...</td>\n",
       "      <td>2.013</td>\n",
       "      <td>2.251</td>\n",
       "      <td>2.021</td>\n",
       "      <td>2.419</td>\n",
       "      <td>3.679</td>\n",
       "      <td>1.970</td>\n",
       "      <td>3.192</td>\n",
       "      <td>2.551</td>\n",
       "      <td>2.855</td>\n",
       "      <td>2.985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 309 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Group  lh_bankssts_part1_thickness  lh_bankssts_part2_thickness  \\\n",
       "0        0                        2.180                        2.382   \n",
       "1        0                        2.394                        1.973   \n",
       "2        0                        2.551                        2.567   \n",
       "3        1                        2.187                        1.923   \n",
       "4        1                        1.862                        1.750   \n",
       "..     ...                          ...                          ...   \n",
       "103      1                        2.240                        2.150   \n",
       "104      1                        2.269                        2.124   \n",
       "105      1                        2.273                        2.559   \n",
       "106      1                        1.940                        2.438   \n",
       "107      1                        2.108                        2.269   \n",
       "\n",
       "     lh_caudalanteriorcingulate_part1_thickness  \\\n",
       "0                                         2.346   \n",
       "1                                         2.534   \n",
       "2                                         1.954   \n",
       "3                                         2.160   \n",
       "4                                         2.129   \n",
       "..                                          ...   \n",
       "103                                       1.995   \n",
       "104                                       2.531   \n",
       "105                                       2.578   \n",
       "106                                       2.272   \n",
       "107                                       2.145   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part1_thickness  \\\n",
       "0                                     2.526   \n",
       "1                                     2.439   \n",
       "2                                     2.439   \n",
       "3                                     2.410   \n",
       "4                                     2.516   \n",
       "..                                      ...   \n",
       "103                                   2.254   \n",
       "104                                   2.502   \n",
       "105                                   2.463   \n",
       "106                                   2.272   \n",
       "107                                   2.192   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part2_thickness  \\\n",
       "0                                     2.747   \n",
       "1                                     2.485   \n",
       "2                                     2.428   \n",
       "3                                     2.381   \n",
       "4                                     2.244   \n",
       "..                                      ...   \n",
       "103                                   2.164   \n",
       "104                                   2.250   \n",
       "105                                   2.463   \n",
       "106                                   2.610   \n",
       "107                                   2.443   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part3_thickness  \\\n",
       "0                                     2.544   \n",
       "1                                     2.435   \n",
       "2                                     2.190   \n",
       "3                                     2.277   \n",
       "4                                     2.169   \n",
       "..                                      ...   \n",
       "103                                   2.008   \n",
       "104                                   2.183   \n",
       "105                                   2.053   \n",
       "106                                   2.099   \n",
       "107                                   1.977   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part4_thickness  lh_cuneus_part1_thickness  \\\n",
       "0                                     2.582                      1.816   \n",
       "1                                     2.458                      1.723   \n",
       "2                                     2.377                      2.026   \n",
       "3                                     2.361                      1.585   \n",
       "4                                     2.220                      1.646   \n",
       "..                                      ...                        ...   \n",
       "103                                   2.298                      1.918   \n",
       "104                                   2.408                      1.539   \n",
       "105                                   2.526                      1.733   \n",
       "106                                   2.538                      1.931   \n",
       "107                                   2.453                      1.590   \n",
       "\n",
       "     lh_cuneus_part2_thickness  ...  rh_supramarginal_part5_thickness  \\\n",
       "0                        2.228  ...                             2.817   \n",
       "1                        1.821  ...                             2.611   \n",
       "2                        1.800  ...                             2.777   \n",
       "3                        1.750  ...                             2.265   \n",
       "4                        1.717  ...                             2.582   \n",
       "..                         ...  ...                               ...   \n",
       "103                      1.717  ...                             2.273   \n",
       "104                      1.611  ...                             2.302   \n",
       "105                      1.859  ...                             2.534   \n",
       "106                      1.792  ...                             2.638   \n",
       "107                      1.715  ...                             2.013   \n",
       "\n",
       "     rh_supramarginal_part6_thickness  rh_supramarginal_part7_thickness  \\\n",
       "0                               2.325                             2.430   \n",
       "1                               2.418                             2.317   \n",
       "2                               2.309                             2.390   \n",
       "3                               2.306                             2.129   \n",
       "4                               2.314                             2.047   \n",
       "..                                ...                               ...   \n",
       "103                             2.288                             2.395   \n",
       "104                             2.182                             2.182   \n",
       "105                             2.604                             2.449   \n",
       "106                             2.225                             2.013   \n",
       "107                             2.251                             2.021   \n",
       "\n",
       "     rh_frontalpole_part1_thickness  rh_temporalpole_part1_thickness  \\\n",
       "0                             3.004                            3.979   \n",
       "1                             2.794                            3.851   \n",
       "2                             2.365                            4.039   \n",
       "3                             2.281                            3.505   \n",
       "4                             2.389                            3.272   \n",
       "..                              ...                              ...   \n",
       "103                           2.105                            3.267   \n",
       "104                           2.327                            2.881   \n",
       "105                           2.370                            3.111   \n",
       "106                           2.115                            3.853   \n",
       "107                           2.419                            3.679   \n",
       "\n",
       "     rh_transversetemporal_part1_thickness  rh_insula_part1_thickness  \\\n",
       "0                                    2.329                      3.620   \n",
       "1                                    2.034                      3.588   \n",
       "2                                    2.337                      3.657   \n",
       "3                                    2.275                      3.121   \n",
       "4                                    2.445                      3.171   \n",
       "..                                     ...                        ...   \n",
       "103                                  2.257                      3.231   \n",
       "104                                  2.124                      3.159   \n",
       "105                                  2.190                      3.480   \n",
       "106                                  2.231                      3.187   \n",
       "107                                  1.970                      3.192   \n",
       "\n",
       "     rh_insula_part2_thickness  rh_insula_part3_thickness  \\\n",
       "0                        2.776                      3.282   \n",
       "1                        2.654                      3.124   \n",
       "2                        2.495                      2.669   \n",
       "3                        2.333                      2.604   \n",
       "4                        2.216                      2.659   \n",
       "..                         ...                        ...   \n",
       "103                      2.574                      2.920   \n",
       "104                      2.450                      2.753   \n",
       "105                      2.294                      2.571   \n",
       "106                      2.510                      2.759   \n",
       "107                      2.551                      2.855   \n",
       "\n",
       "     rh_insula_part4_thickness  \n",
       "0                        3.347  \n",
       "1                        3.214  \n",
       "2                        2.886  \n",
       "3                        2.731  \n",
       "4                        2.657  \n",
       "..                         ...  \n",
       "103                      2.899  \n",
       "104                      2.791  \n",
       "105                      2.875  \n",
       "106                      2.838  \n",
       "107                      2.985  \n",
       "\n",
       "[108 rows x 309 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CT_Dublin_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "402f2a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 309)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get shape of df_adj\n",
    "\n",
    "CT_Dublin_adj.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3996d6",
   "metadata": {},
   "source": [
    "Because the LogisticRegression function from sklearn requires the inputs to be numpy arrays, in the following step the dataframe is converted to a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c20c482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 2.18 , 2.382, ..., 2.776, 3.282, 3.347],\n",
       "       [0.   , 2.394, 1.973, ..., 2.654, 3.124, 3.214],\n",
       "       [0.   , 2.551, 2.567, ..., 2.495, 2.669, 2.886],\n",
       "       ...,\n",
       "       [1.   , 2.273, 2.559, ..., 2.294, 2.571, 2.875],\n",
       "       [1.   , 1.94 , 2.438, ..., 2.51 , 2.759, 2.838],\n",
       "       [1.   , 2.108, 2.269, ..., 2.551, 2.855, 2.985]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe as numpy array \n",
    "\n",
    "CT_Dublin_adj.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5998c14a",
   "metadata": {},
   "source": [
    "### 2.1.2 Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e7df3f",
   "metadata": {},
   "source": [
    "In the next steps, the **logistic regression** model is built. Firstly, the input and output should be defined. Our input contains the **CT** for all of the 308 brain regions, meaning that there are n=308 features in total. The output is within the Group variable containing label information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "2cd70850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define input\n",
    "\n",
    "X = CT_Dublin_adj.iloc[:,1:309].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "4a858fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.18 , 2.382, 2.346, ..., 2.776, 3.282, 3.347],\n",
       "       [2.394, 1.973, 2.534, ..., 2.654, 3.124, 3.214],\n",
       "       [2.551, 2.567, 1.954, ..., 2.495, 2.669, 2.886],\n",
       "       ...,\n",
       "       [2.273, 2.559, 2.578, ..., 2.294, 2.571, 2.875],\n",
       "       [1.94 , 2.438, 2.272, ..., 2.51 , 2.759, 2.838],\n",
       "       [2.108, 2.269, 2.145, ..., 2.551, 2.855, 2.985]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "d44d0e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 308)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "aaa56b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output\n",
    "\n",
    "y = CT_Dublin_adj.iloc[:,[0]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "73f341d3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0d23e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4728103a",
   "metadata": {},
   "source": [
    "The numpy.ravel() functions returns contiguous flattened array (1D array with all the input-array elements and with the same type as it). This step is required for the upcoming analyses. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5377250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6401e42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108,)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cce2797",
   "metadata": {},
   "source": [
    "Now having defined our input and ouput data, to build the logistic regression model we need to split our data into train and test sets. For this, we use the train_test_split splitter function from Sklearn. The training set is the dataset on which the model is trained. This data is seen and learned by the model. The test set is a a subset of the training set and utilized for an accurate evaluation of a final model fit.\n",
    "With that function, the data gets divided into X_train, X_test, y_train and y_test. X_train and y_train are used for training and fitting the model. The X_test and y_test sets, however, are used for training the model if the correct labels were predicted. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e75fed4",
   "metadata": {},
   "source": [
    "But before splitting the data into training and testing set, we use the StandardScaler() function to standardize our data. The function standardizes every feature (each column) indivudally by substracting the mean and then scaling to unit variance (dividing all the values by the standard deviation). As a result, we get a distribution with a mean equal to 0 and with a standard deviation equal to 1. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7abf57",
   "metadata": {},
   "source": [
    "Also, with such a small sample, the N=27 participants (108 * 25%) in the testing sample could differ considerably from the training sample by chance. To tackle this problem, we can run the cross validation for multiple iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "090318e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter = 5000\n",
    "y_preds = []\n",
    "y_tests = []\n",
    "\n",
    "\n",
    "# scale before splitting into test and train samples\n",
    "X_sc = StandardScaler().fit_transform(X)\n",
    "\n",
    "for i in range(n_iter):\n",
    "    \n",
    "    # take a new testing and training sample\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X_sc, y, test_size = 0.25, random_state = i)\n",
    "    y_tests.append(y_test)  # store the y_test sample\n",
    " \n",
    "    \n",
    "    # fit the logistic regression\n",
    "    classifier = LogisticRegression(random_state = i, solver ='liblinear')\n",
    "    classifier.fit(X_train, y_train)\n",
    "    \n",
    "    # get the y predictions and store\n",
    "    y_pred = classifier.predict(X_test)\n",
    "    y_preds.append(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f821651",
   "metadata": {},
   "source": [
    "The test size indicates the size of the test subset, a random sampling without replacement about 75% of the rows , the remaining 25% is put into the test set. The random_state parameter allows you to reproduce the same train test split each time when the code is run. With a different value for random_state, different information would flow into the train and test sets. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c555676e",
   "metadata": {},
   "source": [
    "The following outputs show the first five lines of the iterations for our predicted y values and y testing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "1ce39e57",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
       "        1, 1, 0, 1, 0]),\n",
       " array([1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
       "        0, 1, 0, 1, 0]),\n",
       " array([1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1,\n",
       "        1, 1, 0, 1, 1]),\n",
       " array([1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 0, 0, 1]),\n",
       " array([1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 1])]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "c901050c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "        0, 1, 0, 1, 0]),\n",
       " array([1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "        0, 1, 0, 0, 0]),\n",
       " array([0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "        0, 1, 0, 1, 0]),\n",
       " array([1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0,\n",
       "        1, 0, 0, 0, 0]),\n",
       " array([0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 1])]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tests[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "390aa641",
   "metadata": {},
   "source": [
    "In the following, we can concatenate the the y_pred and y_test results from each iteration and use this to compute the confusion matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "1481ef01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 1])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_preds = np.concatenate([y_preds],axis =0)\n",
    "\n",
    "y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "eb27b859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 0, 0, ..., 0, 1, 0],\n",
       "       [1, 1, 1, ..., 0, 0, 0],\n",
       "       [0, 1, 0, ..., 0, 1, 0],\n",
       "       ...,\n",
       "       [0, 1, 0, ..., 0, 1, 0],\n",
       "       [0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 1, 0, ..., 1, 0, 1]])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tests = np.concatenate([y_tests],axis =0)\n",
    "y_tests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c3c65dc",
   "metadata": {},
   "source": [
    "We also concateante our X_tests values as it is needed for the **ROC** curve (see further below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f3356b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tests = np.concatenate([X_tests])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d487eed3",
   "metadata": {},
   "source": [
    "### 2.1.3 Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610c1784",
   "metadata": {},
   "source": [
    "In the next section, we will have a look at how the logistic regression model performs and evaluate it. To evaluate the model, a look at different measurements such as the **confusion matrix**, **accuracy, precision and recall** and the **receiver operation characteristic curve (ROC-curve)** is helpful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3534e34a",
   "metadata": {},
   "source": [
    "#### 2.1.3.1 Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f048bc1",
   "metadata": {},
   "source": [
    "The **confusion matrix** provides information on the quality of the logistic regression model since it shows the predicted values from the model compared to the actual values from the test dataset. We scale this by the sum of the array (i.e., cm/np.sum(cm)) to get probabilities for hits, misses, false positives and true negatives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "58f882a8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multilabel-indicator is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3m/1g132z9j3_14k03_9l9qv2wr0000gn/T/ipykernel_44403/1504234465.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcm_CT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tests\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mcm_CT_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcm_CT\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm_CT\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Confusion Matrix : \\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcm_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro_ai/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multilabel-indicator is not supported"
     ]
    }
   ],
   "source": [
    "cm_CT = confusion_matrix(y_tests, y_preds)\n",
    "\n",
    "cm_CT_f = cm_CT/np.sum(cm_CT)\n",
    "\n",
    "print(\"Confusion Matrix : \\n\", cm_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc49f766",
   "metadata": {},
   "source": [
    "To make the confusion matrix visually more appealing, we run the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "1eeac9d6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cm_CT_f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3m/1g132z9j3_14k03_9l9qv2wr0000gn/T/ipykernel_44403/2474941548.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtick_marks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myticks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtick_marks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm_CT_f\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mannot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"YlGnBu\"\u001b[0m \u001b[0;34m,\u001b[0m\u001b[0mfmt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'g'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_label_position\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"top\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtight_layout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'cm_CT_f' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_names=[0,1]\n",
    "\n",
    "fig, ax = plt.subplots() \n",
    "tick_marks = np.arange(len(class_names)) \n",
    "plt.xticks(tick_marks, class_names) \n",
    "plt.yticks(tick_marks, class_names) \n",
    "sns.heatmap(pd.DataFrame(cm_CT_f), annot=True, cmap=\"YlGnBu\" ,fmt='g') \n",
    "ax.xaxis.set_label_position(\"top\") \n",
    "plt.tight_layout() \n",
    "plt.title('Confusion Matrix for Cortical Thickness', y=1.1) \n",
    "plt.ylabel('Actual label') \n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02311028",
   "metadata": {},
   "source": [
    "The upper left square in the **confusion matrix** contains all the **true positive** cases meaning that when a participant predicted as control belongs to the control group (hits). Accordingly, the bottom right square carries information on **true negative** cases meaning a participant predicted as patient was a patient. On the contrary, the upper right square contains **false positives** cases (participant predicted as patient but was control) and the bottom left square contains information on **false negative** cases (misses, participant predicted as control but was patient)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d2c2dc",
   "metadata": {},
   "source": [
    "The confusion matrix shows us that the probability for **hits** is around 43%, for **true negatives** around 25%. The probability for **misses** is around 0.8%. The probability for **false positive** cases is around 31%. To get more insight on how the model performs, there are other measures indicating the qualtiy of the model such as **accuracy, precision, recall and F1-Score**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9103b861",
   "metadata": {},
   "source": [
    "#### 2.1.3.2 Model accuracy, precision and recall"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e17262e",
   "metadata": {},
   "source": [
    "The **accuracy** measure indicates the percentage of correct predictions. The **precision** measure shows the correct positive predictions relative to total positive predictions. The **recall** measure indicates the correct positive predictions relative to total actual positives. The **F1-Score** is a measure of a test’s accuracy — it is the harmonic mean of precision and recall. Overall, it is a measure of the preciseness and robustness of your model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "2eeec99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multilabel-indicator but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted', 'samples'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3m/1g132z9j3_14k03_9l9qv2wr0000gn/T/ipykernel_44403/673072659.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tests\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tests\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recall:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tests\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro_ai/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1763\u001b[0m         \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"precision\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1765\u001b[0;31m         \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1766\u001b[0m     )\n\u001b[1;32m   1767\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro_ai/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1544\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro_ai/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1365\u001b[0m             raise ValueError(\n\u001b[1;32m   1366\u001b[0m                 \u001b[0;34m\"Target is %s but average='binary'. Please \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m                 \u001b[0;34m\"choose another average setting, one of %r.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m             )\n\u001b[1;32m   1369\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multilabel-indicator but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted', 'samples']."
     ]
    }
   ],
   "source": [
    "#compute accuracy, precision, recall\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_tests, y_preds)) \n",
    "\n",
    "print(\"Precision:\",metrics.precision_score(y_tests, y_preds)) \n",
    "\n",
    "print(\"Recall:\",metrics.recall_score(y_tests, y_preds)) \n",
    "\n",
    "print(\"F1-Score:\", metrics.f1_score(y_tests, y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb4d817",
   "metadata": {},
   "source": [
    "#### 2.1.3.3 Receiver operating characteristic (ROC-Curve)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da232952",
   "metadata": {},
   "source": [
    "Another measure that provides information on the diagnostic ability of a binary classifier is a **Receiver Operator Characteristic (ROC) curve**. A ROC curve plots the true positiv rate (proportion of observations that were correctly predicted to be positive out of all positive observations) on the y-axis against the false positive rate (proportion of observations that are incorrectly predicted to be positiv out of all negative observations)on the x-axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "e4ba0b0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAEWCAYAAAB42tAoAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAA5bklEQVR4nO3deZxN9f/A8dfbLnvo95UlQhh7JiqJFhGJtEchlTYpWrQrfCXaFF+ppIXQLpQ2pUIMjZ1IYixZYmxZ5/3743NmXGPmzsXce+7ceT8fj/uYe/b3OTNz3/fz+Zzz+YiqYowxxmQmj98BGGOMiW6WKIwxxgRlicIYY0xQliiMMcYEZYnCGGNMUJYojDHGBGWJwpwQEVkiIi38jsNvIjJSRJ6M8DHHiMiASB4zXESkk4h8fYLb2t9ghIg9R5Hzicga4P+Aw8Bu4CvgXlXd7WdcsUZEugK3qeoFPscxBkhS1Sd8jqMfUE1VO0fgWGOIgnPOraxEETvaqWpRoAHQEHjU33COn4jky43H9pNdcxMKSxQxRlU3AdNwCQMAETlXRGaKyA4RWRBYXBeRU0XkbRHZICLbReSzgGVXiEiit91MEakXsGyNiFwqIqeLyL8icmrAsoYislVE8nvTt4rIMm//00TkjIB1VUTuEZGVwMqMzklErvSqGXaIyA8iUitdHI+KyFJv/2+LSKHjOIdHRGQhsEdE8olIXxH5Q0R2efu8ylu3FjASOE9EdovIDm9+WjWQiLQQkSQR6SMim0Vko4h0CzheaRH5QkR2ishcERkgIj9n9rsUkQsCfm/rvBJNqlIiMsWL81cRqRqw3Sve+jtFZJ6INAtY1k9EPhKR90VkJ9BVRBqLyCzvOBtF5DURKRCwTW0R+UZE/hGRv0XkMRFpDTwGXO9djwXeuiVE5C1vP+u9c8zrLesqIr+IyEsisg3o58372Vsu3rLNXuyLRKSOiNwBdAIe9o71RcDv71LvfV4vrtTf3TwRqZjZtTXHSVXtlcNfwBrgUu99BWAR8Io3XR7YBrTBfTFo6U2X9ZZPASYApYD8QHNvfkNgM9AEyAt08Y5TMINjfg/cHhDPEGCk9749sAqoBeQDngBmBqyrwDfAqUDhDM7tLGCPF3d+4GFvfwUC4lgMVPT28Qsw4DjOIdHbtrA371rgdO9aXe8du5y3rCvwc7r4xgQcrwVwCHjWi7UNsBco5S0f771OAeKAden3F7DfM4BdwI3evkoDDQKOuQ1o7F3TscD4gG07e+vnA/oAm4BC3rJ+wEGgg3eOhYFGwLne+pWBZcD93vrFgI3efgp5000C9vV+urg/BV4HigCnAXOAHgHX7xDQ0ztW4cBrCrQC5gElAcH9zZRLf50z+bt/CPd3X8Pbtj5Q2u//zVh5+R6AvbLhl+j+YXZ7HywKfAeU9JY9AryXbv1puA/NckBK6gdZunX+B/RPN28FRxJJ4D/pbcD33nvxPgAv9Ka/BLoH7CMP7sPzDG9agYuDnNuTwMR0268HWgTEcWfA8jbAH8dxDrdmcW0Tgfbe+7QPtYDlaR9guETxL5AvYPlm3IdwXtwHdI2AZQPS7y9g2aPAp5ksGwO8me6clwc5h+1Afe99P2BGFud8f+qxcYnqt0zW60dAosC1k+0nIOF7208PuH5r0+0j7ZoCFwO/e9crT2bXOd3fferf4IrU35O9sv9lVU+xo4OqFsN9WNUEynjzzwCu9aoVdnhVJhfgkkRF4B9V3Z7B/s4A+qTbriLu23Z6H+OqZMoBF+KSz08B+3klYB//4JJJ+YDt1wU5r9OBv1InVDXFWz+z7f8KiDGUczjq2CJyS0BV1Q6gDkeuZSi2qeqhgOm9QFGgLO5bdODxgp13ReCPIMs3ZXAMAETkQXFVfcneOZTg6HNIf85nichkEdnkVUf9N2D9rOIIdAau9LMx4Pq9jitZZHjsQKr6PfAaMBzYLCKjRKR4iMc+njjNcbJEEWNU9Ufct6+h3qx1uBJFyYBXEVV9zlt2qoiUzGBX64CB6bY7RVU/yOCY24GvcVU1N+GqQTRgPz3S7aewqs4M3EWQU9qA+wACXD027kNhfcA6gXXRlbxtQj2HtGOLazt5A7gXV21REletJSHEmZUtuGqXCpnEnd46oGqQ5Rny2iMeBq7DlRRLAskcOQc49jz+BywHqqtqcVzbQ+r664AzMzlc+v2sw5UoygRc7+KqWjvINkfvUHWYqjbCVc2dhatSynI7TvB6mdBYoohNLwMtRaQ+8D7QTkRaeQ1+hbxG1wqquhFXNTRCREqJSH4RudDbxxvAnSLSxGtkLCIibUWkWCbHHAfcAlzjvU81EnhURGpDWmPntcdxLhOBtiJyibjG8T64D6PARHOPiFQQ16D+OK7N5UTOoQjuA2mLF2s3XIki1d9AhcCG3lCp6mHgE1wD7ikiUhN3vTIzFrhURK4T18heWkQahHCoYriEtAXIJyJPAVl9Ky8G7AR2e3HdFbBsMlBORO4XkYIiUkxEmnjL/gYqi0ge7xw34r4wvCAixUUkj4hUFZHmIcSNiJzj/a7y49qG9uFKp6nHyixhAbwJ9BeR6t7vup6IlA7luCZrlihikKpuAd4FnlLVdbgG5cdwHx7rcN/SUn/3N+Pqzpfj6tPv9/aRANyOqwrYjmtA7hrksJOA6sAmVV0QEMunwGBgvFetsRi4/DjOZQWucfZVYCvQDncr8IGA1cbhPqBW46ofBpzIOajqUuAFYBbug6kurnE81ffAEmCTiGwN9RwC3IurBtoEvAd8gEt6GcWyFtf20AdXXZeIa6DNyjTcczS/46rh9hG8igvgQVxJcBcuuaYmWlR1F+5GgnZe3CuBi7zFH3o/t4nIfO/9LUABYCnumn+Eq+YMRXHv+Nu92LfhbowAeAuI86q0Pstg2xdxXyq+xiW9t3CN5SYb2AN3JkcT97Dhbar6rd+xHC8RGQz8R1W7+B2LMcFYicKYCBGRml6ViIhIY6A77nZSY6KaPRlpTOQUw1U3nY6r2noB+NzXiIwJgVU9GWOMCcqqnowxxgSV46qeypQpo5UrV/Y7DGOMyVHmzZu3VVXLnsi2OS5RVK5cmYSEBL/DMMaYHEVE/sp6rYxZ1ZMxxpigLFEYY4wJyhKFMcaYoCxRGGOMCcoShTHGmKAsURhjjAkqbIlCREZ7Y98uzmS5iMgwEVklIgtF5OxwxWKMMebEhbNEMQZoHWT55bhuqasDd+AGTzHGGBNlwvbAnarOEJHKQVZpD7zrjYQ2W0RKikg5b/ATEyXG/bqWzxPXZ72iMSb6qNI48UfOSfzxpHbj55PZ5Tl6QJUkb94xiUJE7sCVOqhUqVJEgjPO54nrWbpxJ3HlQh262BgTDcpu3Ui3CS/QaNFM/ipf7aT2lSO68FDVUcAogPj4eOvuNsLiyhVnQo/z/A7DGBMqVYiPh9Ur4IUXOOO++yB//hPenZ+JYj1HDy5fwZtnjDHmRMycCXXrQrFi8OabUKYMVKyY9XZZ8PP22EnALd7dT+cCydY+YYwxJ2DbNrj9dmjaFF54wc1r2DBbkgSEsUQhIh8ALYAyIpIEPA3kB1DVkcBU3ODxq4C9QLdwxWKMMTFJFd59Fx58ELZvh4cecq9sFs67nm7MYrkC94Tr+MYYE/MeeQSGDIHzz4eRI121UxjkiMZsY4wxnn//hT17XPtD9+5Qvbr7mSd8LQnWhYcxxuQUX30FdepAjx5uukYN1zYRxiQBliiMMSb6bdgA110Hl1/ubnO9996IHt6qnowxJpp99x1cdRUcOAD9+7vG6oIFIxqCJQpjjIlGBw+60kP9+tCmDQwYANVO7gnrE2VVT8YYE0127oRevaBZMzh82DVajx/vW5IASxTGGBMdVOHDD6FmTXj1VdcFx/79fkcFWNWTMcb4b8sW6NIFvvzSPVH9+edwzjl+R5XGShTGGOO34sVh61Z4+WWYMyeqkgRYojDGGH/MmAGtWsHu3e4uptmzXdtEvuir6LFEYYwxkbR1K3TrBs2bw++/w5o1bn6YH5o7GdEbmTHGxBJVGD3aPU39/vvw6KOwZIl70jrKRV8ZxxhjYtX770NcnOvAr3Ztv6MJmZUojDEmXPbuhSeegKQkEIGPP4Yff8xRSQIsURhjTHhMneoSwsCB8MUXbl6pUlHdFpGZnBexMcZEs6QkuOYaaNsWChd2JYi77vI7qpNiicIYY7LTwIEwZQr897+QmAgXXuh3RCfNGrONMeZkzZnjSg9167rO+x56CM480++oso2VKIwx5kQlJ8M998C558Ljj7t5pUvHVJIASxTGGHP8VF2PrjVrultde/Z0t77GKKt6MsaY4/X++3DLLa6H18mToVEjvyMKK0sUxhgTiv37YfVqqFXLDUt66JBLFnnz+h1Z2FnVkzHGZGX6dDfSXKtWLmEULOj6a8oFSQIsURhjTOY2b3alhosvdkOTjhoV8fGqo4FVPRljTEZWrYLGjV034I8/7l6FC/sdlS8sURhjTKCdO91AQlWrQvfucOutrl0iF7OqJ2OMAdizBx55BCpXPtKJ35AhuT5JgJUojDHGddp3772wdq0rRZxyit8RRRVLFMaY3OvQIXer66efup5ef/oJLrjA76iijlU9GWNyH1X3M18+KFcOnnsO5s+3JJEJSxTGmNxl9mz3RPX8+W56+HDXNlGggL9xRTFLFMaY3GH7djcuxPnnw99/u2kTkrAmChFpLSIrRGSViPTNYHklEZkuIr+JyEIRaRPOeIwxudSECa4Dv1Gj4P77YdkyuOQSv6PKMcLWmC0ieYHhQEsgCZgrIpNUdWnAak8AE1X1fyISB0wFKocrJmNMLrV8ubvt9auvoGFDv6PJccJZomgMrFLV1ap6ABgPtE+3jgLFvfclgA1hjMcYk1vs2wfPPHNkrOrHHoOZMy1JnKBwJorywLqA6SRvXqB+QGcRScKVJnpmtCMRuUNEEkQkYcuWLeGI1RgTK779FurVg3793HjVAPnz55oO/MLB78bsG4ExqloBaAO8JyLHxKSqo1Q1XlXjy5YtG/EgjTE5wN9/Q6dO0LKlu/31669h6FC/o4oJ4UwU64GKAdMVvHmBugMTAVR1FlAIKBPGmIwxseqbb+Cjj+Cpp2DRIpcwTLYIZ6KYC1QXkSoiUgC4AZiUbp21wCUAIlILlyisbskYE5oFC1xyAFeaWL7ctU0UKuRvXDEmbHc9qeohEbkXmAbkBUar6hIReRZIUNVJQB/gDRF5ANew3VU19ZHJ3Gfcr2v5PDF9octfSzfuJK5c8axXNCaSdu+Gp5+GV15xdzN16OCesq5Sxe/IYlJY+3pS1am4RurAeU8FvF8KNA1nDDnJ54nro+6DOa5ccdo3SH8PgjE++uwz6NnT9fB6xx0waJBLEiZs7OpGmbhyxZnQ4zy/wzAmOi1aBFddBXXruofozj/f74hyBb/vejLGmOAOHoTvv3fv69aFKVNg3jxLEhFkicIYE71mzoRGjdwdTKtWuXlt2rjnIkzEWKIwxkSff/5x7Q9Nm8KOHfDJJ1Ctmt9R5VrWRmGMiS779kGDBrBhA/Tp456wLlrU76hyNUsUxpjokJQEFSq4ZyD693fJon59v6MyWNWTMcZv//7rnqauWvVIJ35duliSiCJWojDG+Ofrr+Huu+GPP6BzZ2jc2O+ITAZCLlGIyCnhDMQYk8v07AmtWkGePK7H1/feg//7P7+jMhnIskQhIucDbwJFgUoiUh/ooap3hzs4Y0yMOXzY/cybF849F8qUceNVW99MUS2UEsVLQCtgG4CqLgAuDGdQxpgYNH8+nHcejBjhpjt1cv01WZKIeiFVPanqunSzDochFmNMLNq1Cx54AM45B9auhXLl/I7IHKdQGrPXedVPKiL5gV7AsvCGZYyJCV9/Dbfe6p6JuPNO+O9/oWRJv6MyxymURHEn8ApuGNP1wNeAtU8YY7JWoACcdhp8/DE0aeJ3NOYEhZIoaqhqp8AZItIU+CU8IRljcqyDB+HFF2HnThg4EFq0gIQEd2eTybFC+e29GuI8Y0xu9vPP0LAh9O0LK1dCSoqbb0kix8u0RCEi5wHnA2VFpHfAouK4EeuMMQa2bXO3uL71FlSq5J6uvuIKv6My2ShYqi+Ae3YiH1As4LUTuCb8oRljcoRt22D8eHj4YVi61JJEDMq0RKGqPwI/isgYVf0rgjEZY6LdsmUwcaJ7DuKss9xtr6ee6ndUJkxCaczeKyJDgNpA2pMxqnpx2KIyxkSnvXtdI/WQIa7r7+7dXY+vliRiWiitTGOB5UAV4BlgDTA3jDEZY6LRV19BnTruWYibboIVK1ySMDEvlBJFaVV9S0R6BVRHWaIwJjfZvRtuvhlKl4bp091trybXCKVEcdD7uVFE2opIQ8DKmcbEusOH4f333c+iRV0PrwsWWJLIhUIpUQwQkRJAH9zzE8WB+8MZlDHGZ/PmQY8e7mfhwnD11TaQUC6WZYlCVSerarKqLlbVi1S1EfBPBGIzxkRacjLcd58bQGj9enfba8eOfkdlfBbsgbu8wHW4Pp6+UtXFInIF8BhQGGgYmRCNMRFz9dXw/fdwzz0wYACUKOF3RCYKBKt6eguoCMwBhonIBiAe6Kuqn0UgNmNMJKxeDWXLQrFi7tbXPHlcl+DGeIIlinignqqmiEghYBNQVVW3RSY0Y0xYHTgAQ4dC//6uumnwYOvh1WQoWKI4oKopAKq6T0RWW5IwJkbMmOHGh1i2DK65xiUKYzIRLFHUFJGF3nsBqnrTAqiq1gt7dMaY7PfSS9C7N1SuDFOmQJs2fkdkolywRFErYlEYY8IrJQX27HHtEG3bwpYt8MQTcMopfkdmcoBgnQJaR4DGxIIlS1w1U+pIc2ed5brhMCZEYR1RRERai8gKEVklIn0zWec6EVkqIktEZFw44zEmV9m7Fx59FBo0cG0RV1wBqn5HZXKgUJ7MPiHecxjDgZZAEjBXRCap6tKAdaoDjwJNVXW7iJwWrniMyVV++809KLdmDXTrBs8/D2XK+B2VyaFCKlGISGERqXGc+24MrFLV1ap6ABgPtE+3zu3AcFXdDqCqm4/zGMaYQKklhkqV3OvHH2H0aEsS5qRkmShEpB2QCHzlTTcQkUkh7Ls8sC5gOsmbF+gs4CwR+UVEZotI65CiNsYc7dAhePlluOQS14lf6dIuSVx4od+RmRgQSomiH650sANAVRNxY1Nkh3xAdaAFcCPwhoiUTL+SiNwhIgkikrBly5ZsOrQxMWLOHNc30wMPQKFCsHOn3xGZGBNSN+OqmpxuXigtYutxXYCkquDNC5QETFLVg6r6J/A7LnEcfTDVUaoar6rxZcuWDeHQxuQCu3e7PpnOPRf+/hs+/NA9F1GqlN+RmRgTSqJYIiI3AXlFpLqIvArMDGG7uUB1EakiIgWAG4D0VVaf4UoTiEgZXFXU6hBjNyZ3y58ffvgBevY88oS1iN9RmRgUSqLoiRsvez8wDkgmhPEoVPUQcC8wDVgGTFTVJSLyrIhc6a02DdgmIkuB6cBD1k2IMUGsWgW33AK7dkHBgm68iFdegeLF/Y7MxLBQbo+tqaqPA48f785VdSowNd28pwLeK9DbexljMrN/v7vFdeBAKFAAbr8dmjVzbRLGhFkoJYoXRGSZiPQXkTphj8gYc7Tp093ock89BR06wPLlLkkYEyFZlihU9SIR+Q9uEKPXRaQ4MEFVB4Q9OmNyO1VXijh4EL76Clq18jsikwuF9MCdqm5S1WHAnbhnKp4KvoUx5oSlpMAbb8C6da5x+r33YPFiSxLGN1mWKESkFnA9cDWwDZgA9AlzXDnGuF/X8nli+rt+T8zSjTuJK2eNkrnawoWuA79Zs1xV0zPPQLlyfkdlcrlQShSjcQ/btVLVFqr6P+tq44jPE9ezdGP2POAUV6447Rukf3jd5Aq7d8NDD8HZZ8PKlTBmDPTr53dUxgChtVGcF4lAcrK4csWZ0MMukzkJ/frBCy/AbbfBc8+5LjiMiRKZJgoRmaiq14nIIo5+EttGuDMmO6xb5wYTqlkT+vZ1dzRdcIHfURlzjGAlil7ezysiEYgxucahQzBsmGuDaNTIdd5XpowlCRO1Mm2jUNWN3tu7VfWvwBdwd2TCMybGzJ4N8fHQpw+0aAHvvON3RMZkKZTG7JYZzLs8uwMxJuZNmQLnnw9bt8Inn8AXX0Dlyn5HZUyWgrVR3IUrOZwpIgsDFhUDfgl3YMbEBFXYsAHKl4dLL4Vnn4VevaBYMb8jMyZkwdooxgFfAoOAwPGud6nqP2GNyphY8PvvcPfd7ufSpVC0KDzxhN9RGXPcglU9qaquAe4BdgW8EJFTwx+aMTnUvn3udte6dSEhAR59FAoX9jsqY05YViWKK4B5uNtjAzu6V+DMMMZlTM60aZMbfnTlSrjxRnjxRfjPf/yOypiTkmmiUNUrvJ/ZNeypMbHr4EE3kND//Z9LFMOHQ8uM7gMxJufJ8q4nEWkqIkW8951F5EURqRT+0IzJAVJSYORIqFoVkpJcJ35vvmlJwsSUUG6P/R+wV0Tq4zoD/AN4L6xRGZMTLFjgbne96y6oXt2VKoyJQaEkikPeSHTtgddUdTjuFlljcidVePBB91T16tWuG/Bvv4UqVktrYlMoQ6HuEpFHgZuBZiKSB8gf3rCMiWIisH07dO/uOvArVcrviIwJq1BKFNcD+4FbVXUTUAEYEtaojIk2f/3lOu2bP99Nv/EGvP66JQmTK2SZKLzkMBYoISJXAPtU9d2wR2ZMNDh4EJ5/HuLi4JtvYMUKNz9PSINDGhMTQrnr6TpgDnAtbtzsX0XkmnAHZozvZs50Awk98oi7i2nZMvdshDG5TChtFI8D56SOaiciZYFvgY/CGZgxvvv2W0hOhs8+g/bt/Y7GGN+EUn7Ok27o020hbmdMzqIK774LX37pph95xPXRZEnC5HKhfOB/JSLTRKSriHQFpgBTwxuWMRG2fDlcfDF06QJvv+3mFSzoOvIzJpcLpTH7IeB1oJ73GqWqj4Q7MGMi4t9/4cknoV49SEx0dzKNH+93VMZElWDjUVQHhgJVgUXAg6q6PlKBGRMRX3wBAwZA584wdKjrq8kYc5RgJYrRwGTgalwPsq9GJCJjwm3TJvjqK/f+2mvh11/d09WWJIzJULC7noqp6hve+xUiMj8SARkTNocPu6qlRx+FAgVg7Vo3TkTjxn5HZkxUC5YoColIQ46MQ1E4cFpVLXGYnGP+fLjzTpg71w1JOmKEDSZkTIiCJYqNwIsB05sCphW4OFxBGZOt/vzTlRrKlIFx4+CGG1x/TcaYkAQbuOiiSAZiTLZShUWL3N1MVaq4W17btYOSJf2OzJgcxx6cM7Hnzz/hiiugYUNYuNDNu/lmSxLGnKCwJgoRaS0iK0RklYj0DbLe1SKiIhIfznhMjDtwwHX7Xbs2/Piju901Ls7vqIzJ8ULp6+mEiEheYDjQEkgC5orIJFVdmm69YkAv4NdwxWJygcOH3Whz8+ZBx47w8stQsaLfURkTE0LpPVa8sbKf8qYriUgo9xM2Blap6mpVPQCMx42Sl15/YDCw7zjiNsbZudP9zJsXbr3VPUD38ceWJIzJRqFUPY0AzgNS+1fehSspZKU8sC5gOsmbl0ZEzgYqquqUYDsSkTtEJEFEErZs2RLCoU3MU4UxY+DMM+Hzz928u+92bRPGmGwVSqJooqr34H3jV9XtQIGTPbA3pOqLQJ+s1lXVUaoar6rxZcuWPdlDm5xu6VJo0QK6dYOaNaFqVb8jMiamhZIoDnrtDQpp41GkhLDdeiCw/F/Bm5eqGFAH+EFE1gDnApOsQdsE9fzzUL8+LF4Mb74JM2ZAnTp+R2VMTAslUQwDPgVOE5GBwM/Af0PYbi5QXUSqiEgB4AZgUupCVU1W1TKqWllVKwOzgStVNeF4T8LkAqru53/+A506uW7Bu3e3IUmNiYAs73pS1bEiMg+4BNd9RwdVXRbCdodE5F5gGpAXGK2qS0TkWSBBVScF34MxwIYN0KsXNGsG990Ht9ziXsaYiMkyUYhIJWAv8EXgPFVdm9W2qjqVdIMcqepTmazbIqv9mVzk8GHXH9Pjj8PBg+7WV2OML0J5jmIKrn1CgEJAFWAFUDuMcZncLDERbrvNPRNx2WUuYViDtTG+CaXqqW7gtHdL691hi8iY5GRX5TRhghsvwjrwM8ZXx/1ktqrOF5Em4QjG5FKq8OGHsHKlq2pq3hxWr4ZChfyOzBhDaG0UvQMm8wBnAxvCFpHJXf74A+691404d8458PDDkD+/JQljokgo9xYWC3gVxLVZZNQVhzGh278fBg50z0D88gu88grMnOmShDEmqgQtUXgP2hVT1QcjFI/JLdatg/793RgRL78M5ctnuYkxxh+ZlihEJJ+qHgaaRjAeE8u2bIHXXnPvq1VzXXF8+KElCWOiXLASxRxce0SiiEwCPgT2pC5U1U/CHJuJFSkpboS5hx+GXbugZUuoUcN16GeMiXqhtFEUArbhxsi+Amjn/TQma4sXu7uYbrvNDSiUmOiShDEmxwhWojjNu+NpMUceuEulYY3KxIYDB9wDcwcOwOjR0LWrPRNhTA4ULFHkBYpydIJIZYnCZO77710pokABmDjRdQVepozfURljTlCwRLFRVZ+NWCQm50tKch34ffKJK0F06wYXXOB3VMaYkxSsjcLqCExoDh1yt7jWqgVffgmDBrmuwI0xMSFYieKSiEVhcrabb4bx4+Hyy2H4cKhSxe+IjDHZKNNEoar/RDIQk8Ps2AH58kHRonDPPXD11e5ljdXGxBwbHswcH1VXeqhVC5580s274AK45hpLEsbEKEsUJnSrVkGrVnDjjVChAnTu7HdExpgIsERhQjNunOvA79dfXTccs2dDo0Z+R2WMiYDjHo/C5DIHD7oeXePjXfXS88/D6af7HZUxJoKsRGEytnmzu5vp+uvd9FlnwfvvW5IwJheyRGGOlpICo0a5/pgmTHD9Mx0+7HdUxhgfWdWTOWL1atdAPWsWtGgB//uf637DGJOrWaIwR5Qo4Z6PeOcdV+1kt7saY7CqJzNpEnTs6KqXSpd23YLfcoslCWNMGksUudXatdChA7RvD7//Dhs3uvl57E/CGHM0+1TIbQ4dgqFD3ZPVX38NgwfDb7+5B+iMMSYD1kaR2xw+DG++CRdfDK++CpUr+x2RMSbKWYkiN9i+HR55xI1XXbAg/PKLa5uwJGGMCYElilimCmPHultcX3gBpk9380uXtsZqY0zILFHEqt9/h5Yt3XMRlStDQgJceaXfURljcqBc20Yx7te1fJ64/qT3s3TjTuLKFc+GiLLZ/fe75DBiBNxxB+TN63dExpgcKtcmis8T12fLh3xcueK0b1A+m6I6Sd9846qZKlZ0T1UXLAj/+Y/fURljcriwJgoRaQ28AuQF3lTV59It7w3cBhwCtgC3qupf4YwpUFy54kzocV6kDhc+mzZB797wwQdutLnXXoMzzvA7KmNMjAhbG4WI5AWGA5cDccCNIhKXbrXfgHhVrQd8BDwfrnhiUkoKjBzpShEffwxPP+2ekTDGmGwUzsbsxsAqVV2tqgeA8UD7wBVUdbqq7vUmZwP21NfxGDQI7rrLDSC0cCH06weFCvkdlTEmxoSz6qk8sC5gOgloEmT97sCXGS0QkTuAOwAqVaqUXfHlTLt2wdatUKUK3Hmn+3njjXa7qzEmbKLi9lgR6QzEA0MyWq6qo1Q1XlXjy5YtG9ngooUqfPopxMW5wYRU3fMQN91kScIYE1bhTBTrgYoB0xW8eUcRkUuBx4ErVXV/GOPJuf76yz0D0bEjnHoqDBtmycEYEzHhrHqaC1QXkSq4BHEDcFPgCiLSEHgdaK2qm8MYS841axZceql7P3Qo9OoF+XLtXc3GGB+ErUShqoeAe4FpwDJgoqouEZFnRST1EeEhQFHgQxFJFJFJ4Yonx9m50/08+2y49VZYtgz69LEkYYyJuLB+6qjqVGBqunlPBby/NJzHz5G2bYO+fV0X4EuWQNGirpdXY4zxSVQ0Zhtc4/S777pnIt5+2zVYWzuEMSYKWD1GNEhOdqPN/fADnHeee4iuXj2/ozLGGMAShb9UXamheHEoUwZGjYLu3W04UmNMVLFPJL9Mm+YaqpOSXLL48EO4/XZLEsaYqGOfSpG2cSPccAO0bg1798JmuyvYGBPdLFFE0vDhrrH6s8/gmWdc/0xnn+13VMYYE5S1UUTSvHnQpIlLGNWr+x2NMcaExEoU4bRzpxtpbt48Nz1ihGubsCRhjMlBLFGEgyp89BHUquX6ZfrxRze/UCF7NsIYk+NYoshuf/4JV1wB114Lp53m+mrq3dvvqIwx5oRZoshuY8fCjBnw0kswd65rkzDGmBzMGrOzw08/wf79rpfXhx6Crl2hgg3WZ4yJDVaiOBlbt7qeXS+8EJ591s0rWNCShDEmpliJ4kSowpgxrvSQnAyPPAJPPul3VLnCwYMHSUpKYt++fX6HYkxUKlSoEBUqVCB//vzZtk9LFCdi6lRXkmja1HXgV6eO3xHlGklJSRQrVozKlSsjdgeZMUdRVbZt20ZSUhJVqlTJtv1a1VOo9u6FX35x79u0gc8/d43WliQiat++fZQuXdqShDEZEBFKly6d7SVuSxSh+PJLlxAuvxx27HDPQlx5pXXg5xNLEsZkLhz/H/ZJF8z69e55iDZtXCP1F19AyZJ+R2WMMRFliSIzmzdDXBxMngwDBsCCBdC8ud9RmShQtGjRk95HQkIC9913X6bL16xZw7hx40JeP70WLVpQo0YN6tevzznnnENiYuLJhJutJk2axHPPPZct+/r3339p3rw5hw8fzpb9hcOgQYOoVq0aNWrUYNq0aRmu06xZMxo0aECDBg04/fTT6dChAwDJycm0a9eO+vXrU7t2bd5++20AtmzZQuvWrSN1Cq7xIye9GjVqpNnhupEz9bqRM49dkJR05P0rr6iuWpUtxzPZY+nSpX6HoEWKFAn7MaZPn65t27Y94e2bN2+uc+fOVVXV0aNH66WXXpotcR06dChb9pNdXnvtNX355ZdDXj8lJUUPHz4cxoiOtmTJEq1Xr57u27dPV69erWeeeWaW17Bjx476zjvvqKrqwIED9eGHH1ZV1c2bN2upUqV0//79qqratWtX/fnnnzPcR0b/J0CCnuDnrt31lCo5GZ54Al5/HWbPdt1/H8c3OBN5z3yxhKUbdmbrPuNOL87T7Wof93aJiYnceeed7N27l6pVqzJ69GhKlSrF3Llz6d69O3ny5KFly5Z8+eWXLF68mB9++IGhQ4cyefJkfvzxR3r16gW4+uUZM2bQt29fli1bRoMGDejSpQsNGzZMW3/37t307NmThIQERISnn36aq6++OtPYzjvvPIYMGQLAnj176NmzJ4sXL+bgwYP069eP9u3bs3fvXrp27crixYupUaMGGzZsYPjw4cTHx1O0aFF69OjBt99+y/Dhw1mzZg3Dhg3jwIEDNGnShBEjRgDQvXv3tJhuvfVWHnjgAYYNG8bIkSPJly8fcXFxjB8/njFjxpCQkMBrr73GmjVruPXWW9m6dStly5bl7bffplKlSnTt2pXixYuTkJDApk2beP7557nmmmuOObexY8emlbx2795N+/bt2b59OwcPHmTAgAG0b9+eNWvW0KpVK5o0acK8efOYOnUqEydOZOLEiezfv5+rrrqKZ555BoAOHTqwbt069u3bR69evbjjjjuO+28h0Oeff84NN9xAwYIFqVKlCtWqVWPOnDmcd955Ga6/c+dOvv/++7SSg4iwa9cuVJXdu3dz6qmnki9fvrRYx44dS9OmTU8qxlBY1ZMqTJzoOvAbPhzuvBOqVvU7KpPD3HLLLQwePJiFCxdSt27dtA+ebt268frrr5OYmEjevHkz3Hbo0KEMHz6cxMREfvrpJwoXLsxzzz1Hs2bNSExM5IEHHjhq/f79+1OiRAkWLVrEwoULufjii4PG9tVXX6VVZQwcOJCLL76YOXPmMH36dB566CH27NnDiBEjKFWqFEuXLqV///7MS+3xGJdcmjRpwoIFCyhdujQTJkzgl19+STunsWPHkpiYyPr161m8eDGLFi2iW7duADz33HP89ttvLFy4kJEjRx4TW8+ePenSpQsLFy6kU6dOR1Wvbdy4kZ9//pnJkyfTt2/fY7Y9cOAAq1evpnLlyoB7fuDTTz9l/vz5TJ8+nT59+uC+SMPKlSu5++67WbJkCStWrGDlypXMmTOHxMRE5s2bx4wZMwAYPXo08+bNIyEhgWHDhrFt27ZjjvvAAw+kVRMFvjKqTlu/fj0VK1ZMm65QoQLr16/P9Hf12Wefcckll1C8eHEA7r33XpYtW8bpp59O3bp1eeWVV8jj3UQTHx/PTz/9lOm+slPuLlGoQseObiChs8+GSZMgPt7vqEyITuSbfzgkJyezY8cOmnttWF26dOHaa69lx44d7Nq1K+3b40033cTkyZOP2b5p06b07t2bTp060bFjRypk8WT/t99+y/jx49OmS5UqleF6nTp14sCBA+zevTutjeLrr79m0qRJDB06FHC3G69du5aff/45rVRTp04d6tWrl7afvHnzppVYvvvuO+bNm8c555wDuDaC0047jXbt2rF69Wp69uxJ27ZtueyyywCoV68enTp1okOHDmnJKtCsWbP45JNPALj55pt5+OGH05Z16NCBPHnyEBcXx99//33Mtlu3bqVkwM0lqspjjz3GjBkzyJMnD+vXr0/b7owzzuDcc89NuwZff/01DRs2BFxJZOXKlVx44YUMGzaMTz/9FIB169axcuVKSpcufdRxX3rppQyvd3b44IMPuO2229Kmp02bRoMGDfj+++/5448/aNmyJc2aNaN48eKcdtppbNiwIWyxBMqdieLgQfdTBC64AC6+GO6+GzL5xmdMOPXt25e2bdsydepUmjZtmmmD5/EaO3YsjRo14qGHHqJnz5588sknqCoff/wxNWrUCHk/hQoVSisNqSpdunRh0KBBx6y3YMECpk2bxsiRI5k4cSKjR49mypQpzJgxgy+++IKBAweyaNGikI9bsGDBtPepJYNAhQsXPup5gbFjx7JlyxbmzZtH/vz5qVy5ctryIkWKHLWvRx99lB49ehy1vx9++IFvv/2WWbNmccopp9CiRYsMn0d44IEHmD59+jHzb7jhhmNKPuXLl2fdunVp00lJSZQvXz7D8926dStz5sxJS1QAb7/9Nn379kVEqFatGlWqVGH58uU0btyYffv2Ubhw4Qz3ld1yX9XTDz9AvXrEJ7qiJn36QM+eliTMCStRogSlSpVKqwZ47733aN68OSVLlqRYsWL8+uuvAEeVAgL98ccf1K1bl0ceeYRzzjmH5cuXU6xYMXbt2pXh+i1btmT48OFp09u3b880NhGhf//+zJ49m+XLl9OqVSteffXVtA/e3377DXClmokTJwKwdOnSTD/QL7nkEj766CM2e2O9//PPP/z1119s3bqVlJQUrr76agYMGMD8+fNJSUlh3bp1XHTRRQwePJjk5GR279591P7OP//8tOsyduxYmjVrlum5pFeqVCkOHz6c9mGenJzMaaedRv78+Zk+fTp//fVXhtu1atWK0aNHp8Wyfv16Nm/eTHJyMqVKleKUU05h+fLlzJ49O8PtX3rpJRITE495ZVQ9duWVVzJ+/Hj279/Pn3/+ycqVK2ncuHGG+/3oo4+44oorKFSoUNq8SpUq8d133wHw999/s2LFCs4880wAfv/9d+pE6IHf3FOi2LIFHnwQ3n0XqlTh30Kn+B2RyaH27t17VPVQ7969eeedd9Ias88888y0xsi33nqL22+/nTx58tC8eXNKlChxzP5efvllpk+fTp48eahduzaXX345efLkIW/evNSvX5+uXbumVZMAPPHEE9xzzz3UqVOHvHnz8vTTT9OxY8dM4y1cuDB9+vRhyJAhvPbaa9x///3Uq1ePlJQUqlSpwuTJk7n77rvp0qULcXFx1KxZk9q1a2cYa1xcHAMGDOCyyy4jJSWF/PnzM3z4cAoXLky3bt1ISUkB3C2hhw8fpnPnziQnJ6Oq3HfffUdVFQG8+uqrdOvWjSFDhqQ1Zh+Pyy67jJ9//plLL72UTp060a5dO+rWrUt8fDw1a9bMdJtly5alVQkWLVqU999/n9atWzNy5Ehq1apFjRo10qqqTkbt2rW57rrriIuLI1++fAwfPjytdNamTRvefPNNTj/9dMB9kUifbJ588km6du1K3bp1UVUGDx5MmTJlAJg+fTpt27Y96RhDcqK3S/n1OqHbY8eNUy1VSjV/ftXHHlPdsyfz22NNVIuG22OPx65du9LeDxo0SO+77z4fo8ncoUOH9N9//1VV1VWrVmnlypXTbsOMZvPmzdPOnTv7HYYvmjVrpv/880+Gy+z22BNx6JDrgmPkSPcQnTERMmXKFAYNGsShQ4c444wzGDNmjN8hZWjv3r1cdNFFHDx4EFVlxIgRFChQwO+wsnT22Wdz0UUXcfjw4UzvKotFW7ZsoXfv3pneyJDdRDNoJIpm8fHxmpCQEHylPXugf3+oVMk1UqeeY0AfKNe/PguACT0yvp/ZRKdly5ZRq1Ytv8MwJqpl9H8iIvNU9YRu64y9xuzJk6F2bRg8GH7/3c0TOSpJmJwtp325MSaSwvH/ETuJIinJPRPRrh0UKeK6AH/5Zb+jMtmsUKFCbNu2zZKFMRlQdeNRBN45lR1ip41i9WqYNg0GDYLevSEH1K+a41ehQgWSkpLYsmWL36EYE5VSR7jLTjk7UcyZA7NmQa9ebtzqtWsh3VOUJrbkz58/W0fuMsZkLaxVTyLSWkRWiMgqETnmaRQRKSgiE7zlv4pI5ZB2vGOHa6Q+91x48UXXeA2WJIwxJgzClihEJC8wHLgciANuFJH096Z2B7arajXgJWBwljv+5x+oWdP18nrffbBokWuTMMYYExbhrHpqDKxS1dUAIjIeaA8sDVinPdDPe/8R8JqIiAZpqdQ/1/DHGTV4o+9z/FmpBnyw5ISCW7pxJ3Hlip/QtsYYk5uEM1GUB9YFTCcBTTJbR1UPiUgyUBrYGriSiNwBpHYMv7/aX8sX899uJx3gYmDinSe9Gz+VId21ysXsWhxh1+IIuxZHhN4TZDo5ojFbVUcBowBEJOFEHxqJNXYtjrBrcYRdiyPsWhwhIlk8qZy5cDZmrwcqBkxX8OZluI6I5ANKAMeOFGKMMcY34UwUc4HqIlJFRAoANwCT0q0zCejivb8G+D5Y+4QxxpjIC1vVk9fmcC8wDcgLjFbVJSLyLK4Xw0nAW8B7IrIK+AeXTLIyKlwx50B2LY6wa3GEXYsj7FocccLXIsd1CmiMMSayYqevJ2OMMWFhicIYY0xQUZsowtb9Rw4UwrXoLSJLRWShiHwnImf4EWckZHUtAta7WkRURGL21shQroWIXOf9bSwRkXGRjjFSQvgfqSQi00XkN+//pI0fcYabiIwWkc0isjiT5SIiw7zrtFBEzg5pxyc6NF44X7jG7z+AM4ECwAIgLt06dwMjvfc3ABP8jtvHa3ERcIr3/q7cfC289YoBM4DZQLzfcfv4d1Ed+A0o5U2f5nfcPl6LUcBd3vs4YI3fcYfpWlwInA0szmR5G+BLQIBzgV9D2W+0lijSuv9Q1QNAavcfgdoD73jvPwIuEYnJ0YmyvBaqOl1V93qTs3HPrMSiUP4uAPrj+g3bF8ngIiyUa3E7MFxVtwOo6uYIxxgpoVwLBVL77CkBbIhgfBGjqjNwd5Bmpj3wrjqzgZIiUi6r/UZrosio+4/yma2jqoeA1O4/Yk0o1yJQd9w3hliU5bXwitIVVXVKJAPzQSh/F2cBZ4nILyIyW0RaRyy6yArlWvQDOotIEjAV6BmZ0KLO8X6eADmkCw8TGhHpDMQDzf2OxQ8ikgd4EejqcyjRIh+u+qkFrpQ5Q0TqquoOP4PyyY3AGFV9QUTOwz2/VUdVU/wOLCeI1hKFdf9xRCjXAhG5FHgcuFJV90cotkjL6loUA+oAP4jIGlwd7KQYbdAO5e8iCZikqgdV9U/gd1ziiDWhXIvuwEQAVZ0FFMJ1GJjbhPR5kl60Jgrr/uOILK+FiDQEXscliVith4YsroWqJqtqGVWtrKqVce01V6rqCXeGFsVC+R/5DFeaQETK4KqiVkcwxkgJ5VqsBS4BEJFauESRG8fTnQTc4t39dC6QrKobs9ooKqueNHzdf+Q4IV6LIUBR4EOvPX+tql7pW9BhEuK1yBVCvBbTgMtEZClwGHhIVWOu1B3itegDvCEiD+AatrvG4hdLEfkA9+WgjNce8zSQH0BVR+LaZ9oAq4C9QEjjNVgXHsYYY4KK1qonY4wxUcIShTHGmKAsURhjjAnKEoUxxpigLFEYY4wJyhKFiUoiclhEEgNelYOsuzsbjjdGRP70jjXfe3r3ePfxpojEee8fS7ds5snG6O0n9bosFpEvRKRkFus3iNWeUk3k2O2xJiqJyG5VLZrd6wbZxxhgsqp+JCKXAUNVtd5J7O+kY8pqvyLyDvC7qg4Msn5XXA+692Z3LCb3sBKFyRFEpKg31sZ8EVkkIsf0Gisi5URkRsA37mbe/MtEZJa37YciktUH+Aygmrdtb29fi0Xkfm9eERGZIiILvPnXe/N/EJF4EXkOKOzFMdZbttv7OV5E2gbEPEZErhGRvCIyRETmeuME9AjhsszC69BNRBp75/ibiMwUkRreU8rPAtd7sVzvxT5aROZ462bU+64xR/O7/3R72SujF+5J4kTv9SmuF4Hi3rIyuCdLU0vEu72ffYDHvfd5cX0/lcF98Bfx5j8CPJXB8cYA13jvrwV+BRoBi4AiuCfflwANgauBNwK2LeH9/AFv/IvUmALWSY3xKuAd730BXE+ehYE7gCe8+QWBBKBKBnHuDji/D4HW3nRxIJ/3/lLgY+99V+C1gO3/C3T23pfE9f9UxO/ft72i+xWVXXgYA/yrqg1SJ0QkP/BfEbkQSMF9k/4/YFPANnOB0d66n6lqoog0xw1U84vXvUkB3DfxjAwRkSdwfQB1x/UN9Kmq7vFi+ARoBnwFvCAig3HVVT8dx3l9CbwiIgWB1sAMVf3Xq+6qJyLXeOuVwHXg92e67QuLSKJ3/suAbwLWf0dEquO6qMifyfEvA64UkQe96UJAJW9fxmTIEoXJKToBZYFGqnpQXO+whQJXUNUZXiJpC4wRkReB7cA3qnpjCMd4SFU/Sp0QkUsyWklVfxc37kUbYICIfKeqz4ZyEqq6T0R+AFoB1+MG2QE34lhPVZ2WxS7+VdUGInIKrm+je4BhuMGapqvqVV7D/w+ZbC/A1aq6IpR4jQFrozA5Rwlgs5ckLgKOGRdc3Fjhf6vqG8CbuCEhZwNNRSS1zaGIiJwV4jF/AjqIyCkiUgRXbfSTiJwO7FXV93EdMmY07vBBr2STkQm4zthSSyfgPvTvSt1GRM7yjpkhdSMa3gf0kSPd7Kd2F901YNVduCq4VNOAnuIVr8T1PGxMUJYoTE4xFogXkUXALcDyDNZpASwQkd9w39ZfUdUtuA/OD0RkIa7aqWYoB1TV+bi2izm4Nos3VfU3oC4wx6sCehoYkMHmo4CFqY3Z6XyNG1zqW3VDd4JLbEuB+SKyGNdtfNASvxfLQtygPM8Dg7xzD9xuOhCX2piNK3nk92Jb4k0bE5TdHmuMMSYoK1EYY4wJyhKFMcaYoCxRGGOMCcoShTHGmKAsURhjjAnKEoUxxpigLFEYY4wJ6v8B8VGQseRvwUsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "logit_roc_auc = roc_auc_score(y_test, classifier.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, classifier.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da090e03",
   "metadata": {},
   "source": [
    "Curves closer to the top-left corner indicate a better performance of the classifier. The closer the curve comes to the 45-degree diagonal of the ROC space, the less acurate the classifier is. As the plot shows, our model does not perform very well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3ab202",
   "metadata": {},
   "source": [
    "## 2.2 Micro-structural data: mean diffusivity and fractional anisotropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cc3ede",
   "metadata": {},
   "source": [
    "In the following section, the logistic regression model is computed for micro-structural data in an analogous way as for the macro-structural data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ba209f",
   "metadata": {},
   "source": [
    "### 2.2.1 Mean diffusivity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c39656f1",
   "metadata": {},
   "source": [
    "First, we prepare our data to use it in the code efficiently and adjust it for the logistic regression accordingly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56a83991",
   "metadata": {},
   "source": [
    "#### 2.2.1.1 Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d7217d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "\n",
    "MD_Dublin_path = os.path.join(os.pardir, 'data', 'PARC_500.aparc_MD_cortexAv_mean_Dublin.csv')\n",
    "MD_Dublin = pd.read_csv(MD_Dublin_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8f1126d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust dataframe\n",
    "\n",
    "MD_Dublin_adj = MD_Dublin.drop(['Subject ID','Age', 'Sex'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6a0c154b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label group 1 as 0 and 2 as 1\n",
    "\n",
    "MD_Dublin_adj['Group'] = MD_Dublin_adj['Group'].replace([1,2],[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e12a8836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>lh_bankssts_part1_thickness</th>\n",
       "      <th>lh_bankssts_part2_thickness</th>\n",
       "      <th>lh_caudalanteriorcingulate_part1_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part1_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part2_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part3_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part4_thickness</th>\n",
       "      <th>lh_cuneus_part1_thickness</th>\n",
       "      <th>lh_cuneus_part2_thickness</th>\n",
       "      <th>...</th>\n",
       "      <th>rh_supramarginal_part5_thickness</th>\n",
       "      <th>rh_supramarginal_part6_thickness</th>\n",
       "      <th>rh_supramarginal_part7_thickness</th>\n",
       "      <th>rh_frontalpole_part1_thickness</th>\n",
       "      <th>rh_temporalpole_part1_thickness</th>\n",
       "      <th>rh_transversetemporal_part1_thickness</th>\n",
       "      <th>rh_insula_part1_thickness</th>\n",
       "      <th>rh_insula_part2_thickness</th>\n",
       "      <th>rh_insula_part3_thickness</th>\n",
       "      <th>rh_insula_part4_thickness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.931</td>\n",
       "      <td>0.891</td>\n",
       "      <td>1.048</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.939</td>\n",
       "      <td>1.124</td>\n",
       "      <td>0.986</td>\n",
       "      <td>1.045</td>\n",
       "      <td>...</td>\n",
       "      <td>0.928</td>\n",
       "      <td>1.067</td>\n",
       "      <td>1.096</td>\n",
       "      <td>0.892</td>\n",
       "      <td>1.238</td>\n",
       "      <td>1.021</td>\n",
       "      <td>1.166</td>\n",
       "      <td>0.900</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.861</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.927</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.894</td>\n",
       "      <td>0.924</td>\n",
       "      <td>1.040</td>\n",
       "      <td>1.093</td>\n",
       "      <td>...</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.985</td>\n",
       "      <td>1.045</td>\n",
       "      <td>1.001</td>\n",
       "      <td>1.196</td>\n",
       "      <td>1.083</td>\n",
       "      <td>1.143</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0.817</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.828</td>\n",
       "      <td>0.780</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.825</td>\n",
       "      <td>0.848</td>\n",
       "      <td>0.838</td>\n",
       "      <td>...</td>\n",
       "      <td>0.847</td>\n",
       "      <td>0.849</td>\n",
       "      <td>0.819</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.933</td>\n",
       "      <td>0.942</td>\n",
       "      <td>1.059</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.834</td>\n",
       "      <td>0.860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.905</td>\n",
       "      <td>0.878</td>\n",
       "      <td>0.932</td>\n",
       "      <td>0.820</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.918</td>\n",
       "      <td>0.900</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.989</td>\n",
       "      <td>1.075</td>\n",
       "      <td>1.150</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.888</td>\n",
       "      <td>0.916</td>\n",
       "      <td>0.928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0.887</td>\n",
       "      <td>0.854</td>\n",
       "      <td>0.905</td>\n",
       "      <td>1.011</td>\n",
       "      <td>0.946</td>\n",
       "      <td>0.922</td>\n",
       "      <td>1.034</td>\n",
       "      <td>1.126</td>\n",
       "      <td>1.114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.871</td>\n",
       "      <td>0.952</td>\n",
       "      <td>0.987</td>\n",
       "      <td>1.325</td>\n",
       "      <td>0.996</td>\n",
       "      <td>1.094</td>\n",
       "      <td>1.064</td>\n",
       "      <td>0.966</td>\n",
       "      <td>0.989</td>\n",
       "      <td>0.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>1</td>\n",
       "      <td>0.843</td>\n",
       "      <td>0.855</td>\n",
       "      <td>0.940</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.954</td>\n",
       "      <td>0.840</td>\n",
       "      <td>1.128</td>\n",
       "      <td>1.012</td>\n",
       "      <td>0.997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.938</td>\n",
       "      <td>1.062</td>\n",
       "      <td>1.143</td>\n",
       "      <td>0.903</td>\n",
       "      <td>1.364</td>\n",
       "      <td>1.284</td>\n",
       "      <td>1.218</td>\n",
       "      <td>1.017</td>\n",
       "      <td>0.972</td>\n",
       "      <td>1.028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>1</td>\n",
       "      <td>0.911</td>\n",
       "      <td>0.914</td>\n",
       "      <td>0.926</td>\n",
       "      <td>1.001</td>\n",
       "      <td>0.918</td>\n",
       "      <td>1.115</td>\n",
       "      <td>1.036</td>\n",
       "      <td>1.026</td>\n",
       "      <td>1.001</td>\n",
       "      <td>...</td>\n",
       "      <td>0.957</td>\n",
       "      <td>1.085</td>\n",
       "      <td>1.098</td>\n",
       "      <td>1.059</td>\n",
       "      <td>1.268</td>\n",
       "      <td>1.089</td>\n",
       "      <td>1.173</td>\n",
       "      <td>0.990</td>\n",
       "      <td>1.065</td>\n",
       "      <td>1.021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>1</td>\n",
       "      <td>0.890</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.886</td>\n",
       "      <td>0.930</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.883</td>\n",
       "      <td>1.190</td>\n",
       "      <td>1.101</td>\n",
       "      <td>...</td>\n",
       "      <td>0.916</td>\n",
       "      <td>1.010</td>\n",
       "      <td>0.974</td>\n",
       "      <td>0.968</td>\n",
       "      <td>1.305</td>\n",
       "      <td>1.168</td>\n",
       "      <td>1.265</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.975</td>\n",
       "      <td>0.972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>1</td>\n",
       "      <td>0.920</td>\n",
       "      <td>0.986</td>\n",
       "      <td>0.883</td>\n",
       "      <td>0.879</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.983</td>\n",
       "      <td>1.029</td>\n",
       "      <td>1.076</td>\n",
       "      <td>1.053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.990</td>\n",
       "      <td>1.199</td>\n",
       "      <td>1.353</td>\n",
       "      <td>1.187</td>\n",
       "      <td>1.444</td>\n",
       "      <td>0.947</td>\n",
       "      <td>1.047</td>\n",
       "      <td>1.085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>1</td>\n",
       "      <td>0.970</td>\n",
       "      <td>0.868</td>\n",
       "      <td>0.940</td>\n",
       "      <td>0.967</td>\n",
       "      <td>0.930</td>\n",
       "      <td>1.022</td>\n",
       "      <td>0.957</td>\n",
       "      <td>1.112</td>\n",
       "      <td>1.004</td>\n",
       "      <td>...</td>\n",
       "      <td>1.074</td>\n",
       "      <td>1.122</td>\n",
       "      <td>1.215</td>\n",
       "      <td>0.891</td>\n",
       "      <td>1.333</td>\n",
       "      <td>1.295</td>\n",
       "      <td>1.284</td>\n",
       "      <td>1.125</td>\n",
       "      <td>1.110</td>\n",
       "      <td>1.139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>115 rows × 309 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Group  lh_bankssts_part1_thickness  lh_bankssts_part2_thickness  \\\n",
       "0        0                        0.911                        0.931   \n",
       "1        0                        0.861                        0.913   \n",
       "2        0                        0.817                        0.827   \n",
       "3        0                        0.887                        0.905   \n",
       "4        0                        0.887                        0.854   \n",
       "..     ...                          ...                          ...   \n",
       "110      1                        0.843                        0.855   \n",
       "111      1                        0.911                        0.914   \n",
       "112      1                        0.890                        0.899   \n",
       "113      1                        0.920                        0.986   \n",
       "114      1                        0.970                        0.868   \n",
       "\n",
       "     lh_caudalanteriorcingulate_part1_thickness  \\\n",
       "0                                         0.891   \n",
       "1                                         0.846   \n",
       "2                                         0.828   \n",
       "3                                         0.878   \n",
       "4                                         0.905   \n",
       "..                                          ...   \n",
       "110                                       0.940   \n",
       "111                                       0.926   \n",
       "112                                       0.886   \n",
       "113                                       0.883   \n",
       "114                                       0.940   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part1_thickness  \\\n",
       "0                                     1.048   \n",
       "1                                     0.927   \n",
       "2                                     0.828   \n",
       "3                                     0.932   \n",
       "4                                     1.011   \n",
       "..                                      ...   \n",
       "110                                   1.017   \n",
       "111                                   1.001   \n",
       "112                                   0.930   \n",
       "113                                   0.879   \n",
       "114                                   0.967   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part2_thickness  \\\n",
       "0                                     0.881   \n",
       "1                                     0.888   \n",
       "2                                     0.780   \n",
       "3                                     0.820   \n",
       "4                                     0.946   \n",
       "..                                      ...   \n",
       "110                                   0.954   \n",
       "111                                   0.918   \n",
       "112                                   0.883   \n",
       "113                                   0.794   \n",
       "114                                   0.930   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part3_thickness  \\\n",
       "0                                     0.939   \n",
       "1                                     0.894   \n",
       "2                                     0.843   \n",
       "3                                     0.888   \n",
       "4                                     0.922   \n",
       "..                                      ...   \n",
       "110                                   0.840   \n",
       "111                                   1.115   \n",
       "112                                   0.882   \n",
       "113                                   0.983   \n",
       "114                                   1.022   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part4_thickness  lh_cuneus_part1_thickness  \\\n",
       "0                                     1.124                      0.986   \n",
       "1                                     0.924                      1.040   \n",
       "2                                     0.825                      0.848   \n",
       "3                                     0.970                      0.918   \n",
       "4                                     1.034                      1.126   \n",
       "..                                      ...                        ...   \n",
       "110                                   1.128                      1.012   \n",
       "111                                   1.036                      1.026   \n",
       "112                                   0.883                      1.190   \n",
       "113                                   1.029                      1.076   \n",
       "114                                   0.957                      1.112   \n",
       "\n",
       "     lh_cuneus_part2_thickness  ...  rh_supramarginal_part5_thickness  \\\n",
       "0                        1.045  ...                             0.928   \n",
       "1                        1.093  ...                             0.878   \n",
       "2                        0.838  ...                             0.847   \n",
       "3                        0.900  ...                             0.957   \n",
       "4                        1.114  ...                             0.871   \n",
       "..                         ...  ...                               ...   \n",
       "110                      0.997  ...                             0.938   \n",
       "111                      1.001  ...                             0.957   \n",
       "112                      1.101  ...                             0.916   \n",
       "113                      1.053  ...                             0.942   \n",
       "114                      1.004  ...                             1.074   \n",
       "\n",
       "     rh_supramarginal_part6_thickness  rh_supramarginal_part7_thickness  \\\n",
       "0                               1.067                             1.096   \n",
       "1                               0.985                             1.045   \n",
       "2                               0.849                             0.819   \n",
       "3                               0.985                             0.989   \n",
       "4                               0.952                             0.987   \n",
       "..                                ...                               ...   \n",
       "110                             1.062                             1.143   \n",
       "111                             1.085                             1.098   \n",
       "112                             1.010                             0.974   \n",
       "113                             0.985                             0.990   \n",
       "114                             1.122                             1.215   \n",
       "\n",
       "     rh_frontalpole_part1_thickness  rh_temporalpole_part1_thickness  \\\n",
       "0                             0.892                            1.238   \n",
       "1                             1.001                            1.196   \n",
       "2                             0.952                            0.933   \n",
       "3                             1.075                            1.150   \n",
       "4                             1.325                            0.996   \n",
       "..                              ...                              ...   \n",
       "110                           0.903                            1.364   \n",
       "111                           1.059                            1.268   \n",
       "112                           0.968                            1.305   \n",
       "113                           1.199                            1.353   \n",
       "114                           0.891                            1.333   \n",
       "\n",
       "     rh_transversetemporal_part1_thickness  rh_insula_part1_thickness  \\\n",
       "0                                    1.021                      1.166   \n",
       "1                                    1.083                      1.143   \n",
       "2                                    0.942                      1.059   \n",
       "3                                    1.017                      0.986   \n",
       "4                                    1.094                      1.064   \n",
       "..                                     ...                        ...   \n",
       "110                                  1.284                      1.218   \n",
       "111                                  1.089                      1.173   \n",
       "112                                  1.168                      1.265   \n",
       "113                                  1.187                      1.444   \n",
       "114                                  1.295                      1.284   \n",
       "\n",
       "     rh_insula_part2_thickness  rh_insula_part3_thickness  \\\n",
       "0                        0.900                      0.907   \n",
       "1                        0.917                      0.923   \n",
       "2                        0.794                      0.834   \n",
       "3                        0.888                      0.916   \n",
       "4                        0.966                      0.989   \n",
       "..                         ...                        ...   \n",
       "110                      1.017                      0.972   \n",
       "111                      0.990                      1.065   \n",
       "112                      0.981                      0.975   \n",
       "113                      0.947                      1.047   \n",
       "114                      1.125                      1.110   \n",
       "\n",
       "     rh_insula_part4_thickness  \n",
       "0                        0.937  \n",
       "1                        0.960  \n",
       "2                        0.860  \n",
       "3                        0.928  \n",
       "4                        0.977  \n",
       "..                         ...  \n",
       "110                      1.028  \n",
       "111                      1.021  \n",
       "112                      0.972  \n",
       "113                      1.085  \n",
       "114                      1.139  \n",
       "\n",
       "[115 rows x 309 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MD_Dublin_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "aa974bc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.911, 0.931, ..., 0.9  , 0.907, 0.937],\n",
       "       [0.   , 0.861, 0.913, ..., 0.917, 0.923, 0.96 ],\n",
       "       [0.   , 0.817, 0.827, ..., 0.794, 0.834, 0.86 ],\n",
       "       ...,\n",
       "       [1.   , 0.89 , 0.899, ..., 0.981, 0.975, 0.972],\n",
       "       [1.   , 0.92 , 0.986, ..., 0.947, 1.047, 1.085],\n",
       "       [1.   , 0.97 , 0.868, ..., 1.125, 1.11 , 1.139]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe as numpy array \n",
    "\n",
    "MD_Dublin_adj.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9317379a",
   "metadata": {},
   "source": [
    "#### 2.2.1.2 Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e57ed474",
   "metadata": {},
   "source": [
    "In the next step, the input and output for our model is defined. For that, we use the **MD** for each 308 cortical region as input and the label whether a participant belongs to the control or patient group as output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "0decd525",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define input\n",
    "\n",
    "X_MD = MD_Dublin_adj.iloc[:,1:309].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "e4fe91ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output\n",
    "\n",
    "y_MD = MD_Dublin_adj.iloc[:,[0]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "e7089e2f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115, 1)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_MD.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079848d7",
   "metadata": {},
   "source": [
    "To return a 1D flattened array since its required for further analyses, the .ravel() function is used!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "d8c37219",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_MD = y_MD.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0ca72716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(115,)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_MD.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3a491660",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.911, 0.931, 0.891, ..., 1.166, 0.9  , 0.907],\n",
       "       [0.861, 0.913, 0.846, ..., 1.143, 0.917, 0.923],\n",
       "       [0.817, 0.827, 0.828, ..., 1.059, 0.794, 0.834],\n",
       "       ...,\n",
       "       [0.89 , 0.899, 0.886, ..., 1.265, 0.981, 0.975],\n",
       "       [0.92 , 0.986, 0.883, ..., 1.444, 0.947, 1.047],\n",
       "       [0.97 , 0.868, 0.94 , ..., 1.284, 1.125, 1.11 ]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_MD"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741bf0a4",
   "metadata": {},
   "source": [
    "Again, we build our model with 5000 iterations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "f2c9353a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter_MD = 5000\n",
    "y_preds_MD = []\n",
    "y_tests_MD = []\n",
    "\n",
    "# scale before splitting into test and train samples\n",
    "X_sc_MD = StandardScaler().fit_transform(X_MD)\n",
    "\n",
    "for i in range(n_iter):\n",
    "    # take a new testing and training sample\n",
    "    X_train_MD, X_test_MD, y_train_MD, y_test_MD = train_test_split(X_sc_MD, y_MD, test_size = 0.25, random_state = i)\n",
    "    y_tests_MD.append(y_test_MD)  # store the y_test sample\n",
    "    \n",
    "    # fit the logistic regression\n",
    "    classifier_MD = LogisticRegression(random_state = i, solver ='liblinear')\n",
    "    classifier_MD.fit(X_train_MD, y_train_MD)\n",
    "    \n",
    "    # get the y predictions and store\n",
    "    y_pred_MD = classifier_MD.predict(X_test_MD)\n",
    "    y_preds_MD.append(y_pred_MD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3272350b",
   "metadata": {},
   "source": [
    "In the following steps, we again concatenate the values to compute the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "1d9afdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_MD = np.concatenate(y_preds_MD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "71323df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tests_MD = np.concatenate(y_tests_MD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ad84688",
   "metadata": {},
   "source": [
    "#### 2.2.1.3 Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f022c85",
   "metadata": {},
   "source": [
    "##### 2.2.1.3.1 Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "b92c0047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[0.53733103 0.17482759]\n",
      " [0.07247586 0.21536552]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "\n",
    "cm_MD = confusion_matrix(y_tests_MD, y_preds_MD)\n",
    "\n",
    "cm_MD_f = cm_MD/np.sum(cm_MD)\n",
    "  \n",
    "print (\"Confusion Matrix : \\n\", cm_MD_f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba0fc55",
   "metadata": {},
   "source": [
    "To plot the confusion matrix visually more appealing again, the following code can be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "6772de47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 257.44, 'Predicted label')"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "class_names=[0,1]\n",
    "\n",
    "fig, ax = plt.subplots() \n",
    "tick_marks = np.arange(len(class_names)) \n",
    "plt.xticks(tick_marks, class_names) \n",
    "plt.yticks(tick_marks, class_names) \n",
    "sns.heatmap(pd.DataFrame(cm_MD_f), annot=True, cmap=\"YlGnBu\" ,fmt='g') \n",
    "ax.xaxis.set_label_position(\"top\") \n",
    "plt.tight_layout() \n",
    "plt.title('Confusion matrix for Mean Diffusivity', y=1.1) \n",
    "plt.ylabel('Actual label') \n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73f431f5",
   "metadata": {},
   "source": [
    "The confusion matrix reveals the probability for **hits** is around 54%, for **true negatives** around 22%. The probability for **misses** is around 7%. The probability for **false positive** cases is around 17%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147a9322",
   "metadata": {},
   "source": [
    "##### 2.2.1.3.2  Model accuracy, precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "dc865b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.752696551724138\n",
      "Precision: 0.5519459860723249\n",
      "Recall: 0.7482090231688909\n",
      "F1-Score: 0.6352642018003356\n"
     ]
    }
   ],
   "source": [
    "#compute accuracy, precision, recall\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_tests_MD, y_preds_MD)) \n",
    "\n",
    "print(\"Precision:\",metrics.precision_score(y_tests_MD, y_preds_MD)) \n",
    "\n",
    "print(\"Recall:\",metrics.recall_score(y_tests_MD, y_preds_MD)) \n",
    "\n",
    "print(\"F1-Score:\", metrics.f1_score(y_tests_MD, y_preds_MD))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dfe191c",
   "metadata": {},
   "source": [
    "##### 2.2.1.3.3 ROC-curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "3966c149",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test_MD, classifier_MD.predict(X_test_MD))\n",
    "fpr, tpr, thresholds = roc_curve(y_test_MD, classifier_MD.predict_proba(X_test_MD)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d90cf50b",
   "metadata": {},
   "source": [
    "As the plot reveals, the model performs worse than for **CT**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d6bc86",
   "metadata": {},
   "source": [
    "### 2.2.2 Fractional anisotropy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84e891f",
   "metadata": {},
   "source": [
    "Now, the same procedure is applied for **FA**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd038dc5",
   "metadata": {},
   "source": [
    "#### 2.2.2.1 Data preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9b53c7",
   "metadata": {},
   "source": [
    "First, the data is adjusted accordingly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4ed0d86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "\n",
    "FA_Dublin_path = os.path.join(os.pardir, 'data', 'PARC_500.aparc_FA_cortexAv_mean_Dublin.csv')\n",
    "FA_Dublin = pd.read_csv(FA_Dublin_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2245eded",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust dataframe\n",
    "\n",
    "FA_Dublin_adj = FA_Dublin.drop(['Subject ID','Age', 'Sex'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8e2354f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label group 1 as 0 and 2 as 1\n",
    "\n",
    "FA_Dublin_adj['Group'] = FA_Dublin_adj['Group'].replace([1,2],[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "206f4afb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 0.322, 0.147, ..., 0.157, 0.147, 0.137],\n",
       "       [0.   , 0.302, 0.155, ..., 0.152, 0.148, 0.152],\n",
       "       [0.   , 0.324, 0.18 , ..., 0.171, 0.174, 0.143],\n",
       "       ...,\n",
       "       [1.   , 0.323, 0.173, ..., 0.181, 0.143, 0.151],\n",
       "       [1.   , 0.311, 0.174, ..., 0.162, 0.145, 0.123],\n",
       "       [1.   , 0.294, 0.164, ..., 0.145, 0.147, 0.127]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe as numpy array \n",
    "\n",
    "FA_Dublin_adj.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "714a804d",
   "metadata": {},
   "source": [
    "#### 2.2.2.2 Build the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc4e3c0",
   "metadata": {},
   "source": [
    "Again, the input and output variables are defined. Here, we take the **FA** values for every brain region as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "ffa88998",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define input\n",
    "\n",
    "X_FA = FA_Dublin_adj.iloc[:,1:309].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4a6fdc05",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output\n",
    "\n",
    "y_FA = FA_Dublin_adj.iloc[:,[0]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "f7a678ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_FA = y_FA.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "8417be69",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_iter_FA = 5000\n",
    "y_preds_FA = []\n",
    "y_tests_FA = []\n",
    "\n",
    "# scale before splitting into test and train samples\n",
    "X_sc_FA = StandardScaler().fit_transform(X_FA)\n",
    "\n",
    "for i in range(n_iter):\n",
    "    # take a new testing and training sample\n",
    "    X_train_FA, X_test_FA, y_train_FA, y_test_FA = train_test_split(X_sc_FA, y_FA, test_size = 0.25, random_state = i)\n",
    "    y_tests_FA.append(y_test_FA)  # store the y_test sample\n",
    "    \n",
    "    # fit the logistic regression\n",
    "    classifier_FA = LogisticRegression(random_state = i, solver ='liblinear')\n",
    "    classifier_FA.fit(X_train_FA, y_train_FA)\n",
    "    \n",
    "    # get the y predictions and store\n",
    "    y_pred_FA = classifier_FA.predict(X_test_FA)\n",
    "    y_preds_FA.append(y_pred_FA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "4db6e2b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_FA = np.concatenate(y_preds_FA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "04ffbc41",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tests_FA = np.concatenate(y_tests_FA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341d0dfd",
   "metadata": {},
   "source": [
    "### 2.2.2.3 Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dced73e0",
   "metadata": {},
   "source": [
    "#### 2.2.2.3.1 Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "9d1b595a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "multilabel-indicator is not supported",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3m/1g132z9j3_14k03_9l9qv2wr0000gn/T/ipykernel_44403/1759283093.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#confusion matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcm_FA\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tests_FA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds_FA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mcm_FA_f\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcm_FA\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcm_FA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro_ai/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight, normalize)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: multilabel-indicator is not supported"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "\n",
    "cm_FA = confusion_matrix(y_tests_FA, y_preds_FA)\n",
    "\n",
    "cm_FA_f = cm_FA / np.sum(cm_FA)\n",
    "  \n",
    "    \n",
    "print (\"Confusion Matrix : \\n\", cm_FA_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "6a037656",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 257.44, 'Predicted label')"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the confusion matrix visually more appealing\n",
    "\n",
    "class_names=[0,1]\n",
    "\n",
    "fig, ax = plt.subplots() \n",
    "tick_marks = np.arange(len(class_names)) \n",
    "plt.xticks(tick_marks, class_names) \n",
    "plt.yticks(tick_marks, class_names) \n",
    "sns.heatmap(pd.DataFrame(cm_FA_f), annot=True, cmap=\"YlGnBu\" ,fmt='g') \n",
    "ax.xaxis.set_label_position(\"top\") \n",
    "plt.tight_layout() \n",
    "plt.title('Confusion matrix for Fractional Anisotropy', y=1.1) \n",
    "plt.ylabel('Actual label') \n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b1ac17",
   "metadata": {},
   "source": [
    "The confusion matrix shows that the probability for **hits** is around 44%, for **true negatives** around 23%. The probability for **misses** is around 6%. The probability for **false positive** cases is around 27%. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5f68b1",
   "metadata": {},
   "source": [
    "#### 2.2.2.3.2 Model accuracy, precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "b400b986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Target is multilabel-indicator but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted', 'samples'].",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3m/1g132z9j3_14k03_9l9qv2wr0000gn/T/ipykernel_44403/3087685093.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tests_FA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds_FA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Precision:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tests_FA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds_FA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Recall:\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_tests_FA\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_preds_FA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro_ai/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_score\u001b[0;34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1763\u001b[0m         \u001b[0mwarn_for\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"precision\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1764\u001b[0m         \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1765\u001b[0;31m         \u001b[0mzero_division\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mzero_division\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1766\u001b[0m     )\n\u001b[1;32m   1767\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro_ai/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mprecision_recall_fscore_support\u001b[0;34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[0m\n\u001b[1;32m   1542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbeta\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1543\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"beta should be >=0 in the F-beta score\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1544\u001b[0;31m     \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_set_wise_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1545\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1546\u001b[0m     \u001b[0;31m# Calculate tp_sum, pred_sum, true_sum ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro_ai/lib/python3.7/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m_check_set_wise_labels\u001b[0;34m(y_true, y_pred, average, labels, pos_label)\u001b[0m\n\u001b[1;32m   1365\u001b[0m             raise ValueError(\n\u001b[1;32m   1366\u001b[0m                 \u001b[0;34m\"Target is %s but average='binary'. Please \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m                 \u001b[0;34m\"choose another average setting, one of %r.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage_options\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1368\u001b[0m             )\n\u001b[1;32m   1369\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Target is multilabel-indicator but average='binary'. Please choose another average setting, one of [None, 'micro', 'macro', 'weighted', 'samples']."
     ]
    }
   ],
   "source": [
    "#compute accuracy, precision, recall\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_tests_FA, y_preds_FA)) \n",
    "\n",
    "print(\"Precision:\",metrics.precision_score(y_tests_FA, y_preds_FA)) \n",
    "\n",
    "print(\"Recall:\",metrics.recall_score(y_tests_FA, y_preds_FA)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ec4d2",
   "metadata": {},
   "source": [
    "#### 2.2.2.3.3 ROC-curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "7f05eaa1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test_FA, classifier_FA.predict(X_test_FA))\n",
    "fpr, tpr, thresholds = roc_curve(y_test_FA, classifier_FA.predict_proba(X_test_FA)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6fa1c9c",
   "metadata": {},
   "source": [
    "In the next pages, a different algorithm is applied to the data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "578504114d49301275c44c87035f08411733f9928d9347745d7de100c09f7611"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
