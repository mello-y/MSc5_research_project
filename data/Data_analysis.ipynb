{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a966c8cb",
   "metadata": {},
   "source": [
    "# Data analysis for MSc5_research_project "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f0caba",
   "metadata": {},
   "source": [
    "This jupyter notebook deals with analysing the data for my research project within the MSc05 course in the Neurocognitive Psychology lab at Goethe University Frankfurt within the psychology master degree program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6922c12",
   "metadata": {},
   "source": [
    "Just to repeat briefly, the aim of the project is to use machine learning in order to predict whether a particpant can be classified either as control or patient with psychotic disorder based on different brain modalities. Before starting with our first modality being **cortical thickness (CT)**, the learning problem and the task type should be defined to know which model suits the best for the purpose of the project aim."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11812b4b",
   "metadata": {},
   "source": [
    "## 1. Learning problem and task type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feddd06e",
   "metadata": {},
   "source": [
    "Following the scikit-learn algorhitm cheat-sheet, for the data at hand the performance of a **linear SVM** is recommended. The data contains more than 50 participants (samples), the aim is to predict a category (control/patient) and the data is labeled. \n",
    "Since I want to use the given information regarding the labels for each sample, the learning problem is **supervised**. Considering the task type, our purpose is to classify the samples in two categories being control and patient. Hence, the task type is **classification**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e239fd",
   "metadata": {},
   "source": [
    "SVMs are a set of supervised learning methods used that can be used for classifcation, regression and outliers detection (for further information click here). The basic idea is to find an optimal separating line (or hyperplane) as output that separates the data into two classes. The SVM algorithm looks for the data points that are the clostest to the line from both classes. These points are called support vectors. Then, the distance between the support vectors and the hyperplane which is called the margin is computed. To find the best and optimal hyperplane, the margin should be maximized.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fb12fe",
   "metadata": {},
   "source": [
    "Support vector classification(SVC) or Linear Support vector classification (LinearSVC) are methods of SVMs making it feasible to perfom a binary or mulit-class classification on a dataset. For the purpose of this project, LinearSVC is going to be performed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35e81a3",
   "metadata": {},
   "source": [
    "### 1.1 Macro-structural data: Cortical Thickness (CT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e032f4",
   "metadata": {},
   "source": [
    "First of all, I use CT data as my input data for the classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "a2598d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#load CT data\n",
    "\n",
    "CT = pd.read_csv('/Users/mello/Desktop/Dataset/PARC_500.aparc_thickness_Dublin.csv', delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "b0ce6f5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#adjust data frame \n",
    "\n",
    "CT_adj = CT.drop(['Subject ID','Age', 'Sex'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "e01a3903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label group 1 as control and 2 as patient\n",
    "\n",
    "CT_adj['Group'] = CT_adj['Group'].replace([1,2],['control', 'patient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4b524305",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>lh_bankssts_part1_thickness</th>\n",
       "      <th>lh_bankssts_part2_thickness</th>\n",
       "      <th>lh_caudalanteriorcingulate_part1_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part1_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part2_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part3_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part4_thickness</th>\n",
       "      <th>lh_cuneus_part1_thickness</th>\n",
       "      <th>lh_cuneus_part2_thickness</th>\n",
       "      <th>...</th>\n",
       "      <th>rh_supramarginal_part5_thickness</th>\n",
       "      <th>rh_supramarginal_part6_thickness</th>\n",
       "      <th>rh_supramarginal_part7_thickness</th>\n",
       "      <th>rh_frontalpole_part1_thickness</th>\n",
       "      <th>rh_temporalpole_part1_thickness</th>\n",
       "      <th>rh_transversetemporal_part1_thickness</th>\n",
       "      <th>rh_insula_part1_thickness</th>\n",
       "      <th>rh_insula_part2_thickness</th>\n",
       "      <th>rh_insula_part3_thickness</th>\n",
       "      <th>rh_insula_part4_thickness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>control</td>\n",
       "      <td>2.180</td>\n",
       "      <td>2.382</td>\n",
       "      <td>2.346</td>\n",
       "      <td>2.526</td>\n",
       "      <td>2.747</td>\n",
       "      <td>2.544</td>\n",
       "      <td>2.582</td>\n",
       "      <td>1.816</td>\n",
       "      <td>2.228</td>\n",
       "      <td>...</td>\n",
       "      <td>2.817</td>\n",
       "      <td>2.325</td>\n",
       "      <td>2.430</td>\n",
       "      <td>3.004</td>\n",
       "      <td>3.979</td>\n",
       "      <td>2.329</td>\n",
       "      <td>3.620</td>\n",
       "      <td>2.776</td>\n",
       "      <td>3.282</td>\n",
       "      <td>3.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>control</td>\n",
       "      <td>2.394</td>\n",
       "      <td>1.973</td>\n",
       "      <td>2.534</td>\n",
       "      <td>2.439</td>\n",
       "      <td>2.485</td>\n",
       "      <td>2.435</td>\n",
       "      <td>2.458</td>\n",
       "      <td>1.723</td>\n",
       "      <td>1.821</td>\n",
       "      <td>...</td>\n",
       "      <td>2.611</td>\n",
       "      <td>2.418</td>\n",
       "      <td>2.317</td>\n",
       "      <td>2.794</td>\n",
       "      <td>3.851</td>\n",
       "      <td>2.034</td>\n",
       "      <td>3.588</td>\n",
       "      <td>2.654</td>\n",
       "      <td>3.124</td>\n",
       "      <td>3.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>control</td>\n",
       "      <td>2.551</td>\n",
       "      <td>2.567</td>\n",
       "      <td>1.954</td>\n",
       "      <td>2.439</td>\n",
       "      <td>2.428</td>\n",
       "      <td>2.190</td>\n",
       "      <td>2.377</td>\n",
       "      <td>2.026</td>\n",
       "      <td>1.800</td>\n",
       "      <td>...</td>\n",
       "      <td>2.777</td>\n",
       "      <td>2.309</td>\n",
       "      <td>2.390</td>\n",
       "      <td>2.365</td>\n",
       "      <td>4.039</td>\n",
       "      <td>2.337</td>\n",
       "      <td>3.657</td>\n",
       "      <td>2.495</td>\n",
       "      <td>2.669</td>\n",
       "      <td>2.886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>patient</td>\n",
       "      <td>2.187</td>\n",
       "      <td>1.923</td>\n",
       "      <td>2.160</td>\n",
       "      <td>2.410</td>\n",
       "      <td>2.381</td>\n",
       "      <td>2.277</td>\n",
       "      <td>2.361</td>\n",
       "      <td>1.585</td>\n",
       "      <td>1.750</td>\n",
       "      <td>...</td>\n",
       "      <td>2.265</td>\n",
       "      <td>2.306</td>\n",
       "      <td>2.129</td>\n",
       "      <td>2.281</td>\n",
       "      <td>3.505</td>\n",
       "      <td>2.275</td>\n",
       "      <td>3.121</td>\n",
       "      <td>2.333</td>\n",
       "      <td>2.604</td>\n",
       "      <td>2.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>patient</td>\n",
       "      <td>1.862</td>\n",
       "      <td>1.750</td>\n",
       "      <td>2.129</td>\n",
       "      <td>2.516</td>\n",
       "      <td>2.244</td>\n",
       "      <td>2.169</td>\n",
       "      <td>2.220</td>\n",
       "      <td>1.646</td>\n",
       "      <td>1.717</td>\n",
       "      <td>...</td>\n",
       "      <td>2.582</td>\n",
       "      <td>2.314</td>\n",
       "      <td>2.047</td>\n",
       "      <td>2.389</td>\n",
       "      <td>3.272</td>\n",
       "      <td>2.445</td>\n",
       "      <td>3.171</td>\n",
       "      <td>2.216</td>\n",
       "      <td>2.659</td>\n",
       "      <td>2.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>patient</td>\n",
       "      <td>2.240</td>\n",
       "      <td>2.150</td>\n",
       "      <td>1.995</td>\n",
       "      <td>2.254</td>\n",
       "      <td>2.164</td>\n",
       "      <td>2.008</td>\n",
       "      <td>2.298</td>\n",
       "      <td>1.918</td>\n",
       "      <td>1.717</td>\n",
       "      <td>...</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.288</td>\n",
       "      <td>2.395</td>\n",
       "      <td>2.105</td>\n",
       "      <td>3.267</td>\n",
       "      <td>2.257</td>\n",
       "      <td>3.231</td>\n",
       "      <td>2.574</td>\n",
       "      <td>2.920</td>\n",
       "      <td>2.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>patient</td>\n",
       "      <td>2.269</td>\n",
       "      <td>2.124</td>\n",
       "      <td>2.531</td>\n",
       "      <td>2.502</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.183</td>\n",
       "      <td>2.408</td>\n",
       "      <td>1.539</td>\n",
       "      <td>1.611</td>\n",
       "      <td>...</td>\n",
       "      <td>2.302</td>\n",
       "      <td>2.182</td>\n",
       "      <td>2.182</td>\n",
       "      <td>2.327</td>\n",
       "      <td>2.881</td>\n",
       "      <td>2.124</td>\n",
       "      <td>3.159</td>\n",
       "      <td>2.450</td>\n",
       "      <td>2.753</td>\n",
       "      <td>2.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>patient</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.559</td>\n",
       "      <td>2.578</td>\n",
       "      <td>2.463</td>\n",
       "      <td>2.463</td>\n",
       "      <td>2.053</td>\n",
       "      <td>2.526</td>\n",
       "      <td>1.733</td>\n",
       "      <td>1.859</td>\n",
       "      <td>...</td>\n",
       "      <td>2.534</td>\n",
       "      <td>2.604</td>\n",
       "      <td>2.449</td>\n",
       "      <td>2.370</td>\n",
       "      <td>3.111</td>\n",
       "      <td>2.190</td>\n",
       "      <td>3.480</td>\n",
       "      <td>2.294</td>\n",
       "      <td>2.571</td>\n",
       "      <td>2.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>patient</td>\n",
       "      <td>1.940</td>\n",
       "      <td>2.438</td>\n",
       "      <td>2.272</td>\n",
       "      <td>2.272</td>\n",
       "      <td>2.610</td>\n",
       "      <td>2.099</td>\n",
       "      <td>2.538</td>\n",
       "      <td>1.931</td>\n",
       "      <td>1.792</td>\n",
       "      <td>...</td>\n",
       "      <td>2.638</td>\n",
       "      <td>2.225</td>\n",
       "      <td>2.013</td>\n",
       "      <td>2.115</td>\n",
       "      <td>3.853</td>\n",
       "      <td>2.231</td>\n",
       "      <td>3.187</td>\n",
       "      <td>2.510</td>\n",
       "      <td>2.759</td>\n",
       "      <td>2.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>patient</td>\n",
       "      <td>2.108</td>\n",
       "      <td>2.269</td>\n",
       "      <td>2.145</td>\n",
       "      <td>2.192</td>\n",
       "      <td>2.443</td>\n",
       "      <td>1.977</td>\n",
       "      <td>2.453</td>\n",
       "      <td>1.590</td>\n",
       "      <td>1.715</td>\n",
       "      <td>...</td>\n",
       "      <td>2.013</td>\n",
       "      <td>2.251</td>\n",
       "      <td>2.021</td>\n",
       "      <td>2.419</td>\n",
       "      <td>3.679</td>\n",
       "      <td>1.970</td>\n",
       "      <td>3.192</td>\n",
       "      <td>2.551</td>\n",
       "      <td>2.855</td>\n",
       "      <td>2.985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 309 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Group  lh_bankssts_part1_thickness  lh_bankssts_part2_thickness  \\\n",
       "0    control                        2.180                        2.382   \n",
       "1    control                        2.394                        1.973   \n",
       "2    control                        2.551                        2.567   \n",
       "3    patient                        2.187                        1.923   \n",
       "4    patient                        1.862                        1.750   \n",
       "..       ...                          ...                          ...   \n",
       "103  patient                        2.240                        2.150   \n",
       "104  patient                        2.269                        2.124   \n",
       "105  patient                        2.273                        2.559   \n",
       "106  patient                        1.940                        2.438   \n",
       "107  patient                        2.108                        2.269   \n",
       "\n",
       "     lh_caudalanteriorcingulate_part1_thickness  \\\n",
       "0                                         2.346   \n",
       "1                                         2.534   \n",
       "2                                         1.954   \n",
       "3                                         2.160   \n",
       "4                                         2.129   \n",
       "..                                          ...   \n",
       "103                                       1.995   \n",
       "104                                       2.531   \n",
       "105                                       2.578   \n",
       "106                                       2.272   \n",
       "107                                       2.145   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part1_thickness  \\\n",
       "0                                     2.526   \n",
       "1                                     2.439   \n",
       "2                                     2.439   \n",
       "3                                     2.410   \n",
       "4                                     2.516   \n",
       "..                                      ...   \n",
       "103                                   2.254   \n",
       "104                                   2.502   \n",
       "105                                   2.463   \n",
       "106                                   2.272   \n",
       "107                                   2.192   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part2_thickness  \\\n",
       "0                                     2.747   \n",
       "1                                     2.485   \n",
       "2                                     2.428   \n",
       "3                                     2.381   \n",
       "4                                     2.244   \n",
       "..                                      ...   \n",
       "103                                   2.164   \n",
       "104                                   2.250   \n",
       "105                                   2.463   \n",
       "106                                   2.610   \n",
       "107                                   2.443   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part3_thickness  \\\n",
       "0                                     2.544   \n",
       "1                                     2.435   \n",
       "2                                     2.190   \n",
       "3                                     2.277   \n",
       "4                                     2.169   \n",
       "..                                      ...   \n",
       "103                                   2.008   \n",
       "104                                   2.183   \n",
       "105                                   2.053   \n",
       "106                                   2.099   \n",
       "107                                   1.977   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part4_thickness  lh_cuneus_part1_thickness  \\\n",
       "0                                     2.582                      1.816   \n",
       "1                                     2.458                      1.723   \n",
       "2                                     2.377                      2.026   \n",
       "3                                     2.361                      1.585   \n",
       "4                                     2.220                      1.646   \n",
       "..                                      ...                        ...   \n",
       "103                                   2.298                      1.918   \n",
       "104                                   2.408                      1.539   \n",
       "105                                   2.526                      1.733   \n",
       "106                                   2.538                      1.931   \n",
       "107                                   2.453                      1.590   \n",
       "\n",
       "     lh_cuneus_part2_thickness  ...  rh_supramarginal_part5_thickness  \\\n",
       "0                        2.228  ...                             2.817   \n",
       "1                        1.821  ...                             2.611   \n",
       "2                        1.800  ...                             2.777   \n",
       "3                        1.750  ...                             2.265   \n",
       "4                        1.717  ...                             2.582   \n",
       "..                         ...  ...                               ...   \n",
       "103                      1.717  ...                             2.273   \n",
       "104                      1.611  ...                             2.302   \n",
       "105                      1.859  ...                             2.534   \n",
       "106                      1.792  ...                             2.638   \n",
       "107                      1.715  ...                             2.013   \n",
       "\n",
       "     rh_supramarginal_part6_thickness  rh_supramarginal_part7_thickness  \\\n",
       "0                               2.325                             2.430   \n",
       "1                               2.418                             2.317   \n",
       "2                               2.309                             2.390   \n",
       "3                               2.306                             2.129   \n",
       "4                               2.314                             2.047   \n",
       "..                                ...                               ...   \n",
       "103                             2.288                             2.395   \n",
       "104                             2.182                             2.182   \n",
       "105                             2.604                             2.449   \n",
       "106                             2.225                             2.013   \n",
       "107                             2.251                             2.021   \n",
       "\n",
       "     rh_frontalpole_part1_thickness  rh_temporalpole_part1_thickness  \\\n",
       "0                             3.004                            3.979   \n",
       "1                             2.794                            3.851   \n",
       "2                             2.365                            4.039   \n",
       "3                             2.281                            3.505   \n",
       "4                             2.389                            3.272   \n",
       "..                              ...                              ...   \n",
       "103                           2.105                            3.267   \n",
       "104                           2.327                            2.881   \n",
       "105                           2.370                            3.111   \n",
       "106                           2.115                            3.853   \n",
       "107                           2.419                            3.679   \n",
       "\n",
       "     rh_transversetemporal_part1_thickness  rh_insula_part1_thickness  \\\n",
       "0                                    2.329                      3.620   \n",
       "1                                    2.034                      3.588   \n",
       "2                                    2.337                      3.657   \n",
       "3                                    2.275                      3.121   \n",
       "4                                    2.445                      3.171   \n",
       "..                                     ...                        ...   \n",
       "103                                  2.257                      3.231   \n",
       "104                                  2.124                      3.159   \n",
       "105                                  2.190                      3.480   \n",
       "106                                  2.231                      3.187   \n",
       "107                                  1.970                      3.192   \n",
       "\n",
       "     rh_insula_part2_thickness  rh_insula_part3_thickness  \\\n",
       "0                        2.776                      3.282   \n",
       "1                        2.654                      3.124   \n",
       "2                        2.495                      2.669   \n",
       "3                        2.333                      2.604   \n",
       "4                        2.216                      2.659   \n",
       "..                         ...                        ...   \n",
       "103                      2.574                      2.920   \n",
       "104                      2.450                      2.753   \n",
       "105                      2.294                      2.571   \n",
       "106                      2.510                      2.759   \n",
       "107                      2.551                      2.855   \n",
       "\n",
       "     rh_insula_part4_thickness  \n",
       "0                        3.347  \n",
       "1                        3.214  \n",
       "2                        2.886  \n",
       "3                        2.731  \n",
       "4                        2.657  \n",
       "..                         ...  \n",
       "103                      2.899  \n",
       "104                      2.791  \n",
       "105                      2.875  \n",
       "106                      2.838  \n",
       "107                      2.985  \n",
       "\n",
       "[108 rows x 309 columns]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CT_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "ba556885",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 309)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CT_adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d2f733cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features:  Index(['lh_bankssts_part2_thickness',\n",
      "       'lh_caudalanteriorcingulate_part1_thickness',\n",
      "       'lh_caudalmiddlefrontal_part1_thickness',\n",
      "       'lh_caudalmiddlefrontal_part2_thickness',\n",
      "       'lh_caudalmiddlefrontal_part3_thickness',\n",
      "       'lh_caudalmiddlefrontal_part4_thickness', 'lh_cuneus_part1_thickness',\n",
      "       'lh_cuneus_part2_thickness', 'lh_entorhinal_part1_thickness',\n",
      "       'lh_fusiform_part1_thickness',\n",
      "       ...\n",
      "       'rh_supramarginal_part4_thickness', 'rh_supramarginal_part5_thickness',\n",
      "       'rh_supramarginal_part6_thickness', 'rh_supramarginal_part7_thickness',\n",
      "       'rh_frontalpole_part1_thickness', 'rh_temporalpole_part1_thickness',\n",
      "       'rh_transversetemporal_part1_thickness', 'rh_insula_part1_thickness',\n",
      "       'rh_insula_part2_thickness', 'rh_insula_part3_thickness'],\n",
      "      dtype='object', length=306)\n"
     ]
    }
   ],
   "source": [
    "#print the names of the 308 features\n",
    "\n",
    "print(\"Features: \", CT_adj.columns[2:308])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "63e68e06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:  0      1\n",
      "1      1\n",
      "2      1\n",
      "3      2\n",
      "4      2\n",
      "      ..\n",
      "103    2\n",
      "104    2\n",
      "105    2\n",
      "106    2\n",
      "107    2\n",
      "Name: Group, Length: 108, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#print the names of the labels\n",
    "\n",
    "print(\"Labels: \", CT_adj['Group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "5816ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "7901d758",
   "metadata": {},
   "outputs": [],
   "source": [
    "CT_data = CT_adj[0:308]\n",
    "CT_target = CT_adj['Group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "1a416c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(CT_data, CT_target, test_size=0.3,random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e1fffcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5ecb36b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "ddc0be18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear')"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "097f0fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "d6e43cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f51097ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "5869ab22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "adfa92b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb0d430",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c372d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c724d3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('/Users/mello/Desktop/Dataset/PARC_500.aparc_thickness_Dublin.csv', delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dab3630c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Group</th>\n",
       "      <th>lh_bankssts_part1_thickness</th>\n",
       "      <th>lh_bankssts_part2_thickness</th>\n",
       "      <th>lh_caudalanteriorcingulate_part1_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part1_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part2_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part3_thickness</th>\n",
       "      <th>...</th>\n",
       "      <th>rh_supramarginal_part5_thickness</th>\n",
       "      <th>rh_supramarginal_part6_thickness</th>\n",
       "      <th>rh_supramarginal_part7_thickness</th>\n",
       "      <th>rh_frontalpole_part1_thickness</th>\n",
       "      <th>rh_temporalpole_part1_thickness</th>\n",
       "      <th>rh_transversetemporal_part1_thickness</th>\n",
       "      <th>rh_insula_part1_thickness</th>\n",
       "      <th>rh_insula_part2_thickness</th>\n",
       "      <th>rh_insula_part3_thickness</th>\n",
       "      <th>rh_insula_part4_thickness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CON9225</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.180</td>\n",
       "      <td>2.382</td>\n",
       "      <td>2.346</td>\n",
       "      <td>2.526</td>\n",
       "      <td>2.747</td>\n",
       "      <td>2.544</td>\n",
       "      <td>...</td>\n",
       "      <td>2.817</td>\n",
       "      <td>2.325</td>\n",
       "      <td>2.430</td>\n",
       "      <td>3.004</td>\n",
       "      <td>3.979</td>\n",
       "      <td>2.329</td>\n",
       "      <td>3.620</td>\n",
       "      <td>2.776</td>\n",
       "      <td>3.282</td>\n",
       "      <td>3.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CON9229</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.394</td>\n",
       "      <td>1.973</td>\n",
       "      <td>2.534</td>\n",
       "      <td>2.439</td>\n",
       "      <td>2.485</td>\n",
       "      <td>2.435</td>\n",
       "      <td>...</td>\n",
       "      <td>2.611</td>\n",
       "      <td>2.418</td>\n",
       "      <td>2.317</td>\n",
       "      <td>2.794</td>\n",
       "      <td>3.851</td>\n",
       "      <td>2.034</td>\n",
       "      <td>3.588</td>\n",
       "      <td>2.654</td>\n",
       "      <td>3.124</td>\n",
       "      <td>3.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CON9231</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.551</td>\n",
       "      <td>2.567</td>\n",
       "      <td>1.954</td>\n",
       "      <td>2.439</td>\n",
       "      <td>2.428</td>\n",
       "      <td>2.190</td>\n",
       "      <td>...</td>\n",
       "      <td>2.777</td>\n",
       "      <td>2.309</td>\n",
       "      <td>2.390</td>\n",
       "      <td>2.365</td>\n",
       "      <td>4.039</td>\n",
       "      <td>2.337</td>\n",
       "      <td>3.657</td>\n",
       "      <td>2.495</td>\n",
       "      <td>2.669</td>\n",
       "      <td>2.886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GASP3037</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.187</td>\n",
       "      <td>1.923</td>\n",
       "      <td>2.160</td>\n",
       "      <td>2.410</td>\n",
       "      <td>2.381</td>\n",
       "      <td>2.277</td>\n",
       "      <td>...</td>\n",
       "      <td>2.265</td>\n",
       "      <td>2.306</td>\n",
       "      <td>2.129</td>\n",
       "      <td>2.281</td>\n",
       "      <td>3.505</td>\n",
       "      <td>2.275</td>\n",
       "      <td>3.121</td>\n",
       "      <td>2.333</td>\n",
       "      <td>2.604</td>\n",
       "      <td>2.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GASP3040</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.862</td>\n",
       "      <td>1.750</td>\n",
       "      <td>2.129</td>\n",
       "      <td>2.516</td>\n",
       "      <td>2.244</td>\n",
       "      <td>2.169</td>\n",
       "      <td>...</td>\n",
       "      <td>2.582</td>\n",
       "      <td>2.314</td>\n",
       "      <td>2.047</td>\n",
       "      <td>2.389</td>\n",
       "      <td>3.272</td>\n",
       "      <td>2.445</td>\n",
       "      <td>3.171</td>\n",
       "      <td>2.216</td>\n",
       "      <td>2.659</td>\n",
       "      <td>2.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>RPG9019</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.240</td>\n",
       "      <td>2.150</td>\n",
       "      <td>1.995</td>\n",
       "      <td>2.254</td>\n",
       "      <td>2.164</td>\n",
       "      <td>2.008</td>\n",
       "      <td>...</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.288</td>\n",
       "      <td>2.395</td>\n",
       "      <td>2.105</td>\n",
       "      <td>3.267</td>\n",
       "      <td>2.257</td>\n",
       "      <td>3.231</td>\n",
       "      <td>2.574</td>\n",
       "      <td>2.920</td>\n",
       "      <td>2.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>RPG9102</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.269</td>\n",
       "      <td>2.124</td>\n",
       "      <td>2.531</td>\n",
       "      <td>2.502</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.183</td>\n",
       "      <td>...</td>\n",
       "      <td>2.302</td>\n",
       "      <td>2.182</td>\n",
       "      <td>2.182</td>\n",
       "      <td>2.327</td>\n",
       "      <td>2.881</td>\n",
       "      <td>2.124</td>\n",
       "      <td>3.159</td>\n",
       "      <td>2.450</td>\n",
       "      <td>2.753</td>\n",
       "      <td>2.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>RPG9119</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.559</td>\n",
       "      <td>2.578</td>\n",
       "      <td>2.463</td>\n",
       "      <td>2.463</td>\n",
       "      <td>2.053</td>\n",
       "      <td>...</td>\n",
       "      <td>2.534</td>\n",
       "      <td>2.604</td>\n",
       "      <td>2.449</td>\n",
       "      <td>2.370</td>\n",
       "      <td>3.111</td>\n",
       "      <td>2.190</td>\n",
       "      <td>3.480</td>\n",
       "      <td>2.294</td>\n",
       "      <td>2.571</td>\n",
       "      <td>2.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>RPG9121</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.940</td>\n",
       "      <td>2.438</td>\n",
       "      <td>2.272</td>\n",
       "      <td>2.272</td>\n",
       "      <td>2.610</td>\n",
       "      <td>2.099</td>\n",
       "      <td>...</td>\n",
       "      <td>2.638</td>\n",
       "      <td>2.225</td>\n",
       "      <td>2.013</td>\n",
       "      <td>2.115</td>\n",
       "      <td>3.853</td>\n",
       "      <td>2.231</td>\n",
       "      <td>3.187</td>\n",
       "      <td>2.510</td>\n",
       "      <td>2.759</td>\n",
       "      <td>2.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>RPG9126</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.108</td>\n",
       "      <td>2.269</td>\n",
       "      <td>2.145</td>\n",
       "      <td>2.192</td>\n",
       "      <td>2.443</td>\n",
       "      <td>1.977</td>\n",
       "      <td>...</td>\n",
       "      <td>2.013</td>\n",
       "      <td>2.251</td>\n",
       "      <td>2.021</td>\n",
       "      <td>2.419</td>\n",
       "      <td>3.679</td>\n",
       "      <td>1.970</td>\n",
       "      <td>3.192</td>\n",
       "      <td>2.551</td>\n",
       "      <td>2.855</td>\n",
       "      <td>2.985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Subject ID  Age  Sex  Group  lh_bankssts_part1_thickness  \\\n",
       "0      CON9225   21    2      1                        2.180   \n",
       "1      CON9229   28    2      1                        2.394   \n",
       "2      CON9231   29    2      1                        2.551   \n",
       "3     GASP3037   61    1      2                        2.187   \n",
       "4     GASP3040   47    1      2                        1.862   \n",
       "..         ...  ...  ...    ...                          ...   \n",
       "103    RPG9019   31    1      2                        2.240   \n",
       "104    RPG9102   42    2      2                        2.269   \n",
       "105    RPG9119   41    1      2                        2.273   \n",
       "106    RPG9121   51    1      2                        1.940   \n",
       "107    RPG9126   56    1      2                        2.108   \n",
       "\n",
       "     lh_bankssts_part2_thickness  lh_caudalanteriorcingulate_part1_thickness  \\\n",
       "0                          2.382                                       2.346   \n",
       "1                          1.973                                       2.534   \n",
       "2                          2.567                                       1.954   \n",
       "3                          1.923                                       2.160   \n",
       "4                          1.750                                       2.129   \n",
       "..                           ...                                         ...   \n",
       "103                        2.150                                       1.995   \n",
       "104                        2.124                                       2.531   \n",
       "105                        2.559                                       2.578   \n",
       "106                        2.438                                       2.272   \n",
       "107                        2.269                                       2.145   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part1_thickness  \\\n",
       "0                                     2.526   \n",
       "1                                     2.439   \n",
       "2                                     2.439   \n",
       "3                                     2.410   \n",
       "4                                     2.516   \n",
       "..                                      ...   \n",
       "103                                   2.254   \n",
       "104                                   2.502   \n",
       "105                                   2.463   \n",
       "106                                   2.272   \n",
       "107                                   2.192   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part2_thickness  \\\n",
       "0                                     2.747   \n",
       "1                                     2.485   \n",
       "2                                     2.428   \n",
       "3                                     2.381   \n",
       "4                                     2.244   \n",
       "..                                      ...   \n",
       "103                                   2.164   \n",
       "104                                   2.250   \n",
       "105                                   2.463   \n",
       "106                                   2.610   \n",
       "107                                   2.443   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part3_thickness  ...  \\\n",
       "0                                     2.544  ...   \n",
       "1                                     2.435  ...   \n",
       "2                                     2.190  ...   \n",
       "3                                     2.277  ...   \n",
       "4                                     2.169  ...   \n",
       "..                                      ...  ...   \n",
       "103                                   2.008  ...   \n",
       "104                                   2.183  ...   \n",
       "105                                   2.053  ...   \n",
       "106                                   2.099  ...   \n",
       "107                                   1.977  ...   \n",
       "\n",
       "     rh_supramarginal_part5_thickness  rh_supramarginal_part6_thickness  \\\n",
       "0                               2.817                             2.325   \n",
       "1                               2.611                             2.418   \n",
       "2                               2.777                             2.309   \n",
       "3                               2.265                             2.306   \n",
       "4                               2.582                             2.314   \n",
       "..                                ...                               ...   \n",
       "103                             2.273                             2.288   \n",
       "104                             2.302                             2.182   \n",
       "105                             2.534                             2.604   \n",
       "106                             2.638                             2.225   \n",
       "107                             2.013                             2.251   \n",
       "\n",
       "     rh_supramarginal_part7_thickness  rh_frontalpole_part1_thickness  \\\n",
       "0                               2.430                           3.004   \n",
       "1                               2.317                           2.794   \n",
       "2                               2.390                           2.365   \n",
       "3                               2.129                           2.281   \n",
       "4                               2.047                           2.389   \n",
       "..                                ...                             ...   \n",
       "103                             2.395                           2.105   \n",
       "104                             2.182                           2.327   \n",
       "105                             2.449                           2.370   \n",
       "106                             2.013                           2.115   \n",
       "107                             2.021                           2.419   \n",
       "\n",
       "     rh_temporalpole_part1_thickness  rh_transversetemporal_part1_thickness  \\\n",
       "0                              3.979                                  2.329   \n",
       "1                              3.851                                  2.034   \n",
       "2                              4.039                                  2.337   \n",
       "3                              3.505                                  2.275   \n",
       "4                              3.272                                  2.445   \n",
       "..                               ...                                    ...   \n",
       "103                            3.267                                  2.257   \n",
       "104                            2.881                                  2.124   \n",
       "105                            3.111                                  2.190   \n",
       "106                            3.853                                  2.231   \n",
       "107                            3.679                                  1.970   \n",
       "\n",
       "     rh_insula_part1_thickness  rh_insula_part2_thickness  \\\n",
       "0                        3.620                      2.776   \n",
       "1                        3.588                      2.654   \n",
       "2                        3.657                      2.495   \n",
       "3                        3.121                      2.333   \n",
       "4                        3.171                      2.216   \n",
       "..                         ...                        ...   \n",
       "103                      3.231                      2.574   \n",
       "104                      3.159                      2.450   \n",
       "105                      3.480                      2.294   \n",
       "106                      3.187                      2.510   \n",
       "107                      3.192                      2.551   \n",
       "\n",
       "     rh_insula_part3_thickness  rh_insula_part4_thickness  \n",
       "0                        3.282                      3.347  \n",
       "1                        3.124                      3.214  \n",
       "2                        2.669                      2.886  \n",
       "3                        2.604                      2.731  \n",
       "4                        2.659                      2.657  \n",
       "..                         ...                        ...  \n",
       "103                      2.920                      2.899  \n",
       "104                      2.753                      2.791  \n",
       "105                      2.571                      2.875  \n",
       "106                      2.759                      2.838  \n",
       "107                      2.855                      2.985  \n",
       "\n",
       "[108 rows x 312 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cd70850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#input\n",
    "\n",
    "x = df.iloc[:,[4,308]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aaa56b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output\n",
    "\n",
    "y= df.iloc[:,[3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e73701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c728b79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.05831735e+00  6.93062141e-01]\n",
      " [-4.27525422e-01  1.07033991e+00]\n",
      " [ 3.95520787e-01  3.51715590e-01]\n",
      " [ 4.43935270e-01  7.55941768e-01]\n",
      " [-7.97236019e-01  1.29041860e+00]\n",
      " [-5.33157021e-01  1.74405020e+00]\n",
      " [-1.69510461e+00  2.38432451e-02]\n",
      " [-2.55874074e-01  1.38623518e-03]\n",
      " [ 2.98691821e-01  9.98477475e-01]\n",
      " [-4.89143855e-01 -1.19881618e-01]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_x = StandardScaler()\n",
    "xtrain = sc_x.fit_transform(X_train) \n",
    "xtest = sc_x.transform(X_test)\n",
    "  \n",
    "print(xtrain[0:10,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bb98f736",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mello/miniconda3/envs/neuro_ai/lib/python3.7/site-packages/sklearn/utils/validation.py:993: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(random_state = 0)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a3c4e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "58f882a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[19  0]\n",
      " [ 8  0]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "  \n",
    "print (\"Confusion Matrix : \\n\", cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575329aa",
   "metadata": {},
   "source": [
    "Out of 100 : \n",
    "True Positive + True Negative = 19 + 0 \n",
    "False Positive + False Negative = 0 + 8\n",
    "Performance measure – Accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "924603c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.7037037037037037\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print (\"Accuracy : \", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9a1ddaac",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 2-dimensional, but 3 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3m/1g132z9j3_14k03_9l9qv2wr0000gn/T/ipykernel_12777/1337428294.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     plt.scatter(X_set[y_set == j, 1], X_set[y_set == j, 2],\n\u001b[0m\u001b[1;32m     17\u001b[0m                 c = ListedColormap(('red', 'green'))(i), label = j)\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 2-dimensional, but 3 were indexed"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "X_set, y_set = X_test, y_test\n",
    "X1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, \n",
    "                               stop = X_set[:, 0].max() + 1, step = 0.01),\n",
    "                     np.arange(start = X_set[:, 1].min() - 1, \n",
    "                               stop = X_set[:, 1].max() + 1, step = 0.01))\n",
    "  \n",
    "plt.contourf(X1, X2, classifier.predict(\n",
    "             np.array([X1.ravel(), X2.ravel()]).T).reshape(\n",
    "             X1.shape), alpha = 0.75, cmap = ListedColormap(('red', 'green')))\n",
    "  \n",
    "plt.xlim(X1.min(), X1.max())\n",
    "plt.ylim(X2.min(), X2.max())\n",
    "  \n",
    "for i, j in enumerate(np.unique(y_set)):\n",
    "    plt.scatter(X_set[y_set == j, 1], X_set[y_set == j, 2],\n",
    "                c = ListedColormap(('red', 'green'))(i), label = j)\n",
    "      \n",
    "plt.title('Classifier (Test set)')\n",
    "plt.xlabel('Cortical Thickness')\n",
    "plt.ylabel('Diagnosis')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "26e1128e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "regplot inputs must be 1d",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/3m/1g132z9j3_14k03_9l9qv2wr0000gn/T/ipykernel_12777/3781226707.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogistic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mci\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/neuro_ai/lib/python3.7/site-packages/seaborn/_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             )\n\u001b[1;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro_ai/lib/python3.7/site-packages/seaborn/regression.py\u001b[0m in \u001b[0;36mregplot\u001b[0;34m(x, y, data, x_estimator, x_bins, x_ci, scatter, fit_reg, ci, n_boot, units, seed, order, logistic, lowess, robust, logx, x_partial, y_partial, truncate, dropna, x_jitter, y_jitter, label, color, marker, scatter_kws, line_kws, ax)\u001b[0m\n\u001b[1;32m    853\u001b[0m                                  \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogistic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlowess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrobust\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m                                  \u001b[0mx_partial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_partial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropna\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m                                  x_jitter, y_jitter, color, label)\n\u001b[0m\u001b[1;32m    856\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0max\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro_ai/lib/python3.7/site-packages/seaborn/regression.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, data, x_estimator, x_bins, x_ci, scatter, fit_reg, ci, n_boot, units, seed, order, logistic, lowess, robust, logx, x_partial, y_partial, truncate, dropna, x_jitter, y_jitter, color, label)\u001b[0m\n\u001b[1;32m    108\u001b[0m         \u001b[0;31m# Extract the data vals from the arguments or passed dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    109\u001b[0m         self.establish_variables(data, x=x, y=y, units=units,\n\u001b[0;32m--> 110\u001b[0;31m                                  x_partial=x_partial, y_partial=y_partial)\n\u001b[0m\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;31m# Drop null observations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/neuro_ai/lib/python3.7/site-packages/seaborn/regression.py\u001b[0m in \u001b[0;36mestablish_variables\u001b[0;34m(self, data, **kws)\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m                 \u001b[0merr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"regplot inputs must be 1d\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m             \u001b[0msetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvector\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: regplot inputs must be 1d"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "sns.regplot(x=x, y=y, data=df, logistic=True, ci=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "197750af2f3e6af0bfce9c7aa609a0a9c4ddab34bbe7a4296d7aadbc15871ba4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
