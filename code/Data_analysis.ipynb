{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a966c8cb",
   "metadata": {},
   "source": [
    "# Data analysis for MSc5_research_project "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f0caba",
   "metadata": {},
   "source": [
    "This jupyter notebook deals with analysing the data for my research project within the MSc05 course in the Neurocognitive Psychology lab at Goethe University Frankfurt within the psychology master degree program."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6922c12",
   "metadata": {},
   "source": [
    "Just to repeat briefly, the aim of the project is to use machine learning in order to predict whether a particpant can be classified either as control or patient with psychotic disorder based on different brain modalities. Before starting with our first modality being **cortical thickness (CT)**, the learning problem and the task type should be defined to know which model suits the best for the purpose of the project aim."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11812b4b",
   "metadata": {},
   "source": [
    "## 1. Learning problem and task type"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17eea560",
   "metadata": {},
   "source": [
    "Considering the task type, our purpose is to classify the samples in two categories being control and patient. Hence, the task type is **classification**. For that, I want to use the given information regarding the labels for each sample, consequently the learning problem is **supervised**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dd2f62",
   "metadata": {},
   "source": [
    "More specifically, with the data at hand the task type is **binary classification**. **Binary classification** refers to those classification task that have two class labels (in this data set control/patient). \n",
    "Commonly used algorithms for binary classification include **Logistic Regression, k-Nearest Neighbors, Decision Trees, Support Vector Machine and Naive Bayes** (for further information click [here](https://machinelearningmastery.com/types-of-classification-in-machine-learning/)).\n",
    "In this project, I will focus on two algorithms being **Logistic Regression** and **Support Vector Machine**. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb0d430",
   "metadata": {},
   "source": [
    "## 2. Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "150941c9",
   "metadata": {},
   "source": [
    "### 2.1 Data preperation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e032f4",
   "metadata": {},
   "source": [
    "First of all, I use CT data as my input data for the classification.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c372d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import relevant modules \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c724d3cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read data\n",
    "\n",
    "df = pd.read_csv('/Users/mello/Desktop/Dataset/PARC_500.aparc_thickness_Dublin.csv', delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dab3630c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Group</th>\n",
       "      <th>lh_bankssts_part1_thickness</th>\n",
       "      <th>lh_bankssts_part2_thickness</th>\n",
       "      <th>lh_caudalanteriorcingulate_part1_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part1_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part2_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part3_thickness</th>\n",
       "      <th>...</th>\n",
       "      <th>rh_supramarginal_part5_thickness</th>\n",
       "      <th>rh_supramarginal_part6_thickness</th>\n",
       "      <th>rh_supramarginal_part7_thickness</th>\n",
       "      <th>rh_frontalpole_part1_thickness</th>\n",
       "      <th>rh_temporalpole_part1_thickness</th>\n",
       "      <th>rh_transversetemporal_part1_thickness</th>\n",
       "      <th>rh_insula_part1_thickness</th>\n",
       "      <th>rh_insula_part2_thickness</th>\n",
       "      <th>rh_insula_part3_thickness</th>\n",
       "      <th>rh_insula_part4_thickness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CON9225</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.180</td>\n",
       "      <td>2.382</td>\n",
       "      <td>2.346</td>\n",
       "      <td>2.526</td>\n",
       "      <td>2.747</td>\n",
       "      <td>2.544</td>\n",
       "      <td>...</td>\n",
       "      <td>2.817</td>\n",
       "      <td>2.325</td>\n",
       "      <td>2.430</td>\n",
       "      <td>3.004</td>\n",
       "      <td>3.979</td>\n",
       "      <td>2.329</td>\n",
       "      <td>3.620</td>\n",
       "      <td>2.776</td>\n",
       "      <td>3.282</td>\n",
       "      <td>3.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CON9229</td>\n",
       "      <td>28</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.394</td>\n",
       "      <td>1.973</td>\n",
       "      <td>2.534</td>\n",
       "      <td>2.439</td>\n",
       "      <td>2.485</td>\n",
       "      <td>2.435</td>\n",
       "      <td>...</td>\n",
       "      <td>2.611</td>\n",
       "      <td>2.418</td>\n",
       "      <td>2.317</td>\n",
       "      <td>2.794</td>\n",
       "      <td>3.851</td>\n",
       "      <td>2.034</td>\n",
       "      <td>3.588</td>\n",
       "      <td>2.654</td>\n",
       "      <td>3.124</td>\n",
       "      <td>3.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CON9231</td>\n",
       "      <td>29</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2.551</td>\n",
       "      <td>2.567</td>\n",
       "      <td>1.954</td>\n",
       "      <td>2.439</td>\n",
       "      <td>2.428</td>\n",
       "      <td>2.190</td>\n",
       "      <td>...</td>\n",
       "      <td>2.777</td>\n",
       "      <td>2.309</td>\n",
       "      <td>2.390</td>\n",
       "      <td>2.365</td>\n",
       "      <td>4.039</td>\n",
       "      <td>2.337</td>\n",
       "      <td>3.657</td>\n",
       "      <td>2.495</td>\n",
       "      <td>2.669</td>\n",
       "      <td>2.886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GASP3037</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.187</td>\n",
       "      <td>1.923</td>\n",
       "      <td>2.160</td>\n",
       "      <td>2.410</td>\n",
       "      <td>2.381</td>\n",
       "      <td>2.277</td>\n",
       "      <td>...</td>\n",
       "      <td>2.265</td>\n",
       "      <td>2.306</td>\n",
       "      <td>2.129</td>\n",
       "      <td>2.281</td>\n",
       "      <td>3.505</td>\n",
       "      <td>2.275</td>\n",
       "      <td>3.121</td>\n",
       "      <td>2.333</td>\n",
       "      <td>2.604</td>\n",
       "      <td>2.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GASP3040</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.862</td>\n",
       "      <td>1.750</td>\n",
       "      <td>2.129</td>\n",
       "      <td>2.516</td>\n",
       "      <td>2.244</td>\n",
       "      <td>2.169</td>\n",
       "      <td>...</td>\n",
       "      <td>2.582</td>\n",
       "      <td>2.314</td>\n",
       "      <td>2.047</td>\n",
       "      <td>2.389</td>\n",
       "      <td>3.272</td>\n",
       "      <td>2.445</td>\n",
       "      <td>3.171</td>\n",
       "      <td>2.216</td>\n",
       "      <td>2.659</td>\n",
       "      <td>2.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>RPG9019</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.240</td>\n",
       "      <td>2.150</td>\n",
       "      <td>1.995</td>\n",
       "      <td>2.254</td>\n",
       "      <td>2.164</td>\n",
       "      <td>2.008</td>\n",
       "      <td>...</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.288</td>\n",
       "      <td>2.395</td>\n",
       "      <td>2.105</td>\n",
       "      <td>3.267</td>\n",
       "      <td>2.257</td>\n",
       "      <td>3.231</td>\n",
       "      <td>2.574</td>\n",
       "      <td>2.920</td>\n",
       "      <td>2.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>RPG9102</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.269</td>\n",
       "      <td>2.124</td>\n",
       "      <td>2.531</td>\n",
       "      <td>2.502</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.183</td>\n",
       "      <td>...</td>\n",
       "      <td>2.302</td>\n",
       "      <td>2.182</td>\n",
       "      <td>2.182</td>\n",
       "      <td>2.327</td>\n",
       "      <td>2.881</td>\n",
       "      <td>2.124</td>\n",
       "      <td>3.159</td>\n",
       "      <td>2.450</td>\n",
       "      <td>2.753</td>\n",
       "      <td>2.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>RPG9119</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.559</td>\n",
       "      <td>2.578</td>\n",
       "      <td>2.463</td>\n",
       "      <td>2.463</td>\n",
       "      <td>2.053</td>\n",
       "      <td>...</td>\n",
       "      <td>2.534</td>\n",
       "      <td>2.604</td>\n",
       "      <td>2.449</td>\n",
       "      <td>2.370</td>\n",
       "      <td>3.111</td>\n",
       "      <td>2.190</td>\n",
       "      <td>3.480</td>\n",
       "      <td>2.294</td>\n",
       "      <td>2.571</td>\n",
       "      <td>2.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>RPG9121</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.940</td>\n",
       "      <td>2.438</td>\n",
       "      <td>2.272</td>\n",
       "      <td>2.272</td>\n",
       "      <td>2.610</td>\n",
       "      <td>2.099</td>\n",
       "      <td>...</td>\n",
       "      <td>2.638</td>\n",
       "      <td>2.225</td>\n",
       "      <td>2.013</td>\n",
       "      <td>2.115</td>\n",
       "      <td>3.853</td>\n",
       "      <td>2.231</td>\n",
       "      <td>3.187</td>\n",
       "      <td>2.510</td>\n",
       "      <td>2.759</td>\n",
       "      <td>2.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>RPG9126</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2.108</td>\n",
       "      <td>2.269</td>\n",
       "      <td>2.145</td>\n",
       "      <td>2.192</td>\n",
       "      <td>2.443</td>\n",
       "      <td>1.977</td>\n",
       "      <td>...</td>\n",
       "      <td>2.013</td>\n",
       "      <td>2.251</td>\n",
       "      <td>2.021</td>\n",
       "      <td>2.419</td>\n",
       "      <td>3.679</td>\n",
       "      <td>1.970</td>\n",
       "      <td>3.192</td>\n",
       "      <td>2.551</td>\n",
       "      <td>2.855</td>\n",
       "      <td>2.985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 312 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Subject ID  Age  Sex  Group  lh_bankssts_part1_thickness  \\\n",
       "0      CON9225   21    2      1                        2.180   \n",
       "1      CON9229   28    2      1                        2.394   \n",
       "2      CON9231   29    2      1                        2.551   \n",
       "3     GASP3037   61    1      2                        2.187   \n",
       "4     GASP3040   47    1      2                        1.862   \n",
       "..         ...  ...  ...    ...                          ...   \n",
       "103    RPG9019   31    1      2                        2.240   \n",
       "104    RPG9102   42    2      2                        2.269   \n",
       "105    RPG9119   41    1      2                        2.273   \n",
       "106    RPG9121   51    1      2                        1.940   \n",
       "107    RPG9126   56    1      2                        2.108   \n",
       "\n",
       "     lh_bankssts_part2_thickness  lh_caudalanteriorcingulate_part1_thickness  \\\n",
       "0                          2.382                                       2.346   \n",
       "1                          1.973                                       2.534   \n",
       "2                          2.567                                       1.954   \n",
       "3                          1.923                                       2.160   \n",
       "4                          1.750                                       2.129   \n",
       "..                           ...                                         ...   \n",
       "103                        2.150                                       1.995   \n",
       "104                        2.124                                       2.531   \n",
       "105                        2.559                                       2.578   \n",
       "106                        2.438                                       2.272   \n",
       "107                        2.269                                       2.145   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part1_thickness  \\\n",
       "0                                     2.526   \n",
       "1                                     2.439   \n",
       "2                                     2.439   \n",
       "3                                     2.410   \n",
       "4                                     2.516   \n",
       "..                                      ...   \n",
       "103                                   2.254   \n",
       "104                                   2.502   \n",
       "105                                   2.463   \n",
       "106                                   2.272   \n",
       "107                                   2.192   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part2_thickness  \\\n",
       "0                                     2.747   \n",
       "1                                     2.485   \n",
       "2                                     2.428   \n",
       "3                                     2.381   \n",
       "4                                     2.244   \n",
       "..                                      ...   \n",
       "103                                   2.164   \n",
       "104                                   2.250   \n",
       "105                                   2.463   \n",
       "106                                   2.610   \n",
       "107                                   2.443   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part3_thickness  ...  \\\n",
       "0                                     2.544  ...   \n",
       "1                                     2.435  ...   \n",
       "2                                     2.190  ...   \n",
       "3                                     2.277  ...   \n",
       "4                                     2.169  ...   \n",
       "..                                      ...  ...   \n",
       "103                                   2.008  ...   \n",
       "104                                   2.183  ...   \n",
       "105                                   2.053  ...   \n",
       "106                                   2.099  ...   \n",
       "107                                   1.977  ...   \n",
       "\n",
       "     rh_supramarginal_part5_thickness  rh_supramarginal_part6_thickness  \\\n",
       "0                               2.817                             2.325   \n",
       "1                               2.611                             2.418   \n",
       "2                               2.777                             2.309   \n",
       "3                               2.265                             2.306   \n",
       "4                               2.582                             2.314   \n",
       "..                                ...                               ...   \n",
       "103                             2.273                             2.288   \n",
       "104                             2.302                             2.182   \n",
       "105                             2.534                             2.604   \n",
       "106                             2.638                             2.225   \n",
       "107                             2.013                             2.251   \n",
       "\n",
       "     rh_supramarginal_part7_thickness  rh_frontalpole_part1_thickness  \\\n",
       "0                               2.430                           3.004   \n",
       "1                               2.317                           2.794   \n",
       "2                               2.390                           2.365   \n",
       "3                               2.129                           2.281   \n",
       "4                               2.047                           2.389   \n",
       "..                                ...                             ...   \n",
       "103                             2.395                           2.105   \n",
       "104                             2.182                           2.327   \n",
       "105                             2.449                           2.370   \n",
       "106                             2.013                           2.115   \n",
       "107                             2.021                           2.419   \n",
       "\n",
       "     rh_temporalpole_part1_thickness  rh_transversetemporal_part1_thickness  \\\n",
       "0                              3.979                                  2.329   \n",
       "1                              3.851                                  2.034   \n",
       "2                              4.039                                  2.337   \n",
       "3                              3.505                                  2.275   \n",
       "4                              3.272                                  2.445   \n",
       "..                               ...                                    ...   \n",
       "103                            3.267                                  2.257   \n",
       "104                            2.881                                  2.124   \n",
       "105                            3.111                                  2.190   \n",
       "106                            3.853                                  2.231   \n",
       "107                            3.679                                  1.970   \n",
       "\n",
       "     rh_insula_part1_thickness  rh_insula_part2_thickness  \\\n",
       "0                        3.620                      2.776   \n",
       "1                        3.588                      2.654   \n",
       "2                        3.657                      2.495   \n",
       "3                        3.121                      2.333   \n",
       "4                        3.171                      2.216   \n",
       "..                         ...                        ...   \n",
       "103                      3.231                      2.574   \n",
       "104                      3.159                      2.450   \n",
       "105                      3.480                      2.294   \n",
       "106                      3.187                      2.510   \n",
       "107                      3.192                      2.551   \n",
       "\n",
       "     rh_insula_part3_thickness  rh_insula_part4_thickness  \n",
       "0                        3.282                      3.347  \n",
       "1                        3.124                      3.214  \n",
       "2                        2.669                      2.886  \n",
       "3                        2.604                      2.731  \n",
       "4                        2.659                      2.657  \n",
       "..                         ...                        ...  \n",
       "103                      2.920                      2.899  \n",
       "104                      2.753                      2.791  \n",
       "105                      2.571                      2.875  \n",
       "106                      2.759                      2.838  \n",
       "107                      2.855                      2.985  \n",
       "\n",
       "[108 rows x 312 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc679ec0",
   "metadata": {},
   "source": [
    "The data contains variables such as SubjectID, Age and Sex which are not relevant for the classification. Hence, we adjust the dataframe accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e7eaad40",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adjust dataframe\n",
    "\n",
    "df_adj = df.drop(['Subject ID','Age', 'Sex'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1277a861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>lh_bankssts_part1_thickness</th>\n",
       "      <th>lh_bankssts_part2_thickness</th>\n",
       "      <th>lh_caudalanteriorcingulate_part1_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part1_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part2_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part3_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part4_thickness</th>\n",
       "      <th>lh_cuneus_part1_thickness</th>\n",
       "      <th>lh_cuneus_part2_thickness</th>\n",
       "      <th>...</th>\n",
       "      <th>rh_supramarginal_part5_thickness</th>\n",
       "      <th>rh_supramarginal_part6_thickness</th>\n",
       "      <th>rh_supramarginal_part7_thickness</th>\n",
       "      <th>rh_frontalpole_part1_thickness</th>\n",
       "      <th>rh_temporalpole_part1_thickness</th>\n",
       "      <th>rh_transversetemporal_part1_thickness</th>\n",
       "      <th>rh_insula_part1_thickness</th>\n",
       "      <th>rh_insula_part2_thickness</th>\n",
       "      <th>rh_insula_part3_thickness</th>\n",
       "      <th>rh_insula_part4_thickness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2.180</td>\n",
       "      <td>2.382</td>\n",
       "      <td>2.346</td>\n",
       "      <td>2.526</td>\n",
       "      <td>2.747</td>\n",
       "      <td>2.544</td>\n",
       "      <td>2.582</td>\n",
       "      <td>1.816</td>\n",
       "      <td>2.228</td>\n",
       "      <td>...</td>\n",
       "      <td>2.817</td>\n",
       "      <td>2.325</td>\n",
       "      <td>2.430</td>\n",
       "      <td>3.004</td>\n",
       "      <td>3.979</td>\n",
       "      <td>2.329</td>\n",
       "      <td>3.620</td>\n",
       "      <td>2.776</td>\n",
       "      <td>3.282</td>\n",
       "      <td>3.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2.394</td>\n",
       "      <td>1.973</td>\n",
       "      <td>2.534</td>\n",
       "      <td>2.439</td>\n",
       "      <td>2.485</td>\n",
       "      <td>2.435</td>\n",
       "      <td>2.458</td>\n",
       "      <td>1.723</td>\n",
       "      <td>1.821</td>\n",
       "      <td>...</td>\n",
       "      <td>2.611</td>\n",
       "      <td>2.418</td>\n",
       "      <td>2.317</td>\n",
       "      <td>2.794</td>\n",
       "      <td>3.851</td>\n",
       "      <td>2.034</td>\n",
       "      <td>3.588</td>\n",
       "      <td>2.654</td>\n",
       "      <td>3.124</td>\n",
       "      <td>3.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2.551</td>\n",
       "      <td>2.567</td>\n",
       "      <td>1.954</td>\n",
       "      <td>2.439</td>\n",
       "      <td>2.428</td>\n",
       "      <td>2.190</td>\n",
       "      <td>2.377</td>\n",
       "      <td>2.026</td>\n",
       "      <td>1.800</td>\n",
       "      <td>...</td>\n",
       "      <td>2.777</td>\n",
       "      <td>2.309</td>\n",
       "      <td>2.390</td>\n",
       "      <td>2.365</td>\n",
       "      <td>4.039</td>\n",
       "      <td>2.337</td>\n",
       "      <td>3.657</td>\n",
       "      <td>2.495</td>\n",
       "      <td>2.669</td>\n",
       "      <td>2.886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>2.187</td>\n",
       "      <td>1.923</td>\n",
       "      <td>2.160</td>\n",
       "      <td>2.410</td>\n",
       "      <td>2.381</td>\n",
       "      <td>2.277</td>\n",
       "      <td>2.361</td>\n",
       "      <td>1.585</td>\n",
       "      <td>1.750</td>\n",
       "      <td>...</td>\n",
       "      <td>2.265</td>\n",
       "      <td>2.306</td>\n",
       "      <td>2.129</td>\n",
       "      <td>2.281</td>\n",
       "      <td>3.505</td>\n",
       "      <td>2.275</td>\n",
       "      <td>3.121</td>\n",
       "      <td>2.333</td>\n",
       "      <td>2.604</td>\n",
       "      <td>2.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1.862</td>\n",
       "      <td>1.750</td>\n",
       "      <td>2.129</td>\n",
       "      <td>2.516</td>\n",
       "      <td>2.244</td>\n",
       "      <td>2.169</td>\n",
       "      <td>2.220</td>\n",
       "      <td>1.646</td>\n",
       "      <td>1.717</td>\n",
       "      <td>...</td>\n",
       "      <td>2.582</td>\n",
       "      <td>2.314</td>\n",
       "      <td>2.047</td>\n",
       "      <td>2.389</td>\n",
       "      <td>3.272</td>\n",
       "      <td>2.445</td>\n",
       "      <td>3.171</td>\n",
       "      <td>2.216</td>\n",
       "      <td>2.659</td>\n",
       "      <td>2.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2</td>\n",
       "      <td>2.240</td>\n",
       "      <td>2.150</td>\n",
       "      <td>1.995</td>\n",
       "      <td>2.254</td>\n",
       "      <td>2.164</td>\n",
       "      <td>2.008</td>\n",
       "      <td>2.298</td>\n",
       "      <td>1.918</td>\n",
       "      <td>1.717</td>\n",
       "      <td>...</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.288</td>\n",
       "      <td>2.395</td>\n",
       "      <td>2.105</td>\n",
       "      <td>3.267</td>\n",
       "      <td>2.257</td>\n",
       "      <td>3.231</td>\n",
       "      <td>2.574</td>\n",
       "      <td>2.920</td>\n",
       "      <td>2.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2</td>\n",
       "      <td>2.269</td>\n",
       "      <td>2.124</td>\n",
       "      <td>2.531</td>\n",
       "      <td>2.502</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.183</td>\n",
       "      <td>2.408</td>\n",
       "      <td>1.539</td>\n",
       "      <td>1.611</td>\n",
       "      <td>...</td>\n",
       "      <td>2.302</td>\n",
       "      <td>2.182</td>\n",
       "      <td>2.182</td>\n",
       "      <td>2.327</td>\n",
       "      <td>2.881</td>\n",
       "      <td>2.124</td>\n",
       "      <td>3.159</td>\n",
       "      <td>2.450</td>\n",
       "      <td>2.753</td>\n",
       "      <td>2.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.559</td>\n",
       "      <td>2.578</td>\n",
       "      <td>2.463</td>\n",
       "      <td>2.463</td>\n",
       "      <td>2.053</td>\n",
       "      <td>2.526</td>\n",
       "      <td>1.733</td>\n",
       "      <td>1.859</td>\n",
       "      <td>...</td>\n",
       "      <td>2.534</td>\n",
       "      <td>2.604</td>\n",
       "      <td>2.449</td>\n",
       "      <td>2.370</td>\n",
       "      <td>3.111</td>\n",
       "      <td>2.190</td>\n",
       "      <td>3.480</td>\n",
       "      <td>2.294</td>\n",
       "      <td>2.571</td>\n",
       "      <td>2.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2</td>\n",
       "      <td>1.940</td>\n",
       "      <td>2.438</td>\n",
       "      <td>2.272</td>\n",
       "      <td>2.272</td>\n",
       "      <td>2.610</td>\n",
       "      <td>2.099</td>\n",
       "      <td>2.538</td>\n",
       "      <td>1.931</td>\n",
       "      <td>1.792</td>\n",
       "      <td>...</td>\n",
       "      <td>2.638</td>\n",
       "      <td>2.225</td>\n",
       "      <td>2.013</td>\n",
       "      <td>2.115</td>\n",
       "      <td>3.853</td>\n",
       "      <td>2.231</td>\n",
       "      <td>3.187</td>\n",
       "      <td>2.510</td>\n",
       "      <td>2.759</td>\n",
       "      <td>2.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>2</td>\n",
       "      <td>2.108</td>\n",
       "      <td>2.269</td>\n",
       "      <td>2.145</td>\n",
       "      <td>2.192</td>\n",
       "      <td>2.443</td>\n",
       "      <td>1.977</td>\n",
       "      <td>2.453</td>\n",
       "      <td>1.590</td>\n",
       "      <td>1.715</td>\n",
       "      <td>...</td>\n",
       "      <td>2.013</td>\n",
       "      <td>2.251</td>\n",
       "      <td>2.021</td>\n",
       "      <td>2.419</td>\n",
       "      <td>3.679</td>\n",
       "      <td>1.970</td>\n",
       "      <td>3.192</td>\n",
       "      <td>2.551</td>\n",
       "      <td>2.855</td>\n",
       "      <td>2.985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 309 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Group  lh_bankssts_part1_thickness  lh_bankssts_part2_thickness  \\\n",
       "0        1                        2.180                        2.382   \n",
       "1        1                        2.394                        1.973   \n",
       "2        1                        2.551                        2.567   \n",
       "3        2                        2.187                        1.923   \n",
       "4        2                        1.862                        1.750   \n",
       "..     ...                          ...                          ...   \n",
       "103      2                        2.240                        2.150   \n",
       "104      2                        2.269                        2.124   \n",
       "105      2                        2.273                        2.559   \n",
       "106      2                        1.940                        2.438   \n",
       "107      2                        2.108                        2.269   \n",
       "\n",
       "     lh_caudalanteriorcingulate_part1_thickness  \\\n",
       "0                                         2.346   \n",
       "1                                         2.534   \n",
       "2                                         1.954   \n",
       "3                                         2.160   \n",
       "4                                         2.129   \n",
       "..                                          ...   \n",
       "103                                       1.995   \n",
       "104                                       2.531   \n",
       "105                                       2.578   \n",
       "106                                       2.272   \n",
       "107                                       2.145   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part1_thickness  \\\n",
       "0                                     2.526   \n",
       "1                                     2.439   \n",
       "2                                     2.439   \n",
       "3                                     2.410   \n",
       "4                                     2.516   \n",
       "..                                      ...   \n",
       "103                                   2.254   \n",
       "104                                   2.502   \n",
       "105                                   2.463   \n",
       "106                                   2.272   \n",
       "107                                   2.192   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part2_thickness  \\\n",
       "0                                     2.747   \n",
       "1                                     2.485   \n",
       "2                                     2.428   \n",
       "3                                     2.381   \n",
       "4                                     2.244   \n",
       "..                                      ...   \n",
       "103                                   2.164   \n",
       "104                                   2.250   \n",
       "105                                   2.463   \n",
       "106                                   2.610   \n",
       "107                                   2.443   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part3_thickness  \\\n",
       "0                                     2.544   \n",
       "1                                     2.435   \n",
       "2                                     2.190   \n",
       "3                                     2.277   \n",
       "4                                     2.169   \n",
       "..                                      ...   \n",
       "103                                   2.008   \n",
       "104                                   2.183   \n",
       "105                                   2.053   \n",
       "106                                   2.099   \n",
       "107                                   1.977   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part4_thickness  lh_cuneus_part1_thickness  \\\n",
       "0                                     2.582                      1.816   \n",
       "1                                     2.458                      1.723   \n",
       "2                                     2.377                      2.026   \n",
       "3                                     2.361                      1.585   \n",
       "4                                     2.220                      1.646   \n",
       "..                                      ...                        ...   \n",
       "103                                   2.298                      1.918   \n",
       "104                                   2.408                      1.539   \n",
       "105                                   2.526                      1.733   \n",
       "106                                   2.538                      1.931   \n",
       "107                                   2.453                      1.590   \n",
       "\n",
       "     lh_cuneus_part2_thickness  ...  rh_supramarginal_part5_thickness  \\\n",
       "0                        2.228  ...                             2.817   \n",
       "1                        1.821  ...                             2.611   \n",
       "2                        1.800  ...                             2.777   \n",
       "3                        1.750  ...                             2.265   \n",
       "4                        1.717  ...                             2.582   \n",
       "..                         ...  ...                               ...   \n",
       "103                      1.717  ...                             2.273   \n",
       "104                      1.611  ...                             2.302   \n",
       "105                      1.859  ...                             2.534   \n",
       "106                      1.792  ...                             2.638   \n",
       "107                      1.715  ...                             2.013   \n",
       "\n",
       "     rh_supramarginal_part6_thickness  rh_supramarginal_part7_thickness  \\\n",
       "0                               2.325                             2.430   \n",
       "1                               2.418                             2.317   \n",
       "2                               2.309                             2.390   \n",
       "3                               2.306                             2.129   \n",
       "4                               2.314                             2.047   \n",
       "..                                ...                               ...   \n",
       "103                             2.288                             2.395   \n",
       "104                             2.182                             2.182   \n",
       "105                             2.604                             2.449   \n",
       "106                             2.225                             2.013   \n",
       "107                             2.251                             2.021   \n",
       "\n",
       "     rh_frontalpole_part1_thickness  rh_temporalpole_part1_thickness  \\\n",
       "0                             3.004                            3.979   \n",
       "1                             2.794                            3.851   \n",
       "2                             2.365                            4.039   \n",
       "3                             2.281                            3.505   \n",
       "4                             2.389                            3.272   \n",
       "..                              ...                              ...   \n",
       "103                           2.105                            3.267   \n",
       "104                           2.327                            2.881   \n",
       "105                           2.370                            3.111   \n",
       "106                           2.115                            3.853   \n",
       "107                           2.419                            3.679   \n",
       "\n",
       "     rh_transversetemporal_part1_thickness  rh_insula_part1_thickness  \\\n",
       "0                                    2.329                      3.620   \n",
       "1                                    2.034                      3.588   \n",
       "2                                    2.337                      3.657   \n",
       "3                                    2.275                      3.121   \n",
       "4                                    2.445                      3.171   \n",
       "..                                     ...                        ...   \n",
       "103                                  2.257                      3.231   \n",
       "104                                  2.124                      3.159   \n",
       "105                                  2.190                      3.480   \n",
       "106                                  2.231                      3.187   \n",
       "107                                  1.970                      3.192   \n",
       "\n",
       "     rh_insula_part2_thickness  rh_insula_part3_thickness  \\\n",
       "0                        2.776                      3.282   \n",
       "1                        2.654                      3.124   \n",
       "2                        2.495                      2.669   \n",
       "3                        2.333                      2.604   \n",
       "4                        2.216                      2.659   \n",
       "..                         ...                        ...   \n",
       "103                      2.574                      2.920   \n",
       "104                      2.450                      2.753   \n",
       "105                      2.294                      2.571   \n",
       "106                      2.510                      2.759   \n",
       "107                      2.551                      2.855   \n",
       "\n",
       "     rh_insula_part4_thickness  \n",
       "0                        3.347  \n",
       "1                        3.214  \n",
       "2                        2.886  \n",
       "3                        2.731  \n",
       "4                        2.657  \n",
       "..                         ...  \n",
       "103                      2.899  \n",
       "104                      2.791  \n",
       "105                      2.875  \n",
       "106                      2.838  \n",
       "107                      2.985  \n",
       "\n",
       "[108 rows x 309 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adj"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "074688be",
   "metadata": {},
   "source": [
    "As the dataframe shows, the Group variable contains information of whether the samples belong to control or patient. In this case, 1 indicates control and 2 patient. In order to perform a **Logistic Regression**, the labels of the outputs requires to be 0 and 1 since the probability of an instance belonging to a default class is computed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aca4d140",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label group 1 as 0 and 2 as 1\n",
    "\n",
    "df_adj['Group'] = df_adj['Group'].replace([1,2],[0, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "408610ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Group</th>\n",
       "      <th>lh_bankssts_part1_thickness</th>\n",
       "      <th>lh_bankssts_part2_thickness</th>\n",
       "      <th>lh_caudalanteriorcingulate_part1_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part1_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part2_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part3_thickness</th>\n",
       "      <th>lh_caudalmiddlefrontal_part4_thickness</th>\n",
       "      <th>lh_cuneus_part1_thickness</th>\n",
       "      <th>lh_cuneus_part2_thickness</th>\n",
       "      <th>...</th>\n",
       "      <th>rh_supramarginal_part5_thickness</th>\n",
       "      <th>rh_supramarginal_part6_thickness</th>\n",
       "      <th>rh_supramarginal_part7_thickness</th>\n",
       "      <th>rh_frontalpole_part1_thickness</th>\n",
       "      <th>rh_temporalpole_part1_thickness</th>\n",
       "      <th>rh_transversetemporal_part1_thickness</th>\n",
       "      <th>rh_insula_part1_thickness</th>\n",
       "      <th>rh_insula_part2_thickness</th>\n",
       "      <th>rh_insula_part3_thickness</th>\n",
       "      <th>rh_insula_part4_thickness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2.180</td>\n",
       "      <td>2.382</td>\n",
       "      <td>2.346</td>\n",
       "      <td>2.526</td>\n",
       "      <td>2.747</td>\n",
       "      <td>2.544</td>\n",
       "      <td>2.582</td>\n",
       "      <td>1.816</td>\n",
       "      <td>2.228</td>\n",
       "      <td>...</td>\n",
       "      <td>2.817</td>\n",
       "      <td>2.325</td>\n",
       "      <td>2.430</td>\n",
       "      <td>3.004</td>\n",
       "      <td>3.979</td>\n",
       "      <td>2.329</td>\n",
       "      <td>3.620</td>\n",
       "      <td>2.776</td>\n",
       "      <td>3.282</td>\n",
       "      <td>3.347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2.394</td>\n",
       "      <td>1.973</td>\n",
       "      <td>2.534</td>\n",
       "      <td>2.439</td>\n",
       "      <td>2.485</td>\n",
       "      <td>2.435</td>\n",
       "      <td>2.458</td>\n",
       "      <td>1.723</td>\n",
       "      <td>1.821</td>\n",
       "      <td>...</td>\n",
       "      <td>2.611</td>\n",
       "      <td>2.418</td>\n",
       "      <td>2.317</td>\n",
       "      <td>2.794</td>\n",
       "      <td>3.851</td>\n",
       "      <td>2.034</td>\n",
       "      <td>3.588</td>\n",
       "      <td>2.654</td>\n",
       "      <td>3.124</td>\n",
       "      <td>3.214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>2.551</td>\n",
       "      <td>2.567</td>\n",
       "      <td>1.954</td>\n",
       "      <td>2.439</td>\n",
       "      <td>2.428</td>\n",
       "      <td>2.190</td>\n",
       "      <td>2.377</td>\n",
       "      <td>2.026</td>\n",
       "      <td>1.800</td>\n",
       "      <td>...</td>\n",
       "      <td>2.777</td>\n",
       "      <td>2.309</td>\n",
       "      <td>2.390</td>\n",
       "      <td>2.365</td>\n",
       "      <td>4.039</td>\n",
       "      <td>2.337</td>\n",
       "      <td>3.657</td>\n",
       "      <td>2.495</td>\n",
       "      <td>2.669</td>\n",
       "      <td>2.886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2.187</td>\n",
       "      <td>1.923</td>\n",
       "      <td>2.160</td>\n",
       "      <td>2.410</td>\n",
       "      <td>2.381</td>\n",
       "      <td>2.277</td>\n",
       "      <td>2.361</td>\n",
       "      <td>1.585</td>\n",
       "      <td>1.750</td>\n",
       "      <td>...</td>\n",
       "      <td>2.265</td>\n",
       "      <td>2.306</td>\n",
       "      <td>2.129</td>\n",
       "      <td>2.281</td>\n",
       "      <td>3.505</td>\n",
       "      <td>2.275</td>\n",
       "      <td>3.121</td>\n",
       "      <td>2.333</td>\n",
       "      <td>2.604</td>\n",
       "      <td>2.731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1.862</td>\n",
       "      <td>1.750</td>\n",
       "      <td>2.129</td>\n",
       "      <td>2.516</td>\n",
       "      <td>2.244</td>\n",
       "      <td>2.169</td>\n",
       "      <td>2.220</td>\n",
       "      <td>1.646</td>\n",
       "      <td>1.717</td>\n",
       "      <td>...</td>\n",
       "      <td>2.582</td>\n",
       "      <td>2.314</td>\n",
       "      <td>2.047</td>\n",
       "      <td>2.389</td>\n",
       "      <td>3.272</td>\n",
       "      <td>2.445</td>\n",
       "      <td>3.171</td>\n",
       "      <td>2.216</td>\n",
       "      <td>2.659</td>\n",
       "      <td>2.657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>1</td>\n",
       "      <td>2.240</td>\n",
       "      <td>2.150</td>\n",
       "      <td>1.995</td>\n",
       "      <td>2.254</td>\n",
       "      <td>2.164</td>\n",
       "      <td>2.008</td>\n",
       "      <td>2.298</td>\n",
       "      <td>1.918</td>\n",
       "      <td>1.717</td>\n",
       "      <td>...</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.288</td>\n",
       "      <td>2.395</td>\n",
       "      <td>2.105</td>\n",
       "      <td>3.267</td>\n",
       "      <td>2.257</td>\n",
       "      <td>3.231</td>\n",
       "      <td>2.574</td>\n",
       "      <td>2.920</td>\n",
       "      <td>2.899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>1</td>\n",
       "      <td>2.269</td>\n",
       "      <td>2.124</td>\n",
       "      <td>2.531</td>\n",
       "      <td>2.502</td>\n",
       "      <td>2.250</td>\n",
       "      <td>2.183</td>\n",
       "      <td>2.408</td>\n",
       "      <td>1.539</td>\n",
       "      <td>1.611</td>\n",
       "      <td>...</td>\n",
       "      <td>2.302</td>\n",
       "      <td>2.182</td>\n",
       "      <td>2.182</td>\n",
       "      <td>2.327</td>\n",
       "      <td>2.881</td>\n",
       "      <td>2.124</td>\n",
       "      <td>3.159</td>\n",
       "      <td>2.450</td>\n",
       "      <td>2.753</td>\n",
       "      <td>2.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>1</td>\n",
       "      <td>2.273</td>\n",
       "      <td>2.559</td>\n",
       "      <td>2.578</td>\n",
       "      <td>2.463</td>\n",
       "      <td>2.463</td>\n",
       "      <td>2.053</td>\n",
       "      <td>2.526</td>\n",
       "      <td>1.733</td>\n",
       "      <td>1.859</td>\n",
       "      <td>...</td>\n",
       "      <td>2.534</td>\n",
       "      <td>2.604</td>\n",
       "      <td>2.449</td>\n",
       "      <td>2.370</td>\n",
       "      <td>3.111</td>\n",
       "      <td>2.190</td>\n",
       "      <td>3.480</td>\n",
       "      <td>2.294</td>\n",
       "      <td>2.571</td>\n",
       "      <td>2.875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>1</td>\n",
       "      <td>1.940</td>\n",
       "      <td>2.438</td>\n",
       "      <td>2.272</td>\n",
       "      <td>2.272</td>\n",
       "      <td>2.610</td>\n",
       "      <td>2.099</td>\n",
       "      <td>2.538</td>\n",
       "      <td>1.931</td>\n",
       "      <td>1.792</td>\n",
       "      <td>...</td>\n",
       "      <td>2.638</td>\n",
       "      <td>2.225</td>\n",
       "      <td>2.013</td>\n",
       "      <td>2.115</td>\n",
       "      <td>3.853</td>\n",
       "      <td>2.231</td>\n",
       "      <td>3.187</td>\n",
       "      <td>2.510</td>\n",
       "      <td>2.759</td>\n",
       "      <td>2.838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>1</td>\n",
       "      <td>2.108</td>\n",
       "      <td>2.269</td>\n",
       "      <td>2.145</td>\n",
       "      <td>2.192</td>\n",
       "      <td>2.443</td>\n",
       "      <td>1.977</td>\n",
       "      <td>2.453</td>\n",
       "      <td>1.590</td>\n",
       "      <td>1.715</td>\n",
       "      <td>...</td>\n",
       "      <td>2.013</td>\n",
       "      <td>2.251</td>\n",
       "      <td>2.021</td>\n",
       "      <td>2.419</td>\n",
       "      <td>3.679</td>\n",
       "      <td>1.970</td>\n",
       "      <td>3.192</td>\n",
       "      <td>2.551</td>\n",
       "      <td>2.855</td>\n",
       "      <td>2.985</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>108 rows × 309 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Group  lh_bankssts_part1_thickness  lh_bankssts_part2_thickness  \\\n",
       "0        0                        2.180                        2.382   \n",
       "1        0                        2.394                        1.973   \n",
       "2        0                        2.551                        2.567   \n",
       "3        1                        2.187                        1.923   \n",
       "4        1                        1.862                        1.750   \n",
       "..     ...                          ...                          ...   \n",
       "103      1                        2.240                        2.150   \n",
       "104      1                        2.269                        2.124   \n",
       "105      1                        2.273                        2.559   \n",
       "106      1                        1.940                        2.438   \n",
       "107      1                        2.108                        2.269   \n",
       "\n",
       "     lh_caudalanteriorcingulate_part1_thickness  \\\n",
       "0                                         2.346   \n",
       "1                                         2.534   \n",
       "2                                         1.954   \n",
       "3                                         2.160   \n",
       "4                                         2.129   \n",
       "..                                          ...   \n",
       "103                                       1.995   \n",
       "104                                       2.531   \n",
       "105                                       2.578   \n",
       "106                                       2.272   \n",
       "107                                       2.145   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part1_thickness  \\\n",
       "0                                     2.526   \n",
       "1                                     2.439   \n",
       "2                                     2.439   \n",
       "3                                     2.410   \n",
       "4                                     2.516   \n",
       "..                                      ...   \n",
       "103                                   2.254   \n",
       "104                                   2.502   \n",
       "105                                   2.463   \n",
       "106                                   2.272   \n",
       "107                                   2.192   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part2_thickness  \\\n",
       "0                                     2.747   \n",
       "1                                     2.485   \n",
       "2                                     2.428   \n",
       "3                                     2.381   \n",
       "4                                     2.244   \n",
       "..                                      ...   \n",
       "103                                   2.164   \n",
       "104                                   2.250   \n",
       "105                                   2.463   \n",
       "106                                   2.610   \n",
       "107                                   2.443   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part3_thickness  \\\n",
       "0                                     2.544   \n",
       "1                                     2.435   \n",
       "2                                     2.190   \n",
       "3                                     2.277   \n",
       "4                                     2.169   \n",
       "..                                      ...   \n",
       "103                                   2.008   \n",
       "104                                   2.183   \n",
       "105                                   2.053   \n",
       "106                                   2.099   \n",
       "107                                   1.977   \n",
       "\n",
       "     lh_caudalmiddlefrontal_part4_thickness  lh_cuneus_part1_thickness  \\\n",
       "0                                     2.582                      1.816   \n",
       "1                                     2.458                      1.723   \n",
       "2                                     2.377                      2.026   \n",
       "3                                     2.361                      1.585   \n",
       "4                                     2.220                      1.646   \n",
       "..                                      ...                        ...   \n",
       "103                                   2.298                      1.918   \n",
       "104                                   2.408                      1.539   \n",
       "105                                   2.526                      1.733   \n",
       "106                                   2.538                      1.931   \n",
       "107                                   2.453                      1.590   \n",
       "\n",
       "     lh_cuneus_part2_thickness  ...  rh_supramarginal_part5_thickness  \\\n",
       "0                        2.228  ...                             2.817   \n",
       "1                        1.821  ...                             2.611   \n",
       "2                        1.800  ...                             2.777   \n",
       "3                        1.750  ...                             2.265   \n",
       "4                        1.717  ...                             2.582   \n",
       "..                         ...  ...                               ...   \n",
       "103                      1.717  ...                             2.273   \n",
       "104                      1.611  ...                             2.302   \n",
       "105                      1.859  ...                             2.534   \n",
       "106                      1.792  ...                             2.638   \n",
       "107                      1.715  ...                             2.013   \n",
       "\n",
       "     rh_supramarginal_part6_thickness  rh_supramarginal_part7_thickness  \\\n",
       "0                               2.325                             2.430   \n",
       "1                               2.418                             2.317   \n",
       "2                               2.309                             2.390   \n",
       "3                               2.306                             2.129   \n",
       "4                               2.314                             2.047   \n",
       "..                                ...                               ...   \n",
       "103                             2.288                             2.395   \n",
       "104                             2.182                             2.182   \n",
       "105                             2.604                             2.449   \n",
       "106                             2.225                             2.013   \n",
       "107                             2.251                             2.021   \n",
       "\n",
       "     rh_frontalpole_part1_thickness  rh_temporalpole_part1_thickness  \\\n",
       "0                             3.004                            3.979   \n",
       "1                             2.794                            3.851   \n",
       "2                             2.365                            4.039   \n",
       "3                             2.281                            3.505   \n",
       "4                             2.389                            3.272   \n",
       "..                              ...                              ...   \n",
       "103                           2.105                            3.267   \n",
       "104                           2.327                            2.881   \n",
       "105                           2.370                            3.111   \n",
       "106                           2.115                            3.853   \n",
       "107                           2.419                            3.679   \n",
       "\n",
       "     rh_transversetemporal_part1_thickness  rh_insula_part1_thickness  \\\n",
       "0                                    2.329                      3.620   \n",
       "1                                    2.034                      3.588   \n",
       "2                                    2.337                      3.657   \n",
       "3                                    2.275                      3.121   \n",
       "4                                    2.445                      3.171   \n",
       "..                                     ...                        ...   \n",
       "103                                  2.257                      3.231   \n",
       "104                                  2.124                      3.159   \n",
       "105                                  2.190                      3.480   \n",
       "106                                  2.231                      3.187   \n",
       "107                                  1.970                      3.192   \n",
       "\n",
       "     rh_insula_part2_thickness  rh_insula_part3_thickness  \\\n",
       "0                        2.776                      3.282   \n",
       "1                        2.654                      3.124   \n",
       "2                        2.495                      2.669   \n",
       "3                        2.333                      2.604   \n",
       "4                        2.216                      2.659   \n",
       "..                         ...                        ...   \n",
       "103                      2.574                      2.920   \n",
       "104                      2.450                      2.753   \n",
       "105                      2.294                      2.571   \n",
       "106                      2.510                      2.759   \n",
       "107                      2.551                      2.855   \n",
       "\n",
       "     rh_insula_part4_thickness  \n",
       "0                        3.347  \n",
       "1                        3.214  \n",
       "2                        2.886  \n",
       "3                        2.731  \n",
       "4                        2.657  \n",
       "..                         ...  \n",
       "103                      2.899  \n",
       "104                      2.791  \n",
       "105                      2.875  \n",
       "106                      2.838  \n",
       "107                      2.985  \n",
       "\n",
       "[108 rows x 309 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "402f2a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 309)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#get shape of df_adj\n",
    "\n",
    "df_adj.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e598579",
   "metadata": {},
   "source": [
    "To get an idea of how many of the participants belong to control and patient group and to plot that we can simply execute the following commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83e4153e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    80\n",
       "1    28\n",
       "Name: Group, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_adj['Group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4aeeb7ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='Group', ylabel='count'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='Group', data = df_adj, palette='hls')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9b23c0",
   "metadata": {},
   "source": [
    "The plot shows a clear unequal distribution of the participants in the Group variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3996d6",
   "metadata": {},
   "source": [
    "Because the LogisticRegression function from sklearn requires the inputs to be numpy arrays, in the following step the dataframe is converted to a numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c20c482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.   , 2.18 , 2.382, ..., 2.776, 3.282, 3.347],\n",
       "       [0.   , 2.394, 1.973, ..., 2.654, 3.124, 3.214],\n",
       "       [0.   , 2.551, 2.567, ..., 2.495, 2.669, 2.886],\n",
       "       ...,\n",
       "       [1.   , 2.273, 2.559, ..., 2.294, 2.571, 2.875],\n",
       "       [1.   , 1.94 , 2.438, ..., 2.51 , 2.759, 2.838],\n",
       "       [1.   , 2.108, 2.269, ..., 2.551, 2.855, 2.985]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#dataframe as numpy array \n",
    "\n",
    "df_adj.to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5998c14a",
   "metadata": {},
   "source": [
    "### 2.2 Building the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e7df3f",
   "metadata": {},
   "source": [
    "In the next steps, the **logistic regression** model is built. Firstly, the input and output should be defined. Our input contains the **CT** for all of the 308 brain regions, meaning that there are n=308 features in total. The output is within the Group variable containing label information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cd70850",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define input\n",
    "\n",
    "X = df_adj.iloc[:,1:308].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a858fdd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.18 , 2.382, 2.346, ..., 3.62 , 2.776, 3.282],\n",
       "       [2.394, 1.973, 2.534, ..., 3.588, 2.654, 3.124],\n",
       "       [2.551, 2.567, 1.954, ..., 3.657, 2.495, 2.669],\n",
       "       ...,\n",
       "       [2.273, 2.559, 2.578, ..., 3.48 , 2.294, 2.571],\n",
       "       [1.94 , 2.438, 2.272, ..., 3.187, 2.51 , 2.759],\n",
       "       [2.108, 2.269, 2.145, ..., 3.192, 2.551, 2.855]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d44d0e78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 307)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaa56b67",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output\n",
    "\n",
    "y = df_adj.iloc[:,[0]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "73f341d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1],\n",
       "       [1]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0d23e00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108, 1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5377250a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6401e42c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(108,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6e73701b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c728b79f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.05831735  1.57472533  0.97751966 ...  0.69306214 -0.43012507\n",
      "   1.3016343 ]\n",
      " [-0.42752542  0.49195636  0.98566147 ...  1.07033991  2.01003971\n",
      "   1.46144259]\n",
      " [ 0.39552079 -1.33548374 -0.27631893 ...  0.35171559  1.52940119\n",
      "  -0.4653888 ]\n",
      " ...\n",
      " [ 0.48354712  1.22378835  0.41980575 ...  1.0613571  -0.78341492\n",
      "   0.96375391]\n",
      " [ 0.5055537  -0.06012741  0.48086931 ... -0.0884418   0.73244502\n",
      "   0.21493792]\n",
      " [-1.56746643 -0.52233709 -2.69850711 ... -0.38038293  0.2887787\n",
      "  -0.21882744]]\n",
      "[[ 0.47034317 -0.3468686  -1.8761844  ... -1.04511043 -1.42837429\n",
      "  -0.92654987]\n",
      " [ 1.42102756 -0.2569945  -1.82733354 ...  0.29332736 -0.27402025\n",
      "  -1.33748547]\n",
      " [ 0.80484323  1.75447353 -0.92766365 ...  0.61670831  0.21483431\n",
      "  -0.15490412]\n",
      " ...\n",
      " [-0.19425564  0.60750878  0.87981796 ...  1.43863487 -0.17953575\n",
      "  -0.29644861]\n",
      " [-0.64318994 -1.69070043 -1.14342159 ... -1.47179362 -1.2969176\n",
      "  -1.80777844]\n",
      " [-0.26027539  0.48767665  1.35204288 ... -0.09293321  0.55169207\n",
      "   1.42034903]]\n"
     ]
    }
   ],
   "source": [
    "sc_x = StandardScaler()\n",
    "xtrain = sc_x.fit_transform(X_train) \n",
    "xtest = sc_x.transform(X_test)\n",
    "  \n",
    "print(xtrain)\n",
    "print(xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bb98f736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0, solver='liblinear')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = LogisticRegression(random_state = 0, solver ='liblinear')\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dea38f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred=classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1ce39e57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d487eed3",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610c1784",
   "metadata": {},
   "source": [
    "In the next step, the model is evaluated. To evaluate the model, a look at the **confusion matrix** is helpful. The **confusion matrix** provides information on the quality of the logistic regression model since it shows the predicted values from the model compared to the actual values from the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58f882a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix : \n",
      " [[18  1]\n",
      " [ 6  2]]\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "  \n",
    "print (\"Confusion Matrix : \\n\", cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "1eeac9d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 257.44, 'Predicted label')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the confusion matrix visually more appealing\n",
    "\n",
    "class_names=[0,1]\n",
    "\n",
    "fig, ax = plt.subplots() \n",
    "tick_marks = np.arange(len(class_names)) \n",
    "plt.xticks(tick_marks, class_names) \n",
    "plt.yticks(tick_marks, class_names) \n",
    "sns.heatmap(pd.DataFrame(cm), annot=True, cmap=\"YlGnBu\" ,fmt='g') \n",
    "ax.xaxis.set_label_position(\"top\") \n",
    "plt.tight_layout() \n",
    "plt.title('Confusion matrix', y=1.1) \n",
    "plt.ylabel('Actual label') \n",
    "plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02311028",
   "metadata": {},
   "source": [
    "As the plot shows, there are in total 27 predictions (N=108 participants * 25% test size). The upper left square in the **confusion matrix** contains all the **true positive** cases meaning that when a participant predicted as control belongs to the control group. Accordingly, the bottom right square carries information on **true negative** cases meaning a participant predicted as patient was a patient. On the contrary, the upper right square contains **false positives** cases (participant predicted as patient but was control) and the bottom left square contains information on **false negative** cases (participant predicted as control but was patient). At first sight, the model seems to be good. However, there are other measures indicating the qualtiy of the model such as **accuracy, precision and recall**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2eeec99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7407407407407407\n",
      "Precision: 0.6666666666666666\n",
      "Recall: 0.25\n"
     ]
    }
   ],
   "source": [
    "#compute accuracy, precision, recall\n",
    "\n",
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred)) \n",
    "\n",
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred)) \n",
    "\n",
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred)) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e17262e",
   "metadata": {},
   "source": [
    "The accuracy measure indicates the percentage of correct predictions, in this case 74.07%. The precision measure shows the correct positive predictions relative to total positive predictions, here 0.667. The recall measure indicates the correct positive predictions relative to total actual positives, here 0.25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e4ba0b0a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import roc_curve\n",
    "logit_roc_auc = roc_auc_score(y_test, classifier.predict(X_test))\n",
    "fpr, tpr, thresholds = roc_curve(y_test, classifier.predict_proba(X_test)[:,1])\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\n",
    "plt.plot([0, 1], [0, 1],'r--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.savefig('Log_ROC')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e321ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ee9a4e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201bc680",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6789515",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c567aea7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1600942b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "188daf0d",
   "metadata": {},
   "source": [
    "### SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feddd06e",
   "metadata": {},
   "source": [
    "Following the scikit-learn algorhitm cheat-sheet, for the data at hand the performance of a **linear SVM** is recommended. The data contains more than 50 participants (samples), the aim is to predict a category (control/patient) and the data is labeled. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e239fd",
   "metadata": {},
   "source": [
    "SVMs are a set of supervised learning methods used that can be used for classifcation, regression and outliers detection (for further information click here). The basic idea is to find an optimal separating line (or hyperplane) as output that separates the data into two classes. The SVM algorithm looks for the data points that are the clostest to the line from both classes. These points are called support vectors. Then, the distance between the support vectors and the hyperplane which is called the margin is computed. To find the best and optimal hyperplane, the margin should be maximized.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fb12fe",
   "metadata": {},
   "source": [
    "Support vector classification(SVC) or Linear Support vector classification (LinearSVC) are methods of SVMs making it feasible to perfom a binary or mulit-class classification on a dataset. For the purpose of this project, LinearSVC is going to be performed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2598d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#load CT data\n",
    "\n",
    "CT = pd.read_csv('/Users/mello/Desktop/Dataset/PARC_500.aparc_thickness_Dublin.csv', delimiter = ',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ce6f5b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#adjust data frame \n",
    "\n",
    "CT_adj = CT.drop(['Subject ID','Age', 'Sex'], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01a3903",
   "metadata": {},
   "outputs": [],
   "source": [
    "#label group 1 as control and 2 as patient\n",
    "\n",
    "CT_adj['Group'] = CT_adj['Group'].replace([1,2],['control', 'patient'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b524305",
   "metadata": {},
   "outputs": [],
   "source": [
    "CT_adj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba556885",
   "metadata": {},
   "outputs": [],
   "source": [
    "CT_adj.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f733cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#print the names of the 308 features\n",
    "\n",
    "print(\"Features: \", CT_adj.columns[2:308])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63e68e06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#print the names of the labels\n",
    "\n",
    "print(\"Labels: \", CT_adj['Group'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5816ee2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7901d758",
   "metadata": {},
   "outputs": [],
   "source": [
    "CT_data = CT_adj[0:308]\n",
    "CT_target = CT_adj['Group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a416c9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(CT_data, CT_target, test_size=0.3,random_state=109)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fffcd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ecb36b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = svm.SVC(kernel='linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc0be18",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097f0fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e43cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51097ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5869ab22",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Precision:\",metrics.precision_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adfa92b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Recall:\",metrics.recall_score(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5dd6963",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "vscode": {
   "interpreter": {
    "hash": "197750af2f3e6af0bfce9c7aa609a0a9c4ddab34bbe7a4296d7aadbc15871ba4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
